<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ponderings of an Andy</title><link href="https://andrewwegner.com/" rel="alternate"></link><link href="https://andrewwegner.com/feeds/all.atom.xml" rel="self"></link><id>https://andrewwegner.com/</id><updated>2019-12-23T10:00:00-06:00</updated><entry><title>Review of Ultimate AWS Certified Developer Associate 2019 course</title><link href="https://andrewwegner.com/aws-certified-developer-review.html" rel="alternate"></link><published>2019-12-23T10:00:00-06:00</published><updated>2019-12-23T10:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-12-23:/aws-certified-developer-review.html</id><summary type="html">&lt;p&gt;My review of the Ultimate AWS Certified Developer Associate course.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;One of my personal and professional goals for 2019 was to get a certification of some kind. That's a
fairly broad requirement with no real reasoning behind it. I wanted to learn something and I wanted it
to be helpful at work. As the year rapidly entered the last few months, I realized I not done anything
to reach the goal.&lt;/p&gt;
&lt;p&gt;After a brief talk with my management, it was decided that I should get an AWS certification. It'd help
the company out with some work we are doing to become an AWS partner, and I'd get a certification that would
be useful.&lt;/p&gt;
&lt;p&gt;With a read goal, I set out to learn something. I started by finding &lt;a href="https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/"&gt;Ultimate AWS Certified Developer Associate 2019&lt;/a&gt;
on Udemy. At the time I'm posting this entry, the course has been updated to be useful for 2020. It's always a good sign
that the creator is continuously updating their materials. This course was created by Stephane Maarek, who also
holds the certification that is being taught about.&lt;/p&gt;
&lt;h2 id="course-overview"&gt;Course Overview&lt;a class="headerlink" href="#course-overview" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course is a 19 hour overview of most of AWS. At first I thought that length was excessive, but it turns out
that 19 hours isn't enough. This course is focused only on the AWS products that you need to know for the DVA-C01
certification. There is...a lot to know.&lt;/p&gt;
&lt;p&gt;The materials go through how to use AWS's free tier for almost all of the work needed for the course. The very few
areas that can't utilize the free tier are explicitly called out, so you don't end up with surprise AWS bills.&lt;/p&gt;
&lt;p&gt;I highly recommend you set aside the time to go through this course and the practice tests. Then, I recommend
that you do it again. AWS has a &lt;em&gt;ton&lt;/em&gt; of services with three letter names. You need to know how those work
and interact with one another. You need to know how to troubleshoot them, set them up, and scale them.&lt;/p&gt;
&lt;p&gt;One pass through this course wasn't enough for me. I don't blame the instructor though. I blame the expansiveness of
the test.&lt;/p&gt;
&lt;p&gt;The practice questions were very similar to what questions looked like on the real exam. The concepts that were
covered were helpful in answering a few others.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If (when?) I go for the next level of certifications in Amazon, I'll be looking for more courses from this creator.
The course is very well built, very hands on, and obviously updated to stay relevant.&lt;/p&gt;
&lt;p&gt;In November, I took my exam and passed on the first try.&lt;/p&gt;
&lt;p&gt;I have other professional goals for next year, but if I decide to go for another AWS certification, I'll
be looking for another course by Stephane Maarek.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-CAXZ5N6F"&gt;&lt;img alt="Ultimate AWS Certified Developer Associate 2019" src="https://andrewwegner.com/images/udemy-aws-developer-certification.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="AWS Certified Developer - J2WR9QVC314Q1FSY" src="{attach}images/aws_certified_developer.jpg"/&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Setting up GitLab runners</title><link href="https://andrewwegner.com/setting-up-gitlab-runners.html" rel="alternate"></link><published>2019-10-22T11:00:00-05:00</published><updated>2019-10-22T11:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-10-22:/setting-up-gitlab-runners.html</id><summary type="html">&lt;p&gt;How I set up a GitLab runner&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been a year and a half since I set up GitLab. In that time I've used to it
store my personal code, keep track of features I want to add to my own projects,
and generally loved it. One thing I haven't done though, is play with the CI/CD
features. I've been wanting to, but never got around to it.&lt;/p&gt;
&lt;p&gt;To utilize the CI/CD features, you need to set up a &lt;a href="https://docs.gitlab.com/runner/"&gt;GitLab runner&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="set-up"&gt;Set up&lt;a class="headerlink" href="#set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="docker"&gt;Docker&lt;a class="headerlink" href="#docker" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll be running my runners in &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; containers. There are other options,
but for my home environment, this is easiest to set up and maintain.&lt;/p&gt;
&lt;p&gt;Let's start by installing Docker:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get install apt-transport-https ca-certificates curl software-properties-common -y&lt;/span&gt;
&lt;span class="err"&gt;curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -&lt;/span&gt;
&lt;span class="err"&gt;sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"&lt;/span&gt;
&lt;span class="err"&gt;sudo apt update&lt;/span&gt;
&lt;span class="err"&gt;sudo apt install docker-ce -y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is going to add the Docker repository and install the community edition.&lt;/p&gt;
&lt;h3 id="gitlab-runner"&gt;GitLab Runner&lt;a class="headerlink" href="#gitlab-runner" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once Docker is installed and working, we can install the GitLab runner.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;wget -O /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64&lt;/span&gt;
&lt;span class="err"&gt;chmod +x /usr/local/bin/gitlab-runner&lt;/span&gt;
&lt;span class="err"&gt;useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash&lt;/span&gt;
&lt;span class="err"&gt;gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner&lt;/span&gt;
&lt;span class="err"&gt;gitlab-runner start&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is downloading the install package. Then it adds a new user, that the runner will run as. This is a nice security precaution to limit what the runner has access to on the system. It's not full security, but it does all me to restrict what that particular user has access to on the server.&lt;/p&gt;
&lt;p&gt;Then the run is started.&lt;/p&gt;
&lt;p&gt;Next the runner needs to be registered. Log into GitLab, and navigate to
the project that will be using this runner. It should be available at this link:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;https://url.to.your.gitlab.install/&amp;lt;account&amp;gt;/&amp;lt;repo&amp;gt;/settings/ci_cd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Grab the GitLab CI token. That is needed in the next step. Run the &lt;code&gt;gitlab-runner register&lt;/code&gt; command, and fill in your values as required.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;register&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ci&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;coordinator&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;URL&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="k"&gt;to&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;your&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;install&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ci&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;runner&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;redacted&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ci&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;runner&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;my-runner&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gitlab&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ci&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;comma&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;separated&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Registering&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;succeeded&lt;/span&gt;&lt;span class="w"&gt;                     &lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;66&lt;/span&gt;&lt;span class="n"&gt;m_339h&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;executor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;machine&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;parallels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;virtualbox&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;machine&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;kubernetes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Please&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;enter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;default&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Docker&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;image&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;ruby&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;2.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;alpine&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;latest&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Runner&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;registered&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;successfully&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Feel&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;free&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;but&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="err"&gt;'&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;running&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;already&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;should&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;be&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;automatically&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;reloaded&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;My experience with Docker is limited, so I am using the latest alpine version. I'm sure there are better ones to use for a simple Python application, but this works for me and I'm not concerned about the absolute fastest CI/CD pipeline on my server.&lt;/p&gt;
&lt;h2 id="using-the-cicd-pipeline"&gt;Using the CI/CD pipeline&lt;a class="headerlink" href="#using-the-cicd-pipeline" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point, the GitLab runner is registered to a single project and is ready to use. You can enable your project to use this pipeline by adding a &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file to the root of your repository.&lt;/p&gt;
&lt;p&gt;I used it to set up the following pipeline.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Python - GitLab Pipeline" src="{attach}images/gitlab-python-pipeline.png.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;This pipeline has 4 stages.&lt;/p&gt;
&lt;h3 id="static-analysis"&gt;Static Analysis&lt;a class="headerlink" href="#static-analysis" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In the Static Analysis phase, I run various analysis tools over my code. The goal here is to ensure that my code, YAML documents, and documentation are easy to read and use.&lt;/p&gt;
&lt;p&gt;You'll notice the the xenon task has a warning in the image. I have the settings pretty strict in this pipeline, where I allow a very low &lt;a href="https://radon.readthedocs.io/en/latest/intro.html#cyclomatic-complexity"&gt;Cyclomatic Complexity&lt;/a&gt;. In this project, I have one function that is just barely failing my strict settings. I have allowed the pipeline to continue if this one particular task fails.&lt;/p&gt;
&lt;p&gt;I could either increase the allowed complexity in the code base to ignore the warning. Alternatively, I could not allow the pipeline to proceed until I fix this function. This was one of those instances where it hasn't been worth it to refactor the code, but I want to be reminded I &lt;em&gt;should&lt;/em&gt; fix it, so I allow the pipeline to proceed and show me the error.&lt;/p&gt;
&lt;h3 id="test"&gt;Test&lt;a class="headerlink" href="#test" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The Test phase should be fairly self explanatory. It's the stage where I run my test suite. It will only run if the Static Analysis phase completes successfully (or I allow a specific job to fail, in the case of the xenon task).&lt;/p&gt;
&lt;h3 id="deploy-testing"&gt;Deploy Testing&lt;a class="headerlink" href="#deploy-testing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the test suite has completed successfully, I deploy the package to the test instance of PyPI. This ensures that I have a successful build and deploy.&lt;/p&gt;
&lt;h3 id="deploy-production"&gt;Deploy Production&lt;a class="headerlink" href="#deploy-production" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Deployment to production is a manual step. I did this because I don't always want to push changes to production PyPI. This is especially true if I'm only making small fixes - such as white space changes. I don't want to skip the entire CI process, but I also don't want to push out to production for something so minor.&lt;/p&gt;
&lt;h2 id="environment-set-up"&gt;Environment set up&lt;a class="headerlink" href="#environment-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;One of my biggest complaints about the Travis CI integration with GitHub is how you &lt;a href="https://andrewwegner.com/travisci-insecure-environment-variables.html"&gt;can't trust environment variables in Travis CI&lt;/a&gt;. Since I control the server that this runner is connected to, I have no problem adding environment variables into GitLab.&lt;/p&gt;
&lt;p&gt;In the project, I was able to add these by going to Settings-&amp;gt;CI/CD and expanding the Variables section. I needed to store credentials for both the test and production instances of PyPI.&lt;/p&gt;
&lt;p&gt;&lt;img alt="GitLab Environment Variables" src="{attach}images/gitlab-env-variables.png.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;With these added, they are now accessible by my &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file.&lt;/p&gt;
&lt;h3 id="gitlab-ciyml"&gt;.gitlab-ci.yml&lt;a class="headerlink" href="#gitlab-ciyml" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The script I use to build the pipeline is as follows:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nc"&gt;image&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"python:3.7"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nl"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;tags&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;before_script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--version&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;install&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;stages&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Test&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Deploy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Testing&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Deploy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Production&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;flake8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;flake8&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--max-line-length=120&lt;/span&gt;

&lt;span class="nl"&gt;doc8&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;allow_failure&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;doc8&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--max-line-length=100 --ignore-path=docs/_build/* docs/&lt;/span&gt;

&lt;span class="nl"&gt;yamllint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;allow_failure&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;yamllint&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;bandit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;allow_failure&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bandit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;B101&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;my_package&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;radon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;radon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;my_package&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;nb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;radon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mi&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;my_package&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;nb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;xenon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Static&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Analysis&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;allow_failure&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;xenon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--max-absolute B --max-modules B --max-average B my_package/&lt;/span&gt;

&lt;span class="nl"&gt;pytest&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Test&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pytest&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;deploy_testing&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Deploy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Testing&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;TWINE_USERNAME&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;PYPI_TEST_USERNAME&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;TWINE_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;PYPI_TEST_PASSWORD&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sdist&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;twine&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;upload&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--repository-url $PYPI_TEST_URL dist/*&lt;/span&gt;

&lt;span class="nl"&gt;deploy_production&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Deploy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Production&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;extends&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;when&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;manual&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;variables&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;TWINE_USERNAME&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;PYPI_PROD_USERNAME&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;TWINE_PASSWORD&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;PYPI_PROD_PASSWORD&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nl"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sdist&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;twine&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;upload&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="cm"&gt;/*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="gitlab-ciyml-explanation"&gt;.gitlab-ci.yml explanation&lt;a class="headerlink" href="#gitlab-ciyml-explanation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;There are a few areas that I feel need to be explained in the script above.&lt;/p&gt;
&lt;h3 id="tags"&gt;Tags&lt;a class="headerlink" href="#tags" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nl"&gt;.python-tag:&lt;/span&gt;
  &lt;span class="nl"&gt;tags:&lt;/span&gt;
    &lt;span class="err"&gt;-&lt;/span&gt; &lt;span class="nf"&gt;python&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This section is a template that is used to add the &lt;code&gt;python&lt;/code&gt; tag to a job step. The Runner will only run tasks that have a tag you assigned to it. This is useful if you are building across multiple operating systems or across multiple languages. You don't want a runner set up to test against a Windows environment picking up tasks for a Linux environment. In my case, everything is being run for a single runner.&lt;/p&gt;
&lt;p&gt;In each step, I need to add this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;extends:&lt;/span&gt;
&lt;span class="c"&gt;  - .python-tag&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With this, the &lt;code&gt;python&lt;/code&gt; tag will be automatically applied to the task. For a simple pipeline like mine, it may seem like overkill, but it's useful if I want to force other tags or steps.&lt;/p&gt;
&lt;h3 id="allow-failures"&gt;Allow failures&lt;a class="headerlink" href="#allow-failures" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;xenon&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;stage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Static&lt;/span&gt; &lt;span class="n"&gt;Analysis&lt;/span&gt;
  &lt;span class="kd"&gt;extends&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;
  &lt;span class="n"&gt;allow_failure&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;xenon&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;absolute&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;modules&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="n"&gt;my_package&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I previously mentioned that I allowed the xenon step to fail. This is accomplished with the &lt;code&gt;allow_failue: true&lt;/code&gt; setting you see here. Since this setting is in place, the pipeline will proceed even if this single task fails.&lt;/p&gt;
&lt;h3 id="manual-deployment"&gt;Manual deployment&lt;a class="headerlink" href="#manual-deployment" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;deploy_production&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;stage&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Deploy&lt;/span&gt; &lt;span class="n"&gt;Production&lt;/span&gt;
  &lt;span class="kd"&gt;extends&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;python&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;tag&lt;/span&gt;
  &lt;span class="n"&gt;when&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;manual&lt;/span&gt;
  &lt;span class="n"&gt;variables&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;TWINE_USERNAME&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;$PYPI_PROD_USERNAME&lt;/span&gt;
    &lt;span class="n"&gt;TWINE_PASSWORD&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;$PYPI_PROD_PASSWORD&lt;/span&gt;
  &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;py&lt;/span&gt; &lt;span class="n"&gt;sdist&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;twine&lt;/span&gt; &lt;span class="n"&gt;upload&lt;/span&gt; &lt;span class="n"&gt;dist&lt;/span&gt;&lt;span class="o"&gt;/*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The deploy to production is a manual step. I use &lt;code&gt;when: manual&lt;/code&gt; to ensure this step doesn't occur automatically. At some point in the future, this project will be stable and won't have minor fixes any longer and I'll want to automatically deploy to production without interaction. When I reach that point, I'll just need to remove this line. As long as the preceding steps succeed, this one will be performed as well.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next Steps&lt;a class="headerlink" href="#next-steps" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now that I've set this up and come to rely on it, I think my next steps will be converting my home Minecraft Server to use the GitLab pipelines to automatically deploy updates. Look for that post in the future.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Installing InvoiceNinja on Ubuntu 18.04</title><link href="https://andrewwegner.com/invoiceninja-ubuntu-1804.html" rel="alternate"></link><published>2019-07-30T13:00:00-05:00</published><updated>2019-07-30T13:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-07-30:/invoiceninja-ubuntu-1804.html</id><summary type="html">&lt;p&gt;A brief walkthrough on how to install InvoiceNinja on Ubuntu 18.04&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been a several years since I really did a lot of freelance work. Mostly, I did it in the evening hours
a few nights a week for some extra money. Over the last few years, that kind of work has
slowed down for me. Mostly because I enjoy relaxing in the evenings and spending time off
of my computer now. It's weird to type that, but "hobby coding" really hasn't had as much
appeal to me since I started my &lt;a href="https://andrewwegner.com/how-i-found-an-awesome-remote-only-job.html"&gt;current job&lt;/a&gt; a few years ago.&lt;/p&gt;
&lt;p&gt;I love my job. I love working from home 100% of the time and I love being home
when the kids get off the bus, during summer breaks, and when the weather sucks. The
one thing this job has done though, is remove my desire to sit in my office after
everyone else has gone to bed and just code.&lt;/p&gt;
&lt;p&gt;But, that's ok. I've found other hobbies and am really excited about some up coming
things I'm trying out. If they work out, I'll be able to combine my coding skills
with other hobbies. I'm sure I'll write about it at some point.&lt;/p&gt;
&lt;p&gt;I say all of that, because, even though I don't actively take on freelance work any
longer, I still have clients that I did work for that will reach out once and a while
for help, consultations or a small project. When that happens, I need a way to bill them
for my time.&lt;/p&gt;
&lt;p&gt;Previously, my invoices would have been whipped up in Word and converted to a PDF and sent
off to the client. It worked for years. I was able to keep track of everything,
properly report it (don't want to mess with the tax man) and I kept chugging along. The
problem now, is that if I'm doing work for a client, I want to do the work and be done. I don't
want to spent time making a presentable invoice in Word.&lt;/p&gt;
&lt;p&gt;So, I went hunting for some software. I found &lt;a href="https://www.invoiceninja.com/"&gt;InvoiceNinja&lt;/a&gt;. It's amazing.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hosted or self hosted version&lt;/li&gt;
&lt;li&gt;Create simple invoices&lt;/li&gt;
&lt;li&gt;Create full quotes&lt;/li&gt;
&lt;li&gt;API (which I will probably never use, but...it's there)&lt;/li&gt;
&lt;li&gt;Recurring billing&lt;/li&gt;
&lt;li&gt;Zapier integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have this habit of self hosting my own software. See my posts on &lt;a href="https://andrewwegner.com/installing-nextcloud.html"&gt;NextCloud&lt;/a&gt;
and &lt;a href="https://andrewwegner.com/installing-gitlab.html"&gt;GitLab&lt;/a&gt; for other examples.&lt;/p&gt;
&lt;p&gt;This rest of this post is going to walk through how I installed InvoiceNinja.&lt;/p&gt;
&lt;h2 id="getting-started"&gt;Getting Started&lt;a class="headerlink" href="#getting-started" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I'll be self hosting &lt;a href="https://www.invoiceninja.org/"&gt;InvoiceNinja&lt;/a&gt;. You can find that on their &lt;code&gt;.org&lt;/code&gt; site
or on &lt;a href="https://github.com/invoiceninja/invoiceninja"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this, I'll be installing InvoiceNinja, setting up Apache to host it, and showing how
to update it in the future.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ wget https://download.invoiceninja.com/ninja-v4.5.13.zip
$ unzip ninja-v4.5.13.zip
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This downloads and unzips InvoiceNinja 4.5.14 to the current directory. Next,
let's move it to it's final install location and set up appropriate owner and
permissions.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo mv ninja /var/www/html
$ &lt;span class="nb"&gt;cd&lt;/span&gt; /var/www/html
$ sudo chown -R www-data:www-data ninja/
$ sudo chmod -R &lt;span class="m"&gt;755&lt;/span&gt; ninja/storage
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="database-setup"&gt;Database setup&lt;a class="headerlink" href="#database-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;InvoiceNinja runs on MySQL (or MariaDB). We need to create the database, but
the installer will do the rest of the work for us. Log into MySQL with a user
that can create new databases, users and permissions.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mysql -u root -p
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we'll run three commands. The first is to create the new database, the second
is to create the user. The third is to set appropriate permissions for the
new user and new password.&lt;/p&gt;
&lt;p&gt;!!! attention
    Change the default password from &lt;code&gt;ninja&lt;/code&gt; to something secure&lt;/p&gt;
&lt;p&gt;Our three commands:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;CREATE DATABASE ninja;&lt;/span&gt;
&lt;span class="err"&gt;CREATE USER 'ninja'@'localhost' IDENTIFIED BY 'ninja';&lt;/span&gt;
&lt;span class="err"&gt;GRANT ALL PRIVILEGES ON ninja.* TO 'ninja'@'localhost';&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Exit MySQL.&lt;/p&gt;
&lt;h2 id="configure-apache"&gt;Configure Apache&lt;a class="headerlink" href="#configure-apache" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now we're going to set up a new virtualhost in Apache to serve InvoiceNinja.&lt;/p&gt;
&lt;p&gt;Create an entry in sites-available.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;nano /etc/apache2/sites-available/invoiceninja.conf&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;My entry looks like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
     DocumentRoot /var/www/html/ninja/public
     ServerName invoice.example.com
     Redirect permanent / https://invoice.example.com/

     &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/ninja/public&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        Options +FollowSymlinks
        AllowOverride All
        Require all granted
     &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:443&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerName invoice.example.com
    DocumentRoot /var/www/html/ninja/public
    SSLEngine on
    SSLCertificateFile /path/to/dehydrated/certs/invoice.example.com/cert.pem
    SSLCertificateKeyFile /path/to/dehydrated/certs/invoice.example.com/privkey.pem
    SSLCertificateChainFile /path/to/dehydrated/certs/invoice.example.com/chain.pem
    &lt;span class="nt"&gt;&amp;lt;IfModule&lt;/span&gt; &lt;span class="err"&gt;mod_headers.c&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        Header always set Strict-Transport-Security "max-age=15552000; includeSubDomains"
    &lt;span class="nt"&gt;&amp;lt;/IfModule&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/ninja&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This sets up a direct from HTTP to HTTPS. Then it points to the SSL certificates I've
created for this subdomain. I previously wrote about &lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;how I set up SSL&lt;/a&gt;. I followed the
same steps, using the new subdomain.&lt;/p&gt;
&lt;p&gt;With SSL and the subdomain set up in CloudFlare, it's time to enable the site:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo a2ensite invoiceninja.conf
$ sudo systemctl reload apache2
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="completing-the-install"&gt;Completing the install&lt;a class="headerlink" href="#completing-the-install" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Navigate to the new subdomain, and fill out the form. Installation will be
completed in a minute or so.&lt;/p&gt;
&lt;h2 id="updating"&gt;Updating&lt;a class="headerlink" href="#updating" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At some point, InvoiceNinja will come out with an update, and I'll want to update
to get the newest features and security patches.&lt;/p&gt;
&lt;p&gt;To start with, we want to download the newest version:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ wget https://download.invoiceninja.com/ninja-v4.5.14.zip
$ unzip ninja-v4.5.14.zip
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, &lt;code&gt;rsync&lt;/code&gt; the files to the installed directory.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo rsync -tr ninja/ /var/www/html/ninja/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This messes up permissions, so reset those.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;cd&lt;/span&gt; /var/www/html
$ sudo chown -R www-data:www-data ninja/
$ sudo chmod -R &lt;span class="m"&gt;755&lt;/span&gt; ninja/storage
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, hit the &lt;code&gt;/update&lt;/code&gt; URL to complete the process&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;wget https://invoice.example.com/update&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="technical"></category></entry><entry><title>Updating PHP from 7.1 to 7.3 on Ubuntu 18.04</title><link href="https://andrewwegner.com/updating-php-ubuntu-1804.html" rel="alternate"></link><published>2019-07-26T10:00:00-05:00</published><updated>2019-07-26T10:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-07-26:/updating-php-ubuntu-1804.html</id><summary type="html">&lt;p&gt;A brief walkthrough on how to upgrade PHP to 7.3 (and make sure NextCloud still works)&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://andrewwegner.com/new-house-server.html"&gt;new server&lt;/a&gt; has been up and running for about a year and a half now. It's still
working really well. The thing that I'm happiest with is &lt;a href="https://andrewwegner.com/installing-nextcloud.html"&gt;my NextCloud install&lt;/a&gt;. Having
my pictures automatically backed up from the phones is a huge time saver. I no
longer need to worry about whether or not I grabbed a set of pictures off the
phone or which phone has which picture. It's all in one place in NextCloud. This
makes it easy to find what I'm looking for (and easy to backup).&lt;/p&gt;
&lt;p&gt;NextCloud runs on PHP, which means I need to have PHP installed on the server
for it to work. This isn't a huge problem, but the last time I really used PHP,
it was during the transition between PHP 4 and PHP 5. So...a while ago. I set up PHP
(and Apache) to host NextCloud and really just forgot about it.&lt;/p&gt;
&lt;p&gt;During a recent update of packages on the server - because I do like to keep
everything updated. I noticed this line during the &lt;code&gt;apt-get&lt;/code&gt; scroll:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;php7.1 module already enabled, not enabling PHP 7.3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Time to figure out how to use that newly install/upgraded PHP 7.3&lt;/p&gt;
&lt;h2 id="what-is-actually-running"&gt;What is actually running?&lt;a class="headerlink" href="#what-is-actually-running" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first thing I did was check which version of PHP was being used in the terminal:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ php -v
PHP &lt;span class="m"&gt;7&lt;/span&gt;.3.7-2+ubuntu18.04.1+deb.sury.org+1 &lt;span class="o"&gt;(&lt;/span&gt;cli&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;built: Jul &lt;span class="m"&gt;25&lt;/span&gt; &lt;span class="m"&gt;2019&lt;/span&gt; &lt;span class="m"&gt;11&lt;/span&gt;:44:59&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt; NTS &lt;span class="o"&gt;)&lt;/span&gt;
Copyright &lt;span class="o"&gt;(&lt;/span&gt;c&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;1997&lt;/span&gt;-2018 The PHP Group
Zend Engine v3.3.7, Copyright &lt;span class="o"&gt;(&lt;/span&gt;c&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;1998&lt;/span&gt;-2018 Zend Technologies
    with Zend OPcache v7.3.7-2+ubuntu18.04.1+deb.sury.org+1, Copyright &lt;span class="o"&gt;(&lt;/span&gt;c&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="m"&gt;1999&lt;/span&gt;-2018, by Zend Technologies
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's promising. The default version here is PHP 7.3.7.&lt;/p&gt;
&lt;p&gt;But, throwing a quick &lt;code&gt;phpinfo();&lt;/code&gt; together and looking at what it running via
Apache, shows something different:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;PHP Version 7.1.30-1+ubuntu18.04.1+deb.sury.org+1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ok. Now I know which module is out of date. It's the run that is configured to
be used with Apache.&lt;/p&gt;
&lt;h2 id="verifying-whats-installed"&gt;Verifying what's installed&lt;a class="headerlink" href="#verifying-whats-installed" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I assumed I had PHP 7.3 installed, but I wanted to confirm before I just started
disabling and enabling Apache modules.&lt;/p&gt;
&lt;p&gt;To confirm I had PHP 7.3 available, I ran this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls /etc/apache2/mods-available/php*
/etc/apache2/mods-available/php7.1.conf
/etc/apache2/mods-available/php7.1.load
/etc/apache2/mods-available/php7.2.conf
/etc/apache2/mods-available/php7.2.load
/etc/apache2/mods-available/php7.3.conf
/etc/apache2/mods-available/php7.3.load
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And a quick check to see what's enabled:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls /etc/apache2/mods-enabled/php*
/etc/apache2/mods-enabled/php7.1.conf
/etc/apache2/mods-enabled/php7.1.load
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Excellent. I have PHP 7.3 available, and PHP 7.1 is enabled. This is exactly what
I'm seeing.&lt;/p&gt;
&lt;h2 id="updating-apache-php-module"&gt;Updating Apache PHP Module&lt;a class="headerlink" href="#updating-apache-php-module" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With PHP 7.3 already installed, I just need to disable PHP 7.1 and enable PHP 7.3.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ a2dismod php7.1
$ a2enmod php7.3
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then restart Apache to use the new module.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ service apache2 restart
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, validate the correct module is enabled:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ls /etc/apache2/mods-enabled/php*
/etc/apache2/mods-enabled/php7.3.conf
/etc/apache2/mods-enabled/php7.3.load
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Another check of the &lt;code&gt;phpinfo();&lt;/code&gt; page too:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;PHP Version 7.3.7-2+ubuntu18.04.1+deb.sury.org+1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This matches what &lt;code&gt;php -v&lt;/code&gt; output.&lt;/p&gt;
&lt;p&gt;We're done! Right?&lt;/p&gt;
&lt;h2 id="checking-nextcloud"&gt;Checking NextCloud&lt;a class="headerlink" href="#checking-nextcloud" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With PHP updated, it was time to make sure the one PHP application I run still
worked. I visited my &lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;NextCloud URL I set up CloudFlare&lt;/a&gt;. There I was greeted
with a blank page. Oddly, I couldn't find any errors in my server logs.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;a2dismod&lt;/code&gt; and &lt;code&gt;a2enmod&lt;/code&gt; commands from above, I downgraded back to
PHP 7.1. NextCloud worked. I upgraded to PHP 7.2 and it worked. Going back to PHP
7.3, and I was back to a blank page.&lt;/p&gt;
&lt;p&gt;Even without server logs, this indicated that either NextCloud doesn't support
PHP 7.3 or I was missing modules. A check of the &lt;a href="https://docs.nextcloud.com/server/15/admin_manual/installation/system_requirements.html"&gt;system requirements for NextCloud&lt;/a&gt;
shows that PHP 7.3 is supported. That just means I'm missing some modules.&lt;/p&gt;
&lt;p&gt;The documentation also includes a &lt;a href="https://docs.nextcloud.com/server/15/admin_manual/installation/source_installation.html#prerequisites-for-manual-installation"&gt;list of all needed modules&lt;/a&gt; and a nice
&lt;a href="https://github.com/nextcloud/vm/blob/master/nextcloud_install_production.sh/"&gt;shell script&lt;/a&gt; for easy installation. Looking through that, I found the &lt;code&gt;apt&lt;/code&gt;
&lt;a href="https://github.com/nextcloud/vm/blob/c469b3045c7405261a0d9f20fec7ef5f0f508efe/nextcloud_install_production.sh#L256-L272"&gt;packages I needed&lt;/a&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ apt-get install php7.3-fpm &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-intl &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-ldap &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-imap &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-gd &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-pgsql &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-curl &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-xml &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-zip &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-mbstring &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-soap &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-smbclient &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-json &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-gmp &lt;span class="se"&gt;\&lt;/span&gt;
php7.3-bz2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A minute or so later, with those modules now installed, I restarted Apache again.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ service apache2 restart
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then I went to my NextCloud URL. The page loaded as expected and my phone
sync'd the one picture I took as a test to ensure it worked.&lt;/p&gt;
&lt;p&gt;Overall, this was a really simple process. The biggest issue I ran into was missing
a module or two that NextCloud required. Simply installing everything it needed
worked perfectly.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Review of Travis CI Tutorial Udemy course</title><link href="https://andrewwegner.com/travis-ci-tutorial-review.html" rel="alternate"></link><published>2019-07-09T14:30:00-05:00</published><updated>2019-07-09T14:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-07-09:/travis-ci-tutorial-review.html</id><summary type="html">&lt;p&gt;My review of the Travis CI Tutorial course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've written about Travis CI before. I've reported a bug that makes it fairly easy
to see &lt;a href="https://andrewwegner.com/travisci-insecure-environment-variables.html"&gt;environment variables in Travis CI&lt;/a&gt; or even unintentionally transfer
them if you transfer your repository. I &lt;a href="https://andrewwegner.com/autobuild-pelican-blog.html"&gt;build this blog using Travis CI&lt;/a&gt;. I've
&lt;a href="https://andrewwegner.com/how-i-set-up-openshift-travisci-and-flask.html"&gt;used Travis CI to set up an OpenShift application&lt;/a&gt;. &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt; uses it to 
manage it's blacklists. In short, I have experience with Travis CI.&lt;/p&gt;
&lt;p&gt;I was surprised when I saw a course being offered for free recently on Udemy that
deals with Travis CI. Since it was free and only a couple hours long, I figured I'd
give it a shot. I enrolled in the course.&lt;/p&gt;
&lt;p&gt;This is my review of &lt;a href="https://www.udemy.com/travis-ci-tutorial/"&gt;Travis CI Tutorial&lt;/a&gt; by Vaga Notes.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course starts with no instructor introduction, no explanation of what
the course is about, or goals for the course. If you don't know what Travis CI is,
don't expect to learn that here. You are expected to know what it is and what
it does. Honestly, you should probably have used it before too.&lt;/p&gt;
&lt;p&gt;All coding done for this course is gone in the GitHub web editor. This bothered
me initially, but after thinking about it, not so much. Most of the "real code"
needed for this course is simply editing the &lt;code&gt;.travis.yml&lt;/code&gt; file and the instructor
saves a lot of time by &lt;em&gt;not&lt;/em&gt; dealing with git and GitHub more than necessary.&lt;/p&gt;
&lt;p&gt;Unfortunately, I think that is going to be the last good thing I have to say
about this course. The rest can be summed up with one word: Inconsistent.&lt;/p&gt;
&lt;p&gt;The sound is inconsistent. From one lesson to another, the instructor goes from
being whisper quiet at highest volume to so loud it hurts. The microphone being
used picks up static and most annoyingly, the instructor keeps coughing into the
mic. Sound &lt;em&gt;within&lt;/em&gt; a lesson is also inconsistent. In one lesson - Lesson 13 "Build Stages" -
it went from quiet to loud and back multiple times.&lt;/p&gt;
&lt;p&gt;Testing of the course material was inconsistent. The instructor recording their
videos an hour after they had done it the first time, in some cases. This
short time between doing it the first time and recording it for the tutorial
is seen in how the instructor handles unexpected delays and failing builds.&lt;/p&gt;
&lt;p&gt;The presentation is inconsistent. On several videos, the instructor obviously
spent time making an intro and outro for the lecture. It's a few second animation
and sound effect that encapsulates the lesson. On others, they jump right into the
material or awkwardly end the lesson. If the instructor had spent more time
giving the course a unified look and feel through the entire course, it'd come
across as more polished. Instead, it looks like it was thrown together haphazardly.&lt;/p&gt;
&lt;p&gt;Which brings me to the content. This is also inconsistent. There are points where
the instructor didn't have a script at worse and only high level bullet points
at best. They mumble their way through an explanation or series of interface
options. They live code - with typos - their way through set up. They navigate to
GitHub using Google Search, but accidentally click to quickly and get a previous
search result (that could have been embarrassing).&lt;/p&gt;
&lt;p&gt;Along with the live coded examples and an after thought of an explanation of
what each step means, there is very bad advice given in some locations.&lt;/p&gt;
&lt;p&gt;The first example of this is setting up environment variables (see my post
on &lt;a href="https://andrewwegner.com/travisci-insecure-environment-variables.html"&gt;Travis CI environment variables&lt;/a&gt;). While setting up the GitHub token, so
that Travis can deploy GitHub Pages, the advice given is to "just give it all
the access". NO! NO NO NO NO NO! NO!. Especially when combined with the next
step they took, which isn't even described.&lt;/p&gt;
&lt;p&gt;The instructor moves over to Travis CI from GitHub to put in the environment variable.
They put in the name of the variable and the value. Then they change the "Display
this value in build log" from the default "Off" to "On" &lt;em&gt;and don't say why&lt;/em&gt;!.&lt;/p&gt;
&lt;p&gt;Moments later a build is pushed, the Travis CI log is shown, and there is the
GitHub token that had "all the access" displayed in the build log. Anyone can
come along and use that token to do anything to your GitHub repository.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course is now listed for $20. It's not worth it. Go find something on YouTube,
look at another repository that is already using Travis CI or Google for an example.
Any of those options are going to be more useful to you - and more consistent - than
this course. With the bad sound, half finished video introductions, and horrible
advice on token generation the only thing you'll be doing if you take this course is
play with your volume constantly and learn the wrong way to set up environment variables.&lt;/p&gt;
&lt;p&gt;This course feels like it was recorded while the instructor was home sick with a
minor cold and got bored with their video editing software.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-IJRCAV24"&gt;&lt;img alt="Software Testing Masterclass (2019) - From Notice to Expert" src="https://andrewwegner.com/images/udemy-travis-ci.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Review of Software Testing Masterclass (2019) - From Notice to Expert Udemy course</title><link href="https://andrewwegner.com/software-testing-masterclass.html" rel="alternate"></link><published>2019-05-14T15:00:00-05:00</published><updated>2019-05-14T15:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-05-14:/software-testing-masterclass.html</id><summary type="html">&lt;p&gt;My review of the Software Testing Masterclass course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I do QA work for my job and love learning new things, techniques or ways of doing
my job better. The &lt;a href="https://ude.my/UC-1F1K67C9"&gt;Software Testing Masterclass (2019) - From Novice to Expert&lt;/a&gt;
caught my eye during one of Udemy's many sales. This course is only five hours long
so I figured it'd be a quick overview (and I'd be able to skip of the 'novice') part
of the course. It was created by Ozan İlhan. Their Udemy biograph says they
have been a professional software tester for the last 10 years.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;First things first, English is not the instructor's first language. In most of the
course this is not a problem, but be aware that there are some grammatical things
that may throw a native speaker. Normally, I wouldn't count this against the
instructor, but they specifically call out in the course description:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;All videos have hand edited subtitles. We spent many hours to correct all the subtitles to help you to have a smooth learning experience.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Unfortunately, those subtitles are exactly what was said, so the grammar issues
are even more glaring.&lt;/p&gt;
&lt;p&gt;The "high-quality sound" that boasted about in the course description doesn't
seem accurate. Sound from one lesson to the next varies wildly. In one lesson
it is difficult to hear the instructor and in the next they are super loud.&lt;/p&gt;
&lt;p&gt;OK, on to the actual content.&lt;/p&gt;
&lt;p&gt;I felt this course did not take the "to Expert" part of the name to heart. Much
of the content was power point slides being read to the student. The "Novice"
portion of the course was laying a groundwork for students to understand the
different types of testing, software development life cycle, how to report bugs,
and how to build test cases.&lt;/p&gt;
&lt;p&gt;The instructor provided a template for bug reporting and test case checklists. I
cringe a little bit because these are Excel documents, but I've worked in the
corporate world and Excel is the hammer used to pound every nail. I've seen and used
templates that look very similar. It's not flashy or "an app", but it is what's
used "in the real world", even if I hated using it at the time.&lt;/p&gt;
&lt;p&gt;I think the "Expert" part of the course is labeled "Advance Testing Concepts",
which covers different types of tests in more detail. This covers, black box testing,
smoke and sanity testing, reggression testing, risk based testing and a few others.
Unfortunately, this is presented as Power Point slides again.&lt;/p&gt;
&lt;p&gt;The last real content in the course is covering how to sign up for various
things like GitHub, JIRA, TestRail and TestLodge.&lt;/p&gt;
&lt;p&gt;Finally, the course ends with what feels like a bunch of advertisements for
freelance testing services. There are very brief overviews of uTest, Testlio,
and BugFinders.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Overall, I am disappointed in this course. I was really hoping the "Expert" part
covered a bit more or even new methods. Unfortunately, everything here I've heard
of and used at one point or another.&lt;/p&gt;
&lt;p&gt;Additionally, I'm really disappointed that so much of the course was being read
a Power Point presentation. I was hoping to see some testing frameworks in action
to compare/contrast the benefits of one over the other.&lt;/p&gt;
&lt;p&gt;Due to the over use of Power Point though, and the last part of the course feeling
like plugs for various services, I can't recommend this course.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-1F1K67C9"&gt;&lt;img alt="Software Testing Masterclass (2019) - From Notice to Expert" src="https://andrewwegner.com/images/udemy-testing-masterclass.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Stack Overflow still has issues and it's getting worse</title><link href="https://andrewwegner.com/stack-overflows-still-has-issues-and-its-getting-worse.html" rel="alternate"></link><published>2019-03-29T10:34:00-05:00</published><updated>2019-03-29T10:34:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-03-29:/stack-overflows-still-has-issues-and-its-getting-worse.html</id><summary type="html">&lt;p&gt;A follow up from a post I made a year and a half ago. How's Stack Overflow doing (from the perspective of a long time community member and moderator)?&lt;/p&gt;</summary><content type="html">
&lt;h2 id="last-time-on-this-blog"&gt;Last time on this blog&lt;a class="headerlink" href="#last-time-on-this-blog" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A little over a year and a half ago, I wrote an article about &lt;a href="https://andrewwegner.com/stack-overflows-problem-feedback-from-an-experienced-user.html"&gt;Stack Overflow's problems&lt;/a&gt;
from my perspective as an experienced user. This was before I was &lt;a href="https://andrewwegner.com/collecting-diamonds-on-stack-exchange.html"&gt;elected as a moderator&lt;/a&gt; on
Stack Overflow. I ended the previous article with this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I continue to invest my time and effort into the community, but even as an active user who
really wants the company and community to succeed, it's getting harder and harder to ignore that
those of us that have been around for years are not being listened to any more. We're being treated as the
grumpy old person that grumbles about the way things used to be. Our experiences on the site are brushed aside as
being unhelpful to new users. That completely ignores that fact that we are still trying to reach
the goal on which Stack Overflow was created:
&lt;a href="https://stackoverflow.com/tour"&gt;"With your help, we're working together to build a library of detailed answers to every question about programming."&lt;/a&gt;
To do this, we need high quality questions and answers so that we can actually provide help to all users. I
think &lt;em&gt;this&lt;/em&gt; is the biggest challenge that Stack Overflow is going to face in the next 18 months.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, what's happened in the last 18 months?&lt;/p&gt;
&lt;h2 id="documentation"&gt;Documentation&lt;a class="headerlink" href="#documentation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After years of development (being announced in 2015), &lt;a href="https://meta.stackoverflow.com/q/354217/189134"&gt;Documentation was shuttered&lt;/a&gt; in August of 2017. Stack Overflow
wasn't drawing users to the Documentation feature. Their own metrics and analysis showed that fixing Documentation to
be useful to users - both new and experienced - would require a significantly larger team.&lt;/p&gt;
&lt;h3 id="what-went-wrong"&gt;What went wrong?&lt;a class="headerlink" href="#what-went-wrong" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In my opinion, and as I &lt;a href="https://andrewwegner.com/stack-overflows-problem-feedback-from-an-experienced-user.html"&gt;mentioned&lt;/a&gt; in 2017, Stack Overflow has ignored it's user base. This is going to be a recurring
theme in this post. For years, users provided feedback on meta, in dedicated user experience interviews and in chatrooms.
This resulted in superficial changes and major rewrites. Yet, complaints still existed. These complaints turned off the
experienced users that could produce the high quality documentation. Instead, Documentation became a reputation farming operation
in all but name. This turned off even more users.&lt;/p&gt;
&lt;p&gt;By Stack Overflow's own admission when sun setting the feature, Documentation was built to solve a problem that wasn't really a
problem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Finally, our research showed that while a lot of developers were dissatisfied, the current state of programming documentation is
not universally broken the way Q&amp;amp;A was when Stack Overflow started. In particular, we heard over and over that Stack Overflow
has become de facto documentation for many technologies. As many of you pointed out, Stack Overflow is already good enough
at providing documentation of obscure features. Even when considering just the company's mission of helping programmers
“learn, share their knowledge and build their careers”, Documentation isn't the most efficient use of resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Two years of major development, focusing on a problem that the community had not been enthusiastic about, and intentionally ignoring
other feature requests and other improvements angered a lot of users.&lt;/p&gt;
&lt;h2 id="teams"&gt;Teams&lt;a class="headerlink" href="#teams" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my &lt;a href="https://andrewwegner.com/stack-overflows-problem-feedback-from-an-experienced-user.html"&gt;last post&lt;/a&gt;, I mentioned that Teams had been launched and shut down in less than a year. Teams is back! At least the name is.
Initially launched as &lt;a href="https://meta.stackoverflow.com/q/352065/189134"&gt;"Channels"&lt;/a&gt;, and later re-branded to "Stack Overflow for Teams", this is a money generating route for Stack Overflow.
It uses the &lt;a href="https://stackoverflow.com/teams"&gt;old URL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, generating money is good. It's good for both the community and the company. Without money, the company can't survive. Without the
company there is not Stack Overflow or community. My problem isn't with money generation. My problem is that, once again, community feature
requests for higher quality and moderation tooling to cultivate that higher quality was ignored.&lt;/p&gt;
&lt;p&gt;By all accounts, Teams seems to be doing well and bringing in revenue. I am hopeful that this translates into development time to
build out the features the community still clamors for.&lt;/p&gt;
&lt;h2 id="meta-hatred"&gt;Meta hatred&lt;a class="headerlink" href="#meta-hatred" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Meta. &lt;a href="https://blog.codinghorror.com/meta-is-murder/"&gt;It's murder.&lt;/a&gt; Until it's not. Meta is how Stack Overflow communicates with the community. It's how the community
communicates with itself. It's where governing principals/thoughts/guidance/sticky notes comes from. In short, meta is a
large part of how Stack Overflow the company and Stack Overflow the community talks with one another. Decisions are questioned here,
announcements are posted here, and little by little the site is made better.&lt;/p&gt;
&lt;p&gt;That is, until nothing happens. Stack Overflow's &lt;a href="https://meta.stackexchange.com/a/19514/186281"&gt;response time has become a meme&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;"6 to 8 weeks" is a joke. It's used to indicate that something isn't going to be built or changed. It's so prevalent that this
comment crops up over and over on feature request posts. It's used by the community to say that nothing is going to happen.&lt;/p&gt;
&lt;p&gt;When something does happen, it's a "big deal". There have been a few examples in the past year. Unfortunately, these changes happened
due to feedback from Twitter, not Meta. For years we've been told to post on Meta. For years we've been told that Meta is where
the company will engage with us. Then two massive changes happened.&lt;/p&gt;
&lt;h3 id="the-welcoming"&gt;The Welcoming&lt;a class="headerlink" href="#the-welcoming" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first change was to make Stack Overflow more &lt;a href="https://stackoverflow.blog/2018/04/26/stack-overflow-isnt-very-welcoming-its-time-for-that-to-change/"&gt;"welcoming"&lt;/a&gt;. This isn't bad. As both an experienced user and as a
moderator, I've seen my fair share of users not being welcomed. I've seen hostility to poorly asked questions.&lt;/p&gt;
&lt;p&gt;Unfortunately, this whole blog post and resulting meta-drama &lt;em&gt;appears&lt;/em&gt; to have cropped up because of a post on Twitter from
someone who felt unwelcome. That's fair. I believe they felt that way. However, from my point of view, Stack Overflow ignored
their own users (some of whom had been saying the exact same thing for years) because it was suddenly posted on Twitter where
the entire world could comment on things that may have been out of context. Instead of listening to their own users and the
experiences those users had, Stack Overflow went into damage control mode and rapidly &lt;a href="https://stackoverflow.blog/2018/06/21/rolling-out-the-welcome-wagon-june-update/"&gt;updated it's "Be Nice" policy.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Whether this is actually what happened or not is really beside the point. Many long time users had this perception. Meta was
ignored. User feedback was ignored. Instead, the person that could shout the loudest and had made the most noise appeared to
be the one that was listened to.&lt;/p&gt;
&lt;p&gt;A few months after the welcoming blog was posted and a month after the update, another post was made about how the company
was attempting to &lt;a href="https://stackoverflow.blog/2018/07/10/welcome-wagon-classifying-comments-on-stack-overflow"&gt;classify comments&lt;/a&gt;. The idea behind this was good, the execution of the blog post was not. In the initial
version of the post, exact comments were posted to show "bad comments". I disagreed that a few of them were rude. I'd have removed them
as no longer needed without a problem. Honestly, I'd probably have removed them as rude too, because comments don't need to stick around
and it's easier to accept the rude flag than it is to decline and manually delete.&lt;/p&gt;
&lt;p&gt;My problem was that the exact comment content was posted as a "wall of shame". Then, despite only employees being involved, none
of these comments were removed or even flagged for moderators to remove. In short, it really was a "wall of shame".&lt;/p&gt;
&lt;p&gt;I believe I covered my disappointment in both this failure and in the technical aspect in my &lt;a href="https://stackoverflow.blog/2018/07/10/welcome-wagon-classifying-comments-on-stack-overflow/#comment-29001"&gt;comment&lt;/a&gt; on the blog.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am a huge fan of automatically removing unwanted comments. I did so for several years. That said, I’m disappointed in how
this is playing out here. I’m disappointed on both a community level and a technical level.&lt;/p&gt;
&lt;p&gt;On the community level, I am very disappointed that 57 Stack Exchange employees were able to evaluate bad comments, determine
they were bad enough to put in the hall of shame post here, and then do nothing about them. It took users less than 15 minutes
to find those comments on Stack Overflow and identify the “rude” users. Users who are rude because they asked why a certain
tag was on a question. Did none of your 57 users have a diamond where you could remove the comment from the site? Even if
that’s the case, all of you have the option to flag a comment. Even that wasn't done.&lt;/p&gt;
&lt;p&gt;On a technical level, you evaluated less than 4000 comments. That is a few hours worth of comments on a single week
day. (source: http://data.stackexchange.com/stackoverflow/query/872382) Is that really representative? How did you determine
which comments to use in your evaluation?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The good news is that the comment samples were edited to be "representative" of the problem later.&lt;/p&gt;
&lt;p&gt;Welcoming users is &lt;em&gt;great&lt;/em&gt;. Helping users is the purpose of the site. I fully support all of that. What I don't support is
ignoring the feedback mechanism you've built and told everyone to use for years because someone else with a lot of Twitter
followers put Stack Overflow in a bad light. Yes, it should be fixed and should have been fixed sooner, but the perception
of "listen to the loudest shout" is not a good look.&lt;/p&gt;
&lt;p&gt;Which brings me to...&lt;/p&gt;
&lt;h3 id="removal-from-network-questions-list"&gt;Removal from Network Questions list&lt;a class="headerlink" href="#removal-from-network-questions-list" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In October, the entire "Twitter shouted, Stack Overflow reacted" repeated itself. This time, a user was offended (while on
Stack Overflow) over the Hot Network Questions list for two questions on another Stack Exchange site. In under an hour,
Stack Overflow (the company) removed that question from the hot network questions list.&lt;/p&gt;
&lt;p&gt;The community in question was shocked by the result. A community manager explained the decision on that &lt;a href="https://interpersonal.meta.stackexchange.com/a/3335/34"&gt;site's meta&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It was the solution we chose - without consulting IPS - because it was effective and easy to implement since it would
fix the perceived problem immediately and there was already a technical solution in place for doing it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Notice a couple things here that stand out to me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"perceived problem"&lt;/li&gt;
&lt;li&gt;"without consulting IPS"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The company knee-capped an entire community and a large source of their traffic (the Hot Network Questions list) because
of a single Twitter comment. Understandably, the community was upset.&lt;/p&gt;
&lt;p&gt;Behind the scenes was even worse. On Twitter, the original user posting their complaint was engaged by community moderators.
It didn't go well. Then they complained about that. A Stack Overflow employee jumped into the thread with the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If the DM trolls claimed to be moderators on any of the sites then I'd like to follow up with the community team and see about
getting removed - they take this very seriously.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Turns out that Stack Overflow doesn't value their community moderators. One employee might be misguided, but this Twitter
reply remained active and moderators across the network clamored for an official response. A moderator reached out to the Twitter
user in good faith and was threatened with removal by a Stack Overflow employee.&lt;/p&gt;
&lt;p&gt;One of Stack Exchange's most respected moderators posted &lt;a href="https://medium.com/@cellio/dear-stack-overflow-we-need-to-talk-13bf3f90204f"&gt;their frustrations on Medium&lt;/a&gt;. I highly recommend you read it. One
of the community managers posted a &lt;a href="https://jericson.github.io/2018/10/24/lost_trust.html"&gt;response on their own blog&lt;/a&gt; too.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://meta.stackexchange.com/a/317264/186281"&gt;"super-official &lt;em&gt;almost&lt;/em&gt; response"&lt;/a&gt; was posted even later. This was more than 10 days after the &lt;a href="https://meta.stackexchange.com/q/316934/186281"&gt;original incident&lt;/a&gt;. It
took half a month for a first draft of a "moderator social media guidelines" post to be made in the private Stack Moderators Team.
That post consisted of bullet points on how a moderator should behave on social media. I replied to that post with this&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am underwhelmed by this response. The event that led to this post and recent discussions around Stack Exchange (and the broader
internet) wasn't due to a moderator's bad behavior. Moderators engaged a user on Twitter following the bullets in this post, and
yet stuff still exploded in everyone's face. From my point of view, &lt;em&gt;this&lt;/em&gt; post is so far down the list of responses that I was
hoping to see from Stack Exchange that I'm feeling insulted.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was asked to hold my judgment until the final draft was posted. That took place in December - two months after the incident. It was
changed from "Social media guidelines" to a "community emergency process". These four bullets were provided:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Introduce yourself and if necessary, your role as moderator of a SO/SE site.&lt;/li&gt;
&lt;li&gt;Offer to help with the situation, and be very respectful if someone declines your assistance. Sometimes, people just want to vent, and the best thing we can do to help is to give them space.&lt;/li&gt;
&lt;li&gt;Be aware of the volatile nature of online discussions; if the path to constructive discourse becomes blurred, it's often best to disengage.&lt;/li&gt;
&lt;li&gt;Keep your interactions with others, concerning SO/SE, as clear and as kind as possible. If things begin to get out of hand, please disengage and let us know about it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, do exactly what the moderator did initially on Twitter which resulted in the threat of being removed.&lt;/p&gt;
&lt;h2 id="communication"&gt;Communication&lt;a class="headerlink" href="#communication" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Stack Overflow is slowly isolating itself from the community. There have been multiple comments scattered around the network
saying the employees don't want to engage on any meta. There are community managers that are feeling hated because of complaints
users have made. Users are taking out their anger of being ignored on posts talking about new or unrelated features. In turn,
the employees engage just a little bit less. Lines are being drawn. I see it as a moderator. I see it as a user. Very slowly
the community is trusting the company less and less.&lt;/p&gt;
&lt;p&gt;Everything is becoming "us" vs. "them". There is "the company" vs. "the users". Blog posts, comments, meta discussions also appear
to be driving a wedge between "the users" and making it "new users" vs. "established users". In the blog post announcing
&lt;a href="https://stackoverflow.blog/2019/03/28/the-next-ceo-of-stack-overflow/"&gt;the search for a new Stack Overflow CEO&lt;/a&gt;, this comment was made by the current CEO:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One thing I’m very concerned about, as we try to educate the next generation of developers, and, importantly, get more
diversity and inclusiveness in that new generation, is what obstacles we’re putting up for people as they try to learn programming.
In many ways Stack Overflow’s specific rules for what is permitted and what is not are obstacles, but an even bigger problem is
rudeness, snark, or condescension that newcomers often see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The underlying sentiment - improving inclusiveness and diversity - is great. I'm all for that. The rest of it, though, is a dig
at the established community in the same way that the Welcoming blog post was. Stack Overflow's high quality standards are the
problem. It makes the community seem rude and abusive. You should stop closing those questions, stop down voting new users, and
just be nice. It doesn't say that directly, but that's how &lt;a href="https://meta.stackoverflow.com/q/381927/189134"&gt;existing members&lt;/a&gt; are seeing it. Read under &lt;a href="https://meta.stackoverflow.com/a/381935/189134"&gt;hairboat's answer&lt;/a&gt;
to see some of the simmering feelings of &lt;em&gt;high&lt;/em&gt; reputation users.&lt;/p&gt;
&lt;p&gt;The idea of trust between users and the company is brought up in the comments. This is just another example, in a long list,
where the community and the company are butting heads. Something happens that the community doesn't like - reacting to incidents off
site, focusing on features no one asked for, not explaining why these new features &lt;em&gt;need&lt;/em&gt; to be done, comments are made
by one side that makes the other seem unflattering - and another round of not trusting the company starts again.&lt;/p&gt;
&lt;p&gt;The company has had a decade of experience with this community. It's grown, shrunk, and grown again. For most of that time, there has
been fairly open communication and trust. I am afraid that trust has eroded over the last few years and can't be recovered.&lt;/p&gt;
&lt;h2 id="what-can-be-done"&gt;What can be done?&lt;a class="headerlink" href="#what-can-be-done" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The company wants to focus on areas that can bring in more money. In my &lt;a href="https://andrewwegner.com/stack-overflows-problem-feedback-from-an-experienced-user.html"&gt;previous post&lt;/a&gt; I quoted the President and Chief Technology Officer
of the company.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I appreciate that there are a lot of issues on Stack Overflow that need to be addressed, and maybe we haven't been
responding to them as quickly as we should. But Stack Overflow Q&amp;amp;A is a big, established product, most of the problems left are
hard, and we can't let maintenance become the only thing we work on or we'll just slowly run out of money and go out of
business. We are trying to both maintain Q&amp;amp;A and solve new problems for developers and reach new audiences. The latter is hard,
and maybe we'll fail on a lot of our ideas, but we're not going to stop trying. – David Fullerton May 17 at 21:10&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I bemoaned that this sounded that Q&amp;amp;A was feature frozen. It's been nearly two years since that time. I can't remember a new feature that
was introduced into Q&amp;amp;A that helped the community maintain high quality posts. There was a new wizard introduced for new users that
is supposed to help. A quick look at the review queue numbers on Stack Overflow shows that they are still stable at the same point it
was two years ago.&lt;/p&gt;
&lt;p&gt;My suggestion as a user, a moderator and someone interested in see Stack Overflow remain successful, is to focus on helping to manage
the quality of your content. Users have been asking &lt;em&gt;for years&lt;/em&gt; to be able to better handle poor content. They've asked for tools (both
system tools and moderator tools). There have been projects started, stopped, restarted, and stopped again that are supposed to
improve quality. Community tools have been built to help deal with quality problems. &lt;em&gt;Use some of this!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Stack Overflow has a data science team. Work with the community directly to help figure out ways to prevent low quality content from
ever getting posted. Force users - all users - to post higher quality content. Work with the communities that have developed automated
tools. Run it with larger data sets. Even if Stack Overflow has to be more conservative than the community tool, if you can prevent
&lt;em&gt;some&lt;/em&gt; of the low quality content from making it to the site you have a victory.&lt;/p&gt;
&lt;p&gt;Obviously the company can't ignore the areas that bring in revenue, but it's becoming increasingly clear that the community is
much less forgiving than they used to be. Continued communication blunders will not help with anything.&lt;/p&gt;
&lt;h2 id="where-to-from-here"&gt;Where to from here?&lt;a class="headerlink" href="#where-to-from-here" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I ended my last post with this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I want Stack Overflow to continue to grow. I also want Stack Overflow to have high quality content. I think my experience
and the experience of others can help build the features to accomplish this. We just need Stack Overflow to refocus on the
Q&amp;amp;A portion of their network again.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think that holds true today, just as it did 18 months ago. The aspect of the site that draws users in is Q&amp;amp;A. Make it better. Make
the content better. Give users tools to make it better. With all of this, I believe, the "welcoming" aspect will improve. Let the system
handle the low quality stuff automatically. Eliminate the need for users to ask basic questions or remind users to post their code. Let
the system be "the bad guy", and let users interact and &lt;em&gt;help&lt;/em&gt; one another.&lt;/p&gt;
&lt;p&gt;We'll see how everything looks in 18 months. In the meantime, I'll be here, cleaning up the low quality content and prodding the
company to provide improvements to Q&amp;amp;A.&lt;/p&gt;</content><category term="Stack Exchange"></category></entry><entry><title>Upgrading the home network to use Ubiquiti products</title><link href="https://andrewwegner.com/ubiquiti-home-network.html" rel="alternate"></link><published>2019-03-13T11:30:00-05:00</published><updated>2019-03-13T11:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-03-13:/ubiquiti-home-network.html</id><summary type="html">&lt;p&gt;My home network received a major upgrade. This post covers the new hardware and impressions a month after the upgrade.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="routers-past"&gt;Routers past&lt;a class="headerlink" href="#routers-past" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am not known for being gentle with routers at my house. I have pushed many consumer
grade routers to their limits and ended up replacing them for newer models or
competing models. My most recent model was an &lt;a href="https://www.newegg.com/Product/Product.aspx?Item=N82E16833320115"&gt;ASUS RT-AC66U&lt;/a&gt;. I bought this
in 2015. It is one of the longer surviving routers in the house.&lt;/p&gt;
&lt;p&gt;Since I started &lt;a href="https://andrewwegner.com/how-i-found-an-awesome-remote-only-job.html"&gt;working from home though&lt;/a&gt;, I've been noticing more problems.
These include randomly dropping all wireless connections, randomly losing connection
to the cable modem and frequently needing reboots to fix these problems. The issue
that finally made me start looking for another replacement was when the entire
router would reboot when a new wireless device connected to the network.&lt;/p&gt;
&lt;p&gt;This was especially obnoxious when family members would come home and their phones
would reconnect to the home network. On more than one occasion a work call was
dropped, a college course interrupted or a review session with coworkers disconnected.&lt;/p&gt;
&lt;p&gt;I've also found myself adding smart home "things" to my house in the past few years.
I'd told myself that I didn't need smart plugs, smart lights, voice assistants,
and the like, but I received a free voice assistant at some point. I set it up and
the family got hooked. One voice assistant became two then more. I attached
smart plugs to Christmas lights "as an experiment" and found it worked way
better than I expected. Christmas ended and the plugs were re-purposed. I brought
in smart lights and out fitted my office with those. I have more, but haven't yet
expanded to other rooms. It's coming though.&lt;/p&gt;
&lt;p&gt;In short, I have more devices than ever connected to the network and the wireless
router I had didn't seem up to the task of handling all of it.&lt;/p&gt;
&lt;p&gt;It was time for an upgrade. I didn't want just another router that I'd have to
replace in a few years though. I wanted something high quality and that could
handle anything I through at it.&lt;/p&gt;
&lt;h2 id="enter-ubiquti"&gt;Enter Ubiquti&lt;a class="headerlink" href="#enter-ubiquti" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I don't remember what brought [Ubiquiti][ubiquiti] to my attention years ago, but I
was immediately impressed with the hardware, the reviews and the price point. It
is not a home router, but it's also not a five figure price.&lt;/p&gt;
&lt;p&gt;I did some research I what I'd need in the house. I needed to be able to support
several wired devices, even more wireless ones (computers, phones, tablets, and
home automation devices). I wanted to have a guest network like the previous ASUS,
so that I could easily give visitors access to the internet without giving them
access to everything on the network. I also wanted to segregate all of those
smart devices to their own network.&lt;/p&gt;
&lt;p&gt;I am trained as an information security professional. I understand the risks that
all of these devices can add. It's a lot of little mini-computers on the network.
I don't want an outlet plug compromising my house. I also don't have top secret
data, so a little risk for the sake of convenience is ok to me. If I could
put these devices on a network that is seperate from both the main network and
the guest network, that'd be good for my purposes.&lt;/p&gt;
&lt;h2 id="ubiquiti-devices"&gt;Ubiquiti Devices&lt;a class="headerlink" href="#ubiquiti-devices" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After a lot of research on the &lt;a href="https://www.ui.com/products/#default"&gt;devices Ubiquiti offers&lt;/a&gt;, I picked out the
ones that would be used. I'd be using the UniFi branded products instead of the
Edgemax branded products. From everything I was able to find, the hardware between
the two brands is how they are managed.&lt;/p&gt;
&lt;p&gt;I am &lt;em&gt;not&lt;/em&gt; a network engineer. I work with some great ones at work and they
speak another technical language entirely. As useful as it'd be to know more
in that area for work, that's not a goal I wanted to pursue for a home project.
I went with UniFi because of it's easier management with the UniFi controller.&lt;/p&gt;
&lt;p&gt;I went with the following devices&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ui.com/unifi-routing/usg/"&gt;UniFi Security Gateway&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ui.com/unifi-switching/unifi-switch-2448/"&gt;UniFi 24 port switch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ui.com/unifi-switching/unifi-switch-poe/"&gt;UniFi 24 port switch with PoE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ui.com/unifi/unifi-ap-ac-pro/"&gt;UniFi AP AC Pro&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ui.com/unifi/unifi-cloud-key/"&gt;UniFi Cloud Key (gen 1)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="security-gateway"&gt;Security Gateway&lt;a class="headerlink" href="#security-gateway" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://www.ui.com/unifi-routing/usg/"&gt;security gateway&lt;/a&gt; is the router the handles the network. It's much
smaller than previous routers I've had. The purpose of this product is to provide
routing, not be the device everything in the network plugs into. That's the switches.&lt;/p&gt;
&lt;p&gt;The cable modem plugs into WAN1 and the switch plugs into LAN1. That's it. Nice and simple.&lt;/p&gt;
&lt;h3 id="24-port-switch"&gt;24 port switch&lt;a class="headerlink" href="#24-port-switch" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://www.ui.com/unifi-switching/unifi-switch-2448/"&gt;24 port switch&lt;/a&gt; is the first switch I bought for this project. It was a mistake. The mistake
was mine though. The Access points are powered via power over ethernet. This switch doesn't
have that. The best I can come up with for how this mistake was made is that I had both the
PoE and non-PoE versions open when I went to order and put the wrong one in my cart.&lt;/p&gt;
&lt;p&gt;Whoops.&lt;/p&gt;
&lt;p&gt;That said, it ended up being a happy mistake. I have more wired devices than I realized. Previously,
I had a router and a couple small switches scattered around the house to allow multiple devices
to be plugged in. If I'd just ordered the single 24 Port PoE switch, I'd have used well over half
of the ports immediately between the existing devices and the new access points.&lt;/p&gt;
&lt;p&gt;My solution was to keep this switch, and only plug in the wired and non-PoE devices into
this switch. Anything that needed to be powered via PoE would go into the PoE switch.&lt;/p&gt;
&lt;h3 id="24-port-switch-poe"&gt;24 port switch PoE&lt;a class="headerlink" href="#24-port-switch-poe" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://www.ui.com/unifi-switching/unifi-switch-poe/"&gt;24 port PoE device&lt;/a&gt; is slightly deeper than the non-PoE version. It also has
case fans. I am using this device to power the access points I purchased. It was originally
going to power the cloud key too.&lt;/p&gt;
&lt;h3 id="access-points"&gt;Access Points&lt;a class="headerlink" href="#access-points" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I bought a 5 pack of &lt;a href="https://www.ui.com/unifi/unifi-ap-ac-pro/"&gt;AC Pro access points&lt;/a&gt;. As I mentioned, these are
powered via power over ethernet. That means I needed to run wires to locations around
the house. That's an exercise I don't want to repeat.&lt;/p&gt;
&lt;p&gt;I've put up three of the five access points initially to see how much coverage
they provide to the house. So far, I am pleased with how they are performing. I'm
not sure where the last two will go yet, but I'll find a spot eventually.&lt;/p&gt;
&lt;p&gt;These access points are handling the three networks without any issues. The
trust home devices are on one network, the smart home devices are on another, and
a third guest network is used occasionally with no issues.&lt;/p&gt;
&lt;h3 id="cloud-key-gen-1"&gt;Cloud Key (Gen 1)&lt;a class="headerlink" href="#cloud-key-gen-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is the device I wish I'd researched a little more before purchasing. I see
it's purpose, but I don't need it. I can run the UniFi controller on my Ubuntu
server. It took a little bit of work to get it installed because of port
conflicts with GitLab and poor error messages, but once that was figured out, it
works just fine.&lt;/p&gt;
&lt;p&gt;My other complaint about the first generation cloud key is that it just hangs from
the switch. The second generation is mountable (and performs more tasks for other)
Ubiquiti products. I purchased the first generation though and don't think I'll
ever use it.&lt;/p&gt;
&lt;h2 id="review"&gt;Review&lt;a class="headerlink" href="#review" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The set up of all devices is very simple. Plug it in, set up your management
account on the UniFi controller, adopt the devices and you are set up. A little
configuration is needed to set up wireless networks, but that didn't take a lot
of work either.&lt;/p&gt;
&lt;p&gt;From the controller, updating the firmware of all devices is simple. If there
is an update, the controller lets you know and you click "update". Five minutes later,
the device reboots with the new firmware and everything works. I was able to update
everything within thirty minutes.&lt;/p&gt;
&lt;p&gt;Be aware of which devices are plugged into what. You don't want to reboot an upstream
device before the down stream ones are finished. For that reason, I updated the
access points first, then the switches, then the security gateway.&lt;/p&gt;
&lt;p&gt;Since everything was set up, I haven't been disconnected from the cable modem once.
I haven't had the entire wireless network shutdown when a family member came home.
I haven't had any spots without coverage in the house.&lt;/p&gt;
&lt;p&gt;In fact, I have a brand new first world problem. A couple of the smart plugs I
have can only be configured on the 2.4Ghz band. The three access points I have cover
the entire house in a 5Ghz signal. To configure these plugs, I need to step out
into the yard to get outside of the 5Ghz range.&lt;/p&gt;
&lt;p&gt;The amount of details available in the UniFi controller is amazing. I can see
signal strength of all wireless network devices. I can see nearby wireless networks
that I couldn't see with the previous router. I can see traffic patterns (I watch
a lot of video services). I even have the intrusion prevention system enabled
because my internet speed isn't fast enough to be impacted by the load this puts
on the security gateway. There is one persistent IP in Europe that likes to scan
me. Hi Netherlands! I see you!&lt;/p&gt;
&lt;h2 id="whats-next"&gt;What's next?&lt;a class="headerlink" href="#whats-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;So far, everything I've thrown at this new set up has handled it like it was nothing.
That makes sense. These are business class products and are designed to handle way
more than I should be able to throw at it as a home user. I like a challenge.&lt;/p&gt;
&lt;p&gt;What's next though? I'd like to get even more information from the devices. A true
monitoring solution for the entire home network or at the least the network equipment
and the server. I've been investigating the &lt;a href="https://www.influxdata.com/time-series-platform/"&gt;TICK stack&lt;/a&gt; for gathering metrics.
I'll see if I can set something like that up in a way that I like.&lt;/p&gt;
&lt;p&gt;I'd also like to expand wireless coverage out to the shed. I'm not sure if I can
do that with the access points though. I don't want to run an ethernet cord out
there (and bury it). That's really far down on my wish list though.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Fixing XPS 13 (Ubuntu) and Thunder Bolt 16 issue after BIOS update</title><link href="https://andrewwegner.com/xps-tb16-bios-fix.html" rel="alternate"></link><published>2019-01-31T10:30:00-06:00</published><updated>2019-01-31T10:30:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-01-31:/xps-tb16-bios-fix.html</id><summary type="html">&lt;p&gt;Updating BIOS using a Dell provided update broke how my Thunder Bolt dock and XPS interacted. This is how I fixed it.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="what-happened"&gt;What happened?&lt;a class="headerlink" href="#what-happened" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In November of 2018, Dell released a &lt;a href="https://www.dell.com/support/home/us/en/04/drivers/driversdetails?driverId=T7XJF&amp;amp;osCode=WT64A&amp;amp;productCode=xps-13-9360-laptop"&gt;BIOS update&lt;/a&gt; (version 2.10.0) for my XPS 13 9360 running Ubuntu 18.04.1. Among the enhancements
this updated added was:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Enhanced the stability of Linux operating system&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="BIOS Update available" src="https://andrewwegner.com/images/update-available.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've been putting off updating due to squeamishness involving touching the BIOS. If it goes poorly, it could make my day really
stressful.&lt;/p&gt;
&lt;p&gt;It's currently -50 with the windchill outside. Schools are closed. Businesses are closed. Even the Post Office has said they aren't
delivering mail because it's so cold. This sounds like the perfect time to perform an update.&lt;/p&gt;
&lt;p&gt;There was my mistake...&lt;/p&gt;
&lt;p&gt;After installing the update and rebooting the machine, the XPS froze as the Ubuntu login screen was loading. There was only a
mouse cursor on an otherwise black screen. The mouse didn't respond to input from the touch pad or from a USB mouse. The keyboard
didn't appear to be responding either. The external monitors weren't receiving a signal and, finally, an attempt to SSH into the laptop failed.&lt;/p&gt;
&lt;h2 id="troubleshooting"&gt;Troubleshooting&lt;a class="headerlink" href="#troubleshooting" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The laptop was entirely unresponsive. First step: "Did you reboot it?" Yes. I had to hold down the power button so it wasn't a clean reboot.
The exact same symptoms occurred: Black screen with only a mouse cursor right before the login page loads. Doesn't respond to any input.&lt;/p&gt;
&lt;p&gt;Next, I unplugged everything. The laptop is plugged into a Thunder Bolt 16 docking station so that I can utilize two external
monitors. I also have Logitech headphones plugged into one of the USB ports and an external keyboard and mouse. Then I rebooted again by
holding down the power button.&lt;/p&gt;
&lt;p&gt;This time, everything worked. The login screen popped up, the machine responded to input events and everything was fine. Victory?&lt;/p&gt;
&lt;p&gt;Nope.&lt;/p&gt;
&lt;p&gt;I started plugging stuff back in: Keyboard, then mouse, then headphones. No problems. Then I plugged in the Thunder Bolt docking station. A few
seconds later, the screen went black and stopped responding.&lt;/p&gt;
&lt;p&gt;After a few reboots and a few tests of plugging in the dock, I realized that it was the dock causing the laptop issues. When it was plugged into
the wall adapter, it worked fine. The docking station was causing the problem. This isn't great, but at least the laptop works.&lt;/p&gt;
&lt;h2 id="rolling-back-bios"&gt;Rolling back BIOS&lt;a class="headerlink" href="#rolling-back-bios" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point, it was time to roll back the BIOS. An update broke it, the original version should fix it...hopefully. The first step was
finding the old version - 2.9.0. Fortunately, Dell's support is helpful in this one single way. There is a page for old drivers and I quickly
found the &lt;a href="https://www.dell.com/support/home/us/en/19/drivers/driversdetails?driverId=RCKDK&amp;amp;osCode=WT64A&amp;amp;productCode=xps-13-9360-laptop"&gt;System BIOS version 2.9.0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To perform the roll back, there are only a few steps you need to do.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get a USB drive that is formatted with FAT32&lt;/li&gt;
&lt;li&gt;Copy the BIOS file to the drive and leave it plugged into the XPS&lt;/li&gt;
&lt;li&gt;Make sure the XPS is plugged in (with the wall adapter, not the Thunder Bolt)&lt;/li&gt;
&lt;li&gt;Restart the machine&lt;/li&gt;
&lt;li&gt;At the Dell splash screen press &lt;kbd class="light"&gt;F12&lt;/kbd&gt; to open the One Time Boot Menu&lt;/li&gt;
&lt;li&gt;Select "BIOS Flash Update"&lt;/li&gt;
&lt;li&gt;Select the file you downloaded on the USB drive&lt;/li&gt;
&lt;li&gt;Wait patiently as BIOS is flashed again&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When the flashing was done, I was back to BIOS 2.9.0. Ubuntu restarted...and the same issue occurred. Plugging in the Thunder Bolt made the
laptop seize.&lt;/p&gt;
&lt;h2 id="dell-support"&gt;Dell Support&lt;a class="headerlink" href="#dell-support" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the BIOS reflash a failure, I turned to Dell support. I didn't have high expectations going in to this. Yet, somehow, I came out even
more disappointed. Through two phone calls, I was informed that&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dell doesn't support Ubuntu&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is despite that fact that the laptop came with Ubuntu installed by Dell &lt;em&gt;and&lt;/em&gt; the BIOS update was from Dell. Since my operating system
was not Windows, I couldn't get any support.&lt;/p&gt;
&lt;p&gt;I turned to the Dell Community forums. After some private back and forth with a community moderator (and Dell Social Media Support employee), I
was given this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;At this point, I do not think that the TB16 or XPS hardware are at fault here. I think that the BIOS update broke the laptop USB Type-C.
Not physically, but in the operating system. So even though you backflashed, the issue remains.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was encouraged to test the Thunder Bolt with another Dell laptop. It's fortunate that my wife has a Dell for her work. Without it, I
wouldn't have been able to get this message when attempting to flash the Thunder Bolt firmware I was pointed to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Error: Collecting Dock Information failed&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I never heard back from Dell support after providing them with a screenshot of that error.&lt;/p&gt;
&lt;p&gt;I was on my own.&lt;/p&gt;
&lt;h2 id="inspiration"&gt;Inspiration&lt;a class="headerlink" href="#inspiration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At first glance, the quote from the forum moderator above doesn't make much sense. How can the BIOS update break the USB Type-C port in the operating system?
How can it not be fixed by going to a previous version?&lt;/p&gt;
&lt;p&gt;Then it hit me: There was more to this BIOS update. A day earlier I'd updated the kernel and hadn't rebooted yet and forgot about it.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ uname -r
&lt;span class="m"&gt;4&lt;/span&gt;.15.0-44-generic
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Working with that, the phrase "Thunder Bolt" and Google, I stumbled across a post on &lt;a href="https://askubuntu.com/a/1113954/183377"&gt;Stack Exchange&lt;/a&gt; with the same issue. Of course.
Why didn't I start there? I had been chasing the wrong thing. BIOS wasn't the cause, it was just the reason for the system reboot.&lt;/p&gt;
&lt;h2 id="fix"&gt;Fix&lt;a class="headerlink" href="#fix" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The fix involved going back to the previous kernel. I didn't follow the &lt;a href="https://askubuntu.com/a/1113954/183377"&gt;Ask Ubuntu post&lt;/a&gt; exactly. First, I edited by grub configuration to display the
grub menu. This is at &lt;code&gt;/etc/default/grub&lt;/code&gt;. I changed the &lt;code&gt;GRUB_TIMEOUT&lt;/code&gt; value to &lt;code&gt;-1&lt;/code&gt; and uncommented &lt;code&gt;GRUB_HIDDEN_TIMEOUT&lt;/code&gt;. After saving that config file
I ran &lt;code&gt;sudo update-grub&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Then I restarted.&lt;/p&gt;
&lt;p&gt;When the grub menu appeared, I selected "Advanced Boot Options" and then selected the &lt;code&gt;4.15.0-43-generic&lt;/code&gt; kernel and continued the boot.&lt;/p&gt;
&lt;p&gt;Ubuntu loaded. It stayed responsive when I swapped from the wall adapter to the Thunder Bolt dock.&lt;/p&gt;
&lt;p&gt;Victory!&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the XPS working again, I have decided to stay on BIOS 2.9.0 for now. I also haven't re-updated the kernel to the &lt;code&gt;-44&lt;/code&gt; version. In fact, I purged that one
for the time being with this command:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get purge -f linux-image-4.15.0-44-generic&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is a &lt;a href="https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1813663"&gt;known bug&lt;/a&gt; with 4.15.0-44 and a fix is being worked on. It also seems to impact more than just Dell products. It looks like
4.15.0-45 will fix the issue. We'll see.&lt;/p&gt;
&lt;p&gt;Also, Dell support is less helpful than I thought it would be. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Review of Sanic - An Asynchronous Web Framework for Pythonistas Udemy course</title><link href="https://andrewwegner.com/sanic-webframework-review.html" rel="alternate"></link><published>2019-01-23T10:00:00-06:00</published><updated>2019-01-23T10:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2019-01-23:/sanic-webframework-review.html</id><summary type="html">&lt;p&gt;My review of the Sanic Web Framework fro Pythonistas course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At work we are starting to write version 2 of our API. As part of this new version, we're migrating from PHP to Python (hooray!). There are various technical
reasons for this, but I am excited. My technical skills are much (&lt;em&gt;much&lt;/em&gt;) better in Python. Part of this migration involved decided the framework we'd be using
and after several internal discussions, we settled on &lt;a href="https://sanic.readthedocs.io/en/latest/"&gt;Sanic&lt;/a&gt;. The first line of the documentation reads:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Sanic is a Flask-like Python 3.5+ web server that’s written to go fast.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Great! I used Flask at my previous job. To be clear, Sanic is not &lt;em&gt;based on&lt;/em&gt; Flask, but it's API is &lt;em&gt;Flask-like&lt;/em&gt;. Good enjoy to start with. With the framework
set, and previous experience with a similar framework, I wanted to go through how Sanic works.&lt;/p&gt;
&lt;p&gt;I turned to Udemy and the &lt;a href="https://www.udemy.com/sanic-an-asynchronous-web-framework-for-pythonistas/"&gt;Sanic - an asynchronous web framework for Pythonistas&lt;/a&gt; course, created by Szabó Dániel Ernő.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The course is roughly two hours long and consists of 20 tutorial videos. Each one is less than 10 minutes long. It covers a wide range of features available in
Sanic. The instructor made their code available on &lt;a href="https://github.com/r3ap3rpy/sanic-web-framework"&gt;GitHub&lt;/a&gt;. I never actually used the GitHub repository though. Instead, I followed along with the brief
tutorials.&lt;/p&gt;
&lt;p&gt;For me, this speaks to the instructor's ability to keep the lessons and code short and simple yet effectively show how a single feature works. By making the
code easy enough to type and follow along, the lesson was more effective because I was &lt;em&gt;doing&lt;/em&gt; instead of just reading code.&lt;/p&gt;
&lt;p&gt;The first few lessons are a little rough, because the recordings stutter like the machine that was doing the recording wasn't powerful enough. After 5-6 lessons
this clears up. It's a minor thing but I do feel it's something that should have been fixed before the course was posted. One other annoyance was that each
lesson contains the same boiler plate code:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sanic&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sanic&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sanic&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"__main__"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"localhost"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The lesson code will then go after the &lt;code&gt;app&lt;/code&gt; variable is defined. The problem with this boiler plate code is that the instructor types it out every single lesson.
Again, this is minor and it makes each lesson self contained, but I think having this code already written and adding in the important, lesson specific code,
would have made the lesson more succinct. It also would have prevented a few typos that the instructor made and had to spend time correcting.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The lessons themselves were effective at teaching a single Sanic feature. Some were a little short and almost all of them lacked any complexity you'd find in
a real application, but they were quick ways to show how a feature worked and didn't spend a lot of time doing more than that. Lessons covered a variety of
things you'd expect a web framework to handle:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Request Parameters&lt;/li&gt;
&lt;li&gt;Aliases&lt;/li&gt;
&lt;li&gt;Listeners&lt;/li&gt;
&lt;li&gt;Configuration&lt;/li&gt;
&lt;li&gt;Middleware&lt;/li&gt;
&lt;li&gt;Cookies&lt;/li&gt;
&lt;li&gt;Streaming files&lt;/li&gt;
&lt;li&gt;Logging&lt;/li&gt;
&lt;li&gt;Class methodology&lt;/li&gt;
&lt;li&gt;Blueprints&lt;/li&gt;
&lt;li&gt;Request Types&lt;/li&gt;
&lt;li&gt;Error handling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ironically, in the error handling lesson, the instructor had an error in their code. This is great, because it helps to see how to troubleshoot errors that Sanic
can throw. My issue is that the instructor left the time where he's looking at another monitor (probably reading documentation) in the video. I feel this time
could have been removed and the troubleshooting steps still been effectively shown.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Overall, I was happy with this course. It's about two hours long and does a good job of showing various aspects of Sanic. I don't recall ever being pointed
to the documentation, which is a little surprising, but it was easy enough to find. The course provides a good foundation of knowing what Sanic can handle. As
of the time of this post, Udemy says there have been ten students that signed up for the course. That is low and the lack of Q&amp;amp;A is also a bit concerning. I
don't know how responsive the instructor is to student questions.&lt;/p&gt;
&lt;p&gt;If you have a few hours (and dollars, during a Udemy sale) to spare and wish to learn some basics about Sanic, this is a good course to take. If not, the
&lt;a href="https://github.com/r3ap3rpy/sanic-web-framework"&gt;GitHub repository&lt;/a&gt; contains all of the lessons you go over.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-LYP0VLF7"&gt;&lt;img alt="Sanic - An Asynchronous Web Framework for Pythonistas Completion" src="https://andrewwegner.com/images/udemy-sanic.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Autobuild and Deploy this Pelican Blog</title><link href="https://andrewwegner.com/autobuild-pelican-blog.html" rel="alternate"></link><published>2018-11-15T08:30:00-06:00</published><updated>2018-11-15T08:30:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-11-15:/autobuild-pelican-blog.html</id><summary type="html">&lt;p&gt;It's time to automate the deployment of this Pelican blog. This is a walkthrough of how I set it up.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Several years ago, I &lt;a href="https://andrewwegner.com/why-i-moved-from-wordpress-to-pelican.html"&gt;migrated from Wordpress to Pelican&lt;/a&gt; for this blog. I set it up to &lt;a href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;run on GitHub Pages&lt;/a&gt;. I've
been happy with that set up. I can modify my template as needed (which is infrequent), I can publish a post relatively easily
and can write the entire post in MarkDown.&lt;/p&gt;
&lt;p&gt;There was room for improvement though. The way I originally set it up required me to push to two different repositories
every time I wrote a new blog post. Once for the MarkDown file and images, and once for the generated HTML. I wanted to
eliminate the need for me to perform the second step.&lt;/p&gt;
&lt;h2 id="previously-on-this-blog"&gt;Previously on this blog&lt;a class="headerlink" href="#previously-on-this-blog" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Previously, this blog was broken into two repositories. One was the "source" and one was the generated HTML. In my development
environment, there was also my local theme and a clone of the &lt;a href="https://github.com/getpelican/pelican-plugins"&gt;Pelican plugins repository&lt;/a&gt;, but I never formalized these
into curated repositories. The generated HTML was a submodule of the source repository and was placed in the &lt;code&gt;output&lt;/code&gt;
directory. I used the following command to generate HTML each time I created a new post&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;pelican content --output output --settings publishconf.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using my settings, this would generate my HTML in the output directory. After this was generated, I'd push the content repository
which had a &lt;code&gt;.gitignore&lt;/code&gt; rule to ignore the &lt;code&gt;output&lt;/code&gt; directory, and then I'd push the output directory.&lt;/p&gt;
&lt;p&gt;With all of this, I had a &lt;code&gt;requirements.txt&lt;/code&gt; document so that I could theoretically generate a post from anywhere, but I failed to keep
that updated an in sync with my development environment. On more than one occasion, I tried to write a post on my laptop (not my usual
development machine) and failed due to the mismatched dependencies, missing theme and missing plugins.&lt;/p&gt;
&lt;p&gt;My development environment was fragile and couldn't be replicated with what I'd posted on GitHub. I'd also forgotten to push the &lt;code&gt;output&lt;/code&gt;
directory on more than one occasion, which was annoying.&lt;/p&gt;
&lt;p&gt;I set out to change all of this with the following goals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only a single push to GitHub would generate and deploy the HTML for this blog&lt;/li&gt;
&lt;li&gt;I should be able to clone the appropriate repositories and generate content locally in an emergency&lt;/li&gt;
&lt;li&gt;It'd be nice to have true separation between the content of the site (the MarkDown articles) and the source code&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="warning"&gt;Warning&lt;a class="headerlink" href="#warning" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Earlier this year, I made a &lt;a href="https://andrewwegner.com/travisci-insecure-environment-variables.html"&gt;public post about how poorly Travis CI handles secure environment variables&lt;/a&gt;. The public
&lt;a href="https://github.com/travis-ci/travis-ci/issues/9430"&gt;GitHub issue&lt;/a&gt; hasn't been worked on yet. The two issues identified still persist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Secure variables can be show via simple string manipulation from a malicious commit&lt;/li&gt;
&lt;li&gt;Secure variables are transferred to a third party if the repository is transferred&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I feel that the still need to be addressed. They are security issues.&lt;/p&gt;
&lt;p&gt;That said, I am using a Travis CI secure environment variable in my deployment script. It is the GitHub token used to push
to the repository that contains generated HTML. I have chosen to do this because I am the only one that will be committing
to the repository and will not be transferring it to a 3rd party. This is a personal site.&lt;/p&gt;
&lt;p&gt;There are alternatives if you don't like the idea of storing your token with Travis CI. I've accepted that risk, even though I
believe the issue should be fixed as soon as possible.&lt;/p&gt;
&lt;h2 id="improved-deployment"&gt;Improved Deployment&lt;a class="headerlink" href="#improved-deployment" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With my goals in place, I started with the "nice to have", because...this isn't work and I can prioritize how I want. I split my
blog into three repositories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-content"&gt;awegnergithub.github.io-content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source"&gt;awegnergithub.github.io-source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io"&gt;awegnergithub.github.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="content"&gt;Content&lt;a class="headerlink" href="#content" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-content"&gt;content repository&lt;/a&gt; is the one repository that I commit MarkDown to. This would be the repository that triggers new deployments
and would be the one that changes most frequently. Other than a single &lt;code&gt;.travis.yml&lt;/code&gt; file, the only thing in this repository would be
content that is used on the site. It'd be my MarkDown articles, associated images, and meta files (&lt;code&gt;robots.txt&lt;/code&gt;, and verification files)
but wouldn't contain any Pelican code, plugins or theme information.&lt;/p&gt;
&lt;h3 id="source"&gt;Source&lt;a class="headerlink" href="#source" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source"&gt;source repository&lt;/a&gt; is where Pelican source code lives. This repository already existed in my first iteration of the blog. I needed to
pull out the &lt;code&gt;content&lt;/code&gt; and &lt;code&gt;output&lt;/code&gt; directories and add in the theme and plugins that had only existed locally. I also updated &lt;code&gt;requirements.txt&lt;/code&gt;
to contain all of the dependencies I needed to generate the site correctly. I am pretty embarrassed to admit that I hadn't updated this file in almost
three years, except to fix a plugin that had broken.&lt;/p&gt;
&lt;p&gt;I had Pelican pinned to an old version that I hadn't used in over a year and I was missing dependencies that the Pelican plugins required. This took
a lot more time to hunt down than I expected, and it's entire my fault for not keeping this updated over the years. Fortunately, with the setup, I have
to keep this updated or the site won't generate correctly.&lt;/p&gt;
&lt;h3 id="generated-content"&gt;Generated Content&lt;a class="headerlink" href="#generated-content" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The last &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io"&gt;repository&lt;/a&gt; is the one that holds the generated HTML for this blog. This already existed and continues to serve exactly the same
purpose as before. The only difference is that the content should be pushed to this repository automatically.&lt;/p&gt;
&lt;h2 id="set-up"&gt;Set up&lt;a class="headerlink" href="#set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="github-token"&gt;GitHub Token&lt;a class="headerlink" href="#github-token" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the three repositories set up and content committed to them as appropriate, the next step is setting up the single Travis CI environment
variable we'll need. This will be the Personal Access Token used to commit to the generated content repository.&lt;/p&gt;
&lt;p&gt;To do this, navigate to GitHub, select your avatar in the upper right, and select "Settings". On the left, select "Developer settings" then
"Personal access tokens".&lt;/p&gt;
&lt;p&gt;Click "Generate new token" and enter your password as appropriate. Provide a useful description for your token and under the &lt;code&gt;repo&lt;/code&gt; scope,
select only &lt;code&gt;public_repo&lt;/code&gt;. If you are planning on committing to a private repository, you will need to select the entire &lt;code&gt;repo&lt;/code&gt; scope. Since my
generated content isn't hosted in a private repository, the &lt;code&gt;public_repo&lt;/code&gt; is enough. Select "Generate token" at the bottom.&lt;/p&gt;
&lt;p&gt;&lt;img alt="GitHub Token Selection" src="https://andrewwegner.com/images/build_blog_github_token.png"/&gt;&lt;/p&gt;
&lt;p&gt;You will be presented with your token. &lt;strong&gt;Copy this someplace, you won't be able to access this value again&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id="travis-ci-environment-variable"&gt;Travis CI Environment Variable&lt;a class="headerlink" href="#travis-ci-environment-variable" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now, this token needs to be accessible in Travis CI. Navigate to &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt; and find your &lt;code&gt;content&lt;/code&gt; repository. Under "More Options",
on the left select "Settings". Scroll down to "Environment Variables". In my &lt;code&gt;deploy.sh&lt;/code&gt; script, I use the variable &lt;code&gt;GITHUB_API_KEY&lt;/code&gt;,
so that is what I'll use here too. Enter the variable name and the token GitHub provided in the previous step. Do not change "Display value
in build log" to &lt;code&gt;true&lt;/code&gt; and press "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="GitHub Token Selection" src="https://andrewwegner.com/images/build_blog_github_envvariable.png"/&gt;&lt;/p&gt;
&lt;h3 id="deploysh"&gt;deploy.sh&lt;a class="headerlink" href="#deploysh" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next step is configuring the &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source/blob/master/deploy.sh"&gt;&lt;code&gt;deploy.sh&lt;/code&gt;&lt;/a&gt; script in the source repository. For my configuration, all that is needed is
changing the &lt;code&gt;GH_USERNAME&lt;/code&gt; variable to be the name of the user hosting the blog. Still, there is more to the script, if you
find this and wish to make changes.&lt;/p&gt;
&lt;p&gt;There are a few areas that may be important. The first is that pushes to the generated repository are done with the username "Travis CI" and
an associated Travis CI email address. Change these as you wish. I didn't want them in my name, so that I could easily pick out which commits
I did versus which ones were done automatically. The old commits in my name vs. the new automated commits look like this in GitHub.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Blog commit differences" src="https://andrewwegner.com/images/build_blog_github_commits.png"/&gt;&lt;/p&gt;
&lt;p&gt;Another important line of code is this one in the deploy script:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git push -fq https://$GH_USERNAME:$GITHUB_API_KEY@github.com/$TARGET_REPO &amp;amp;&amp;gt;/dev/null || exit $?&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This line pushes the generated site to the appropriate repository using the &lt;code&gt;GITHUB_API_KEY&lt;/code&gt; we previously generated and told
Travis CI about. It also sends all output of this command to &lt;code&gt;/dev/null&lt;/code&gt; so that the secure key won't show up in the build log. If
this isn't done, Travis CI will print out the command and may or may not properly obscure it (see my previous warning, above).&lt;/p&gt;
&lt;p&gt;The deployment ends by pinging Google and Bing with my &lt;code&gt;sitemap.xml&lt;/code&gt;. This is an automated way of telling the two search engines
that the site has been updated and they should recheck the sitemap and reindex as appropriate. It doesn't guarantee they will
crawl the site immediately, but it does let them know their is an update before their next scheduled crawl.&lt;/p&gt;
&lt;h3 id="travisyml"&gt;.travis.yml&lt;a class="headerlink" href="#travisyml" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Lastly, we need to tell Travis CI what to do when there is a commit made to the &lt;code&gt;content&lt;/code&gt; repository. The only non-content file
in this repository is &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-content/blob/master/.travis.yml"&gt;&lt;code&gt;.travis.yml&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Right now, I have it building against Python 3.5 simply because that is the version I have installed and utilize most often. There is
no reason this blog wouldn't generate against 3.6 or 3.7. I'm pretty sure all of the dependencies will also work against 2.7
right now too.&lt;/p&gt;
&lt;p&gt;It will only build when I commit to the &lt;code&gt;master&lt;/code&gt; branch. I don't use other branches right now, but if I ever do, they won't trigger a build.&lt;/p&gt;
&lt;p&gt;The important bits are in the &lt;code&gt;before_script&lt;/code&gt; and &lt;code&gt;script&lt;/code&gt; sections.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;before_script:&lt;/span&gt;
&lt;span class="c"&gt;  - git clone https://github.com/AWegnerGithub/awegnergithub.github.io-source.git source&lt;/span&gt;
&lt;span class="c"&gt;  - mkdir source/content&lt;/span&gt;
&lt;span class="c"&gt;  - rsync -av --progress ./* source/content --exclude source&lt;/span&gt;
&lt;span class="c"&gt;  - cd source&lt;/span&gt;
&lt;span class="c"&gt;  - pip install --upgrade pip&lt;/span&gt;
&lt;span class="c"&gt;  - pip install -r requirements.txt&lt;/span&gt;
&lt;span class="c"&gt;script:&lt;/span&gt;
&lt;span class="c"&gt;  - pelican content --output output --settings publishconf.py --verbose&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In &lt;code&gt;before_script&lt;/code&gt;, I clone my &lt;code&gt;source&lt;/code&gt; repository containing all my Pelican settings into the &lt;code&gt;source&lt;/code&gt; directory. Next, I add a &lt;code&gt;content&lt;/code&gt;
directory into this newly created &lt;code&gt;source&lt;/code&gt; directory. I &lt;code&gt;rsync&lt;/code&gt; my content to this directory and exclude &lt;code&gt;source&lt;/code&gt; because you can't
recursively copy a directory into itself.&lt;/p&gt;
&lt;p&gt;Then, I get my dependancies installed. I update &lt;code&gt;pip&lt;/code&gt; and install my &lt;code&gt;requirements.txt&lt;/code&gt;. Finally, I execute the same &lt;code&gt;pelican&lt;/code&gt; command I
previously used and add on the &lt;code&gt;verbose&lt;/code&gt; flag, just in case I need to troubleshoot a failed build.&lt;/p&gt;
&lt;p&gt;Deployment is done via the &lt;code&gt;deploy&lt;/code&gt; block, but all it is doing is calling my &lt;code&gt;deploy.sh&lt;/code&gt; script that I covered above.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;deploy&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;provider&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;script&lt;/span&gt;
  &lt;span class="n"&gt;skip_cleanup&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;bash&lt;/span&gt; &lt;span class="n"&gt;deploy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;sh&lt;/span&gt;
  &lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;branch&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;skip_cleanup&lt;/code&gt; is important to leave as &lt;code&gt;true&lt;/code&gt; so that the output from the &lt;code&gt;script&lt;/code&gt; block isn't cleaned up before we deploy.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This post should be the first one that is automatically deployed. I'm sure there are improvements I can and will make to my
&lt;code&gt;deploy.sh&lt;/code&gt; script or &lt;code&gt;.travis.yml&lt;/code&gt; over time, but right now I'm happy with how it works. In testings, a deployment is taking
about a minute or two from the time I push a new article. This is about how long it took previously, but now I only need to
perform a single push.&lt;/p&gt;
&lt;p&gt;I'm also happy with the split of my repositories. I was never a huge fan of having content and source code mashed together, but
it worked. Now, I can keep the two separate and easily determine where everything is. Template changes are source code, article
changes are content. If I make changes to anything other than content, I can trigger a rebuild within Travis CI with the click
of a button. If I am just adding an article, I just need to wait a few minutes for it to be built and deployed. Hooray for
automation!&lt;/p&gt;
&lt;p&gt;One other thing this split may have done is make it easier to eventually add comments to the blog. That's been a long term
goal and one that I've investigated off and on over the past three years. Since I host everything via GitHub Pages and
don't have a database, comments would probably need to be done via GitHub comments somehow. I have ideas, but haven't started
testing any of those yet. This split will make it easier, I think, when or if I investigate further.&lt;/p&gt;</content><category term="technical"></category><category term="Pelican"></category></entry><entry><title>Review of Udemy's Docker Swarm: Beginner + Advanced</title><link href="https://andrewwegner.com/docker-swarm-beginner-advanced.html" rel="alternate"></link><published>2018-10-31T15:00:00-05:00</published><updated>2018-10-31T15:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-10-31:/docker-swarm-beginner-advanced.html</id><summary type="html">&lt;p&gt;My review of the Docker Swarm: Beginner + Advanced&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I recently found short two courses about Docker on Udemy there were listed as free by the author as they get ready to update the course. This is a review of &lt;a href="https://www.udemy.com/docker-swarm-from-beginner-to-advanced-with-docker-cluster-hosting/"&gt;Docker Swarm: Beginner + Advanced&lt;/a&gt; by Luke Angel. This is the second course I've reviewed by this author. The previous course was reviewed &lt;a href="https://andrewwegner.com/docker-essentials-course.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have a very basic idea of what the container/microservice architecture is designed to solve. I've never used it professionally or on personal projects. My experience is limited to reading articles about technologies such as Docker or Kubernetes and thinking that I'd like to try those out at some point in the future.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is another hour long course and promises "foundational knowledge" by the end of the course. I disagree with this.&lt;/p&gt;
&lt;p&gt;The course starts with a lecture that is essentially an ad (almost in the form of a TV episode trailer) for the course. There are duplicate lectures, which seems to be a recurring problem based on the same issue in the previous course. Another problem that has carried over from the previous course is audio issues and inconsistencies.&lt;/p&gt;
&lt;p&gt;This is not a beginner course, despite the name. The author assumes knowledge of Docker and does not explain concepts when the "demo" starts. Speaking of the "demo", this isn't a true demonstration of the product. Instead, the author provides a ZIP file of commands that are run and outputs of those commands. In the lectures, a few elements of the output are highlighted and explained. I didn't find this to be a useful demonstration.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is a course that is several years old. It is not well put together, with multiple lectures being duplicated. Sound issues plague the presentation throughout the hour. These are all similar complaints to the &lt;a href="https://andrewwegner.com/docker-essentials-course.html"&gt;previous course&lt;/a&gt;. This course also includes a demonstration, that is really just looking at the output of an attached text file. For a demonstration, I was expecting to be able to follow along, as as this is "Beginner + Advanced", I was expecting some kind of instructions on how to set up my environment. There is none.&lt;/p&gt;
&lt;p&gt;I don't recommend this course (or the &lt;a href="https://andrewwegner.com/docker-essentials-course.html"&gt;previous one&lt;/a&gt;) because of how little "useful" content is fit into these two hours.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-X9SRS3MO"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-docker-swarm-beginner-to-advanced.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Review of Udemy's Docker and Containers: The Essentials</title><link href="https://andrewwegner.com/docker-essentials-course.html" rel="alternate"></link><published>2018-10-29T09:45:00-05:00</published><updated>2018-10-29T09:45:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-10-29:/docker-essentials-course.html</id><summary type="html">&lt;p&gt;My review of the Docker and Containers: The Essentials&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I recently found short two courses about Docker on Udemy there were listed as free by the author as they get ready to update the course. This is a review of &lt;a href="https://www.udemy.com/docker-and-containers-the-essentials/"&gt;Docker and Containers: The Essentials&lt;/a&gt; by Luke Angel. There is a third free Docker course by the same author as well.&lt;/p&gt;
&lt;p&gt;I have a very basic idea of what the container/microservice architecture is designed to solve. I've never used it professionally or on personal projects. My experience is limited to reading articles about technologies such as Docker or Kubernetes and thinking that I'd like to try those out at some point in the future.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course is a one hour, very high level, overview of what containers are. The course description mentions that there won't be detailed developer examples, and this is true. My issue with the course is that it is to high level. This course is not for anyone with even a tiny idea of what a container is.&lt;/p&gt;
&lt;p&gt;The author has basically created an hour long, narrated Power Point presentation. Even worse, there are at least two instances of lecture that are duplicated (and are pointed out in the community feedback and Q&amp;amp;A section). The narration is obviously edited from multiple microphones and the sound consistency is uneven. The author also spends lectures typing on their keyboard while talking. This is loud and distracting.&lt;/p&gt;
&lt;p&gt;Motivational speaking makes it into one of the final lectures, explaining that we are winners for being on the right track by studying Docker.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is a course that is several years old. It is not well put together, with multiple lectures being duplicated. Sound issues plague the presentation throughout the hour. The content of the course is accurate - as of a few years ago - but has areas that are outdated at this point.&lt;/p&gt;
&lt;p&gt;I don't know how long the author is spending on updating their courses, but there is a lot that needs to be done in just this one hour course.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-WEQ6PT39"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-docker-containers-essentials.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Review of Udemy's renamed The 2018 Git Complete: 45 minute crash course using Angular.</title><link href="https://andrewwegner.com/git-45-minute-crash-course.html" rel="alternate"></link><published>2018-10-01T09:45:00-05:00</published><updated>2018-10-01T09:45:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-10-01:/git-45-minute-crash-course.html</id><summary type="html">&lt;p&gt;My review of the The 2018 Git Complete: 45 minute crash course using Angular.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I use Git extensively in both my personal and professional work. I've set up &lt;a href="https://andrewwegner.com/installing-gitlab.html"&gt;GitLab&lt;/a&gt; for my personal work. I know enough about Git to be effective in a small environment with a handful of developers. I found a 30 minute crash course about Git on Udemy and decided to take it with the goal of learning a little bit more.&lt;/p&gt;
&lt;p&gt;The course I found was &lt;a href="https://www.udemy.com/git-complete-the-30-minute-crash-course-to-learning-git/"&gt;The 30 minute crash course to learning GIT&lt;/a&gt;&lt;a href="https://www.udemy.com/git-complete-the-30-minute-crash-course-to-learning-git/"&gt;2&lt;/a&gt; by Ricardo Morales.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Spoiler&lt;/em&gt;: I rated this course poorly on Udemy and since that rating, the course name has been changed to "The 2018 Git Complete: 45 minute Crash Course using Angular". The course has been updated slightly to add 15 more minutes of content since I completed the course. I have watched those as well and have not changed my rating.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When I took this course it was definitely incomplete. The very first lesson starts with "In our previous lecture...". Obviously, as the first lecture, there isn't a previous one. The 15 minutes of new content does add a few introduction lectures before this, so it's not as jarring, but the order of lectures is still out of order. There are next instances of "In the next lecture I'll cover..." and then the next lecture is something else, or "In the last lecture we talked about..." and the mentioned topic was a few lectures ago.&lt;/p&gt;
&lt;p&gt;The course is a very quick run down of common Git commands. Very quick. Most lessons are under a minute in length. What this means is that there is almost no explanation about the command you're about to learn. In most of the lectures, it's a quick reading of the command's "help" sentence, then typing the command in a terminal window to show the syntax. Unfortunately, there isn't an over all project and the order of the lectures is out of order, so it's difficult to see how a particular command actually works since there isn't any set up done ahead of time.&lt;/p&gt;
&lt;p&gt;One example of how this is poorly demonstrated is in the lecture on renaming a file. The example uses &lt;code&gt;mv&lt;/code&gt; to rename a file, talks about how it's been renamed, and then uses &lt;code&gt;mv&lt;/code&gt; to rename it back to the original name to that there "won't be problems with Git." The entire point of the lecture is to show how this should be accomplished and this lecture misses it's mark entirely.&lt;/p&gt;
&lt;p&gt;Another example is in the lessons on handling merge conflicts. This is an important topic because conflicts need to be handled when multiple developers are working on the same thing. The lecture on handling these though talks about the theory of handling it but doesn't provide a demo. The same thing is done in the topic on rebasing.&lt;/p&gt;
&lt;p&gt;Minute long lectures are not a good format. The lessons are rushed to the point where there is almost no content. Reading the "help" sentence and then showing the syntax doesn't make this a crash course. It makes it an audio/visual help document.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you know anything about Git, avoid this course. If you don't know anything about Git, I'd avoid it too, unless you prefer listening to help documents instead of reading them. There isn't any novel content here. Examples are lacking, at best. Lectures are out of order and when I took it, missing entirely. The newly renamed course to include "using Angular" is incredibly misleading. Angular is used only to generate a project that can be committed to Git. Nothing done here uses Angular other than generating that project.&lt;/p&gt;
&lt;p&gt;If you know anything about Git, there is nothing here you don't know.&lt;/p&gt;
&lt;p&gt;The completion award below reflects the name of the course before it was renamed.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-H4EVPTH5"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-git-crash-course.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Backing up Ubuntu laptop to Ubuntu Server with passwordless rsync</title><link href="https://andrewwegner.com/ubuntu-backup-rsync.html" rel="alternate"></link><published>2018-09-26T12:30:00-05:00</published><updated>2018-09-26T12:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-09-26:/ubuntu-backup-rsync.html</id><summary type="html">&lt;p&gt;The server has been running and the laptop needs to be backed up. This walks through how I did it.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The server has been running for almost nine months. It's been backing up family data and pictures from phones without any problems. Now it's time to back up the laptop because I have the space and really should make sure the stuff that isn't work related (ie. the stuff that is in the work git repositories) is also backed up.&lt;/p&gt;
&lt;p&gt;Enter &lt;a href="https://rsync.samba.org/"&gt;&lt;code&gt;rsync&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="how-to"&gt;How To&lt;a class="headerlink" href="#how-to" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My goal is to automatically back up my home directory from the laptop to the server on a daily basis. This will provide a once a day backup and if I need to do more than that in the future, it will be as easy as modifying the final cronjob that I'll use.&lt;/p&gt;
&lt;h3 id="ssh-key"&gt;SSH Key&lt;a class="headerlink" href="#ssh-key" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first step is setting up an SSH key so that I don't have to manually provide a password. I can, in the future, add restrictions on the server side as to what this particular key will be able to do too. I'm not doing that today though, because I don't open SSH to the outside world.&lt;/p&gt;
&lt;p&gt;The first thing to do is generate a new key. I already have an SSH key configured, but it has a password. On the laptop, run the following:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;ssh-keygen -t rsa -b 2048 -f ~/.ssh/laptop-rsync-key&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When asked to enter a passphrase, simply press enter and then enter again to confirm the empty passphrase.&lt;/p&gt;
&lt;p&gt;This will put &lt;code&gt;laptop-rsync-key&lt;/code&gt; and &lt;code&gt;laptop-rsync-key.pub&lt;/code&gt; in my user's &lt;code&gt;.ssh/&lt;/code&gt; directory.&lt;/p&gt;
&lt;h3 id="copy-the-public-key-to-the-server"&gt;Copy the public key to the server&lt;a class="headerlink" href="#copy-the-public-key-to-the-server" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next, we need to copy the public key that was just generated to the server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;scp&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;laptop&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rsync&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pub&lt;/span&gt; &lt;span class="n"&gt;andy&lt;/span&gt;&lt;span class="mf"&gt;@192.168.140.187&lt;/span&gt;&lt;span class="o"&gt;:~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once it's been copied, log into the server. Now you need to add this key to the &lt;code&gt;authorized_keys&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cd ~/.ssh&lt;/span&gt;
&lt;span class="err"&gt;cat laptop-rsync-key.pub &amp;gt;&amp;gt; authorized_keys&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="rsync-command"&gt;rsync command&lt;a class="headerlink" href="#rsync-command" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final command to back up my home directory is pretty simple. This command is going to tell &lt;code&gt;rsync&lt;/code&gt; to use the new SSH key that was just created, to exclude all dot files and directories, and to delete anything that has been removed on the laptop from the server. The backup will go in &lt;code&gt;~/backup/laptop&lt;/code&gt; on the server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;rsync -a -e "ssh -i ~/.ssh/laptop-rsync-key" ~/ andy@nas:~/backup/laptop --exclude=".*" --exclude=".*/" --delete&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once I confirmed this worked, I added it to my user's crontab on the laptop. It will run once a day now.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next steps&lt;a class="headerlink" href="#next-steps" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next steps I'll take be taking are to restrict the new SSH key on the server to only allow it to perform &lt;code&gt;rsync&lt;/code&gt; tasks. This can be done by slightly modifying the appropriate line in &lt;code&gt;authorized_keys&lt;/code&gt;. I'll see how this daily, single, back up works for a while. If I need to, I may change it to a rotating weekly backup. I don't forsee that right now, but I need a few weeks of seeing how this works and if the single day is good enough.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Review of Udemy's Learn DaVinci Resolve 15 from scratch</title><link href="https://andrewwegner.com/learn-davinci-resolve-15-from-scratch.html" rel="alternate"></link><published>2018-09-21T09:45:00-05:00</published><updated>2018-09-21T09:45:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-09-21:/learn-davinci-resolve-15-from-scratch.html</id><summary type="html">&lt;p&gt;My review of the Learn DaVinci Resolve 15 from scratch course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been a while since I've done a course review. I wanted to try something new in an area that seems interesting, but I'm not sure if I want to do anything with it hobby-wise. &lt;a href="https://www.udemy.com/davinci-resolve-15-from-scratch/"&gt;Learn DaVinci Resolve 15 from scratch&lt;/a&gt; caught my attention, and I found a coupon code that allowed me to take the course for free. Video editting sounds interesting and I always have the "do something with family videos" on my very distant TODO list. The course is two and a half hours long and it seems to be a basic class.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.blackmagicdesign.com/products/davinciresolve/"&gt;DaVinci Resolve&lt;/a&gt; is a very powerful, professional piece video editing software. The free version has everything I'd ever need for home use or even YouTube content. The paid version adds in multi-user collaboration features, additional 3D tools and new Resolve FX.&lt;/p&gt;
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The course focuses heavily on learning the &lt;em&gt;interface&lt;/em&gt; of DaVinci Resolve. There are a few basic tutorials and the author promises more in the future. This isn't exactly what I was expecting with a course description that includes&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Learn how to use DaVinci Resolve to create beautiful and stunning videos for the world to see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That said, it does provide a good overview of each of the tabs in DaVinci Resolve. The explanation of what each tab is used for and the very basic examples of how to use each give users an idea of how powerful DaVinci Resolve can be.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As an overview of the interface for DaVinci Resolve, this course is good. As a "learn from scratch" course, the interface overview quickly shows that two and a half hours isn't enough time to learn the software beyond the very basics. The title is a bit misleading and as someone who didn't know anything about DaVinci Resolve and only took this course because of a potentially budding hobby, I was hoping for more than a two hour tutorial on where to click in the interface to do the basics. Alas, my ignorance of the topic meant I wasn't able to judge the course accurately.&lt;/p&gt;
&lt;p&gt;I had several nit-picks with the content too. For one, I was immediately turned off to the course creator when they begged in the first lecture to not give them bad reviews. That isn't the type of thing I expect from someone who's put time and effort into creating the course. I was worried when this was done, but it turned out to be better than the begging implied.&lt;/p&gt;
&lt;p&gt;My second complaint is about how the content is presented. This is a course on &lt;em&gt;video editting&lt;/em&gt;. I expect a certain amount of care to be put into the presentation of such a topic, but the course wasn't well paced. There are very abrupt endings to several lectures. There are other lectures that have long periods of silence at the end. There are also more than a few occasions where the audio and video seem to be out of sync. You never see the instructor, but when they are presenting a new tab and say something like "Click on this tab" and then the mouse doesn't move to the tab for a few seconds it makes it hard to follow along.&lt;/p&gt;
&lt;p&gt;My final complaint is how incomplete the course is. There is one five second lecture that is just "This lecture will be uploaded very soon". The last bonus lecutre ends with "See you at the next lecture", but there are no more lectures. I realize the course was released this month, but it's incomplete. The full price of the course is $80. I expect more to be completed for that price.&lt;/p&gt;
&lt;p&gt;This is a good overview of the DaVinci Resolve environment. I understand what each tab is and how I can use them for basic edits. I feel comfortable enough to make a very simple video with some home videos now.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If you are paying for the course, you should avoid it for a while. It's not complete. There is no guarantee that additional lectures will be added and the promise of "more to come" isn't worth the full price. If you are looking for an overview of the most important buttons in DaVinci Resolve, this is a good course. If you are looking for details on what every button or menu option is going to do, this course doesn't cover that. Finally, if you are really looking to "learn DaVinci Resolve" and not "learn the DaVinci Resolve interface", this isn't the best course either. There are some tutorials here, but they are not the majority of content. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-SMH6Q3ET"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-learn-davinci-resolve-15-from-scratch.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Deploying a Flask Slack app on Google Cloud Platform</title><link href="https://andrewwegner.com/slack-app-google-cloud.html" rel="alternate"></link><published>2018-07-13T10:00:00-05:00</published><updated>2018-07-13T10:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-07-13:/slack-app-google-cloud.html</id><summary type="html">&lt;p&gt;Setup a Slack app using Flask and deploy it to Google's Cloud&lt;/p&gt;</summary><content type="html">
&lt;h2 id="background-and-goals"&gt;Background and goals&lt;a class="headerlink" href="#background-and-goals" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At work I am the software QA team lead (I haven't given myself a fancy title, but I should). As such, I spend a lot of time in JIRA tracking our bug and feature requests and in Slack working with every aspect of the company to ensure the new features work as expected and bugs as appropriately squashed. As new releases approach their release date, I start running more queries to ensure everything will be done on time.&lt;/p&gt;
&lt;p&gt;Mini-rant: I hate JIRA's UI. It's slow, clunky and makes rolling things up as I need them unnecessarily complicated.&lt;/p&gt;
&lt;p&gt;Despite that complaint, JIRA is good because it has so much flexibility on the web UI and, even better, it has an API I can use to automate the queries I use. So, that's what I did. Our last release was larger and more complex than the ones we've done in the last year (since I started). The reason for this complexity was that we needed to coordinate our updates with those of our third party billing platform. Messing up how we bill customers is a great way to get into a "discussion" with the higher ups at any company.&lt;/p&gt;
&lt;p&gt;In this release, I started poking around &lt;a href="https://developer.atlassian.com/server/jira/platform/rest-apis/"&gt;JIRA's API&lt;/a&gt;. With very little work, I'd managed to automatically run the queries that were taking a significant amount of time in the UI. I formatted these nicely and started posting the results in Slack during our update calls so that all of the developers were on the same page. From my point of view, these calls were more efficient. After the release was pushed out, I decided to see what it'd take to make these queries available to everyone via a Slack slash command.&lt;/p&gt;
&lt;p&gt;This article will talk about the process I went through, give a small tutorial for a basic command, explain how I tested locally, provide a few tips that deal with pitfalls I encountered and explain how I deployed this to Google's cloud platform.&lt;/p&gt;
&lt;h2 id="writing-the-flask-app"&gt;Writing the Flask app&lt;a class="headerlink" href="#writing-the-flask-app" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://api.slack.com/slash-commands"&gt;Slack's slash apps&lt;/a&gt; do not run on Slack's platform. When a slash command is issued, it calls a predefined URL and awaits a response. My experience is with Python. I've used both Flask and Django web frameworks. These commands will be small and don't need any of the back end batteries that Django includes, so I chose to use Flask to handle the commands I wanted to create.&lt;/p&gt;
&lt;h3 id="slash-pitfall-1-timeouts"&gt;Slash Pitfall 1: Timeouts&lt;a class="headerlink" href="#slash-pitfall-1-timeouts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first pitfall that I encountered was before I even started writing code. Slack only allows a slash command 3000 milliseconds to respond, before it times out. Unfortunately, connecting to JIRA and running the series of queries I need takes a minimum of 5 seconds. Fortunately, the workaround for this was simple: Use &lt;a href="https://api.slack.com/slash-commands#responding_response_url"&gt;delayed responses&lt;/a&gt; by responding to the initial command with a confirmation message of some kind, then perform the work and respond again using the Slack passed &lt;code&gt;response_url&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="sample-application"&gt;Sample Application&lt;a class="headerlink" href="#sample-application" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The application code below is a simple toy example. It will respond to the command "/hello-world" and then reply again after a few seconds, to simulate the delayed responses I needed.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;wraps&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thread&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;abort&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jsonify&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;SLACK_VERIFICATION_TOKEN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="c1"&gt;# Put your token here&lt;/span&gt;
&lt;span class="n"&gt;SLACK_TEAM_ID&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="c1"&gt;# Put your team ID here&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;validate_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Decorator to validate request is from slack"""&lt;/span&gt;
    &lt;span class="nd"&gt;@wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_request_validity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;is_request_valid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;abort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;check_request_validity&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_request_valid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Validate a request is from Slack"""&lt;/span&gt;
    &lt;span class="n"&gt;is_token_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'token'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;SLACK_VERIFICATION_TOKEN&lt;/span&gt;
    &lt;span class="n"&gt;is_team_id_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'team_id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;SLACK_TEAM_ID&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;is_token_valid&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;is_team_id_valid&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;slack_command_response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Respond to a Slack command"""&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'in_channel'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;response_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;'response_type'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;'text'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;response_text&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;start_command_worker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Switch to new event loop and run forever"""&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_event_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_forever&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="n"&gt;command_loop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_event_loop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;command_worker&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start_command_worker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;command_loop&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
&lt;span class="n"&gt;command_worker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hello_world&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Sends "Hello World!" to Slack after 5 seconds"""&lt;/span&gt;
    &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;slack_command_response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@app.route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/hello-world'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'POST'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nd"&gt;@validate_request&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;command_hello_world&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;command_loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call_soon_threadsafe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello_world&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'response_url'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jsonify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Waiting to greet you..."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# This is used when running locally. Gunicorn is used to run the&lt;/span&gt;
    &lt;span class="c1"&gt;# application on Google App Engine. See entrypoint in app.yaml.&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'127.0.0.1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="sample-application-walkthrough"&gt;Sample Application Walkthrough&lt;a class="headerlink" href="#sample-application-walkthrough" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The only interesting thing in the imports here is the inclusion of &lt;code&gt;asyncio&lt;/code&gt;. Since I need to fire off an immediate response and then do the "real work", I'll funnel that work into worker threads. I'm also including &lt;code&gt;functools.wraps&lt;/code&gt; because I'm making a decorator for validating a request is coming from Slack. For a single command, this type of decorator isn't needed, but I have multiple Slack slash commands in the real application. I figured it'd be helpful to show here too. This application will also need the &lt;a href="http://docs.python-requests.org/en/master/"&gt;requests&lt;/a&gt; library.&lt;/p&gt;
&lt;p&gt;Speaking of that decorator, the first function encountered in the code is &lt;code&gt;validate_request&lt;/code&gt;. This will be the decorator that ensures a request came from Slack. It calls &lt;code&gt;is_request_valid&lt;/code&gt;, which compares the passed &lt;code&gt;token&lt;/code&gt; and &lt;code&gt;team_id&lt;/code&gt; to the values we've previously saved. If they match, the request is valid. If they don't match, the request is invalid. This application is only for my team and won't be distributed elsewhere.&lt;/p&gt;
&lt;p&gt;Next up is &lt;code&gt;slack_command_response&lt;/code&gt;, which is used to send text back to Slack. It will respond to the &lt;code&gt;response_url&lt;/code&gt; parameter. This is passed by Slack and is part of the &lt;code&gt;request.form&lt;/code&gt; object Flask receives. This can be found at &lt;code&gt;request.form['response_url']&lt;/code&gt;. It will reply either &lt;code&gt;ephemeral&lt;/code&gt; (default) or &lt;code&gt;in_channel&lt;/code&gt;. The first will reply only to the user and will hide the slash command that was used. The second will reply to the entire channel and will leave the slash command visible to all.&lt;/p&gt;
&lt;p&gt;Starting the worker thread is done in &lt;code&gt;start_command_worker&lt;/code&gt; and the next three lines. This will fire up a thread that listens forever. It will not take place on the main thread, which allows Flask to respond immediately and then perform work in the background. Remember, this is a small application and will work for the scale me and my team will be using this on. This is most certainly not designed for a huge number of users constantly using it.&lt;/p&gt;
&lt;p&gt;Now it's time to get to the real work. &lt;code&gt;hello_world&lt;/code&gt; and &lt;code&gt;command_hello_world&lt;/code&gt;. If you've used Flask before, you can see that &lt;code&gt;command_hello_world&lt;/code&gt; will be the function associated with a user hitting &lt;code&gt;http:\\server.tld\hello-world&lt;/code&gt; with a &lt;code&gt;POST&lt;/code&gt; request. Slack only sends &lt;code&gt;POST&lt;/code&gt; requests, so I care about &lt;code&gt;GET&lt;/code&gt; methods. In &lt;code&gt;command_hello_world&lt;/code&gt;, we send a call to the command worker thread, telling it to call &lt;code&gt;hello_world&lt;/code&gt; and then pass the &lt;code&gt;response_url&lt;/code&gt; as a parameter. The function immediately returns a response to Slack telling the user to wait.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;hello_world&lt;/code&gt;, the function sleeps for a few seconds before sending a response back to the passed &lt;code&gt;response_url&lt;/code&gt;. This &lt;code&gt;sleep&lt;/code&gt; is to emulate "real work" being done. In my case, it's five seconds of queries to JIRA to gather and format all of the data I want to return.&lt;/p&gt;
&lt;p&gt;Finally, this can run locally by firing up Flask. I tested with this command:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;FLASK_APP=jira-slack-integration.py flask run&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When deploying to Google App Engine, the &lt;code&gt;main&lt;/code&gt; function won't be utilized. I cover that below.&lt;/p&gt;
&lt;h2 id="testing-the-application"&gt;Testing the application&lt;a class="headerlink" href="#testing-the-application" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now it's time for everyone's favorite part of development: TESTING!&lt;/p&gt;
&lt;h3 id="slack-set-up-part-1"&gt;Slack set up - Part 1&lt;a class="headerlink" href="#slack-set-up-part-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To test a Slack application, though, some set up within Slack is needed: create a Slack Application, set up and gather tokens, and set up slash command end points.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First, create a &lt;a href="https://api.slack.com/apps?new_app=1"&gt;new Slack App&lt;/a&gt;. Fill out the name and select the appropriate workspace.&lt;/li&gt;
&lt;li&gt;After submission, it redirects to a basic information section about the new application. Scroll down to "App Credentials". Copy the &lt;code&gt;Verification Token&lt;/code&gt; and put it in the &lt;code&gt;SLACK_VERIFICATION_TOKEN&lt;/code&gt; variable in the Flask application.&lt;/li&gt;
&lt;li&gt;Open Slack in the browser, sign in, and then open the web console. In Chrome, do this with &lt;kbd class="light"&gt;CTRL&lt;/kbd&gt;+&lt;kbd class="light"&gt;SHIFT&lt;/kbd&gt;+&lt;kbd class="light"&gt;I&lt;/kbd&gt; or with &lt;kbd class="light"&gt;F12&lt;/kbd&gt; in FireFox. View the page source and search for &lt;code&gt;team_id&lt;/code&gt;. It will look something like this: &lt;code&gt;"T083XXXX"&lt;/code&gt;. Copy this value to &lt;code&gt;SLACK_TEAM_ID&lt;/code&gt; in the Flask application.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="ngrok-set-up"&gt;ngrok set up&lt;a class="headerlink" href="#ngrok-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before slash commands can be set up in Slack, you need a development environment and an easy way to access our development server. One option is to punch holes in the router's firewall to point to your development machine. This works if you are on a home network and you'll be the only machine running the development server. It's no so easy if your set up is more complicated or infrastructure is outside of your control.&lt;/p&gt;
&lt;p&gt;I choose to use &lt;a href="https://ngrok.com/"&gt;ngrok&lt;/a&gt; instead. This application provides you with a free, secure and public URL to your local development environment without worrying about your NAT or firewall settings.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sign up. After that the four steps to complete setup are shown&lt;/li&gt;
&lt;li&gt;Download ngrok. There are downloads for a variety of operating systems. This includes Ubuntu, which I use for my work related development work.&lt;/li&gt;
&lt;li&gt;Unzip ngrok to any location: &lt;code&gt;unzip /path/to/ngrok.zip&lt;/code&gt; This places an &lt;code&gt;ngrok&lt;/code&gt; binary in the selected location.&lt;/li&gt;
&lt;li&gt;Set up the authentication token. This is a one time step. This will create a &lt;code&gt;~/.ngrok2/ngrok.yml&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Start &lt;code&gt;ngrok&lt;/code&gt;. If you're using the script from above, Flask should run on the local machine on port 5000. The command to start &lt;code&gt;ngrok&lt;/code&gt; to point to the Flask server is: &lt;code&gt;./ngrok http 5000&lt;/code&gt;. In another command prompt start the Flask application.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="slack-set-up-part-2"&gt;Slack set up - Part 2&lt;a class="headerlink" href="#slack-set-up-part-2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ngrok&lt;/code&gt; provides a public URL. In the screenshot below, my URL is &lt;code&gt;https://1eed8eae.ngrok.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ngrok dashboard" src="https://andrewwegner.com/images/ngrok.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; This changes every time &lt;code&gt;ngrok&lt;/code&gt; is stated.&lt;/p&gt;
&lt;p&gt;At this point, I can visit &lt;code&gt;https://1eed8eae.ngrok.io/hello-world&lt;/code&gt; in my browser and get an error message because I didn't configure it to support &lt;code&gt;GET&lt;/code&gt; requests.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go back to Slack and the management area where the new application was set up.&lt;/li&gt;
&lt;li&gt;Select "Slash Commands"&lt;/li&gt;
&lt;li&gt;Select "Create New Command"&lt;/li&gt;
&lt;li&gt;Put in the command users will use within Slack. This can be anything.&lt;/li&gt;
&lt;li&gt;Enter the request URL. This will be &lt;code&gt;https://1eed8eae.ngrok.io/hello-world&lt;/code&gt; with this example&lt;/li&gt;
&lt;li&gt;Provide a description of the command&lt;/li&gt;
&lt;li&gt;Add a usage hint. This is useful if you are passing parameters to the command.&lt;/li&gt;
&lt;li&gt;Press save&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Slash Command Example" src="https://andrewwegner.com/images/slash-command-example.png"/&gt;&lt;/p&gt;
&lt;p&gt;The slash command is now set up. The last step is installing the application. Go back to "Basic Information" and expand "Install your app to your workspace" then press the green "Install App to Workspace" button. You'll be presented with an oAuth Access Token. For this example application, it's not needed.&lt;/p&gt;
&lt;p&gt;Now go into any channel in Slack and use the new &lt;code&gt;/hello-world&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; If/when you shut down and restart &lt;code&gt;ngrok&lt;/code&gt;, you'll get a new end point. The slash command will need to be modified to point to this new request URL to continue to function. These changes will not be required once the application is deployed to Google's App Engine.&lt;/p&gt;
&lt;h2 id="deploy-application-to-app-engine"&gt;Deploy application to App Engine&lt;a class="headerlink" href="#deploy-application-to-app-engine" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This project requires the use of the &lt;a href="https://cloud.google.com/appengine/docs/the-appengine-environments"&gt;flexible app engine environment&lt;/a&gt; (vs. standard environment). The biggest reason for this is due to the network requirements. It seems that anything other than Node.js has networking restrictions, and the sample application needs to connect to Slack and my application also needed to connect to JIRA. Another downside of the standard environment is that it only supports Python 2.7. I don't believe there is anything in the example application that would break on Python 2, but there are a few Python 3 specific things I used in my real application (f strings, are one).&lt;/p&gt;
&lt;p&gt;The flexible environment isn't free though. It's always on. The sample application and my real application are so small and used by so few people that it costs less than fifty cents a day. This isn't a huge deal when the rest of our Google cloud bill exceeds that by a couple orders of magnitude, but it is something to consider if you are just running this as a small side thing. It's not free.&lt;/p&gt;
&lt;h3 id="set-up-gcloud-sdk"&gt;Set up gcloud SDK&lt;a class="headerlink" href="#set-up-gcloud-sdk" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Due to the size of this application, the &lt;a href="https://cloud.google.com/appengine/docs/flexible/python/"&gt;quick start tutorial&lt;/a&gt; that Google provides is perfect.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the Google Cloud Platform console, create a new App Engine project and enable billing (billing must be enabled). This can be done from &lt;a href="https://console.cloud.google.com/projectselector/appengine/create?lang=flex_python&amp;amp;st=true"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download the &lt;a href="https://cloud.google.com/sdk/docs/"&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Extract this to any location. To add it to the path, run &lt;code&gt;./google-cloud-sdk/install.sh&lt;/code&gt;. If this isn't done, the full path needs to be in all &lt;code&gt;gcloud&lt;/code&gt; commands.&lt;/li&gt;
&lt;li&gt;Initialize the SDK by running &lt;code&gt;gcloud init&lt;/code&gt; and follow the prompts on screen. You'll need access to a browser for this step as you'll be authorizing your account using oAuth.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="set-up-appyaml"&gt;Set up app.yaml&lt;a class="headerlink" href="#set-up-appyaml" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With &lt;code&gt;gcloud&lt;/code&gt; set up on your development machine, there is one last step to do: Configuring the &lt;code&gt;app.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;This file contains information on the type of environment you'll be deploying to. Create and save an &lt;code&gt;app.yaml&lt;/code&gt; file in the same directory as the Flask application. For this example, the Flask application is in a file saved as &lt;code&gt;example-script.py&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;runtime&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;flex&lt;/span&gt;
&lt;span class="n"&gt;entrypoint&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;gunicorn&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;$PORT&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;app&lt;/span&gt;

&lt;span class="n"&gt;runtime_config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;python_version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="n"&gt;manual_scaling&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;instances&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cpu&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="n"&gt;memory_gb&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;
  &lt;span class="n"&gt;disk_size_gb&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other than the &lt;code&gt;entrypoint&lt;/code&gt; line, this is the example &lt;code&gt;app.yaml&lt;/code&gt; provided by Google. &lt;code&gt;example-script&lt;/code&gt; is the name of the file that contains the Flask application.&lt;/p&gt;
&lt;h3 id="deploy-to-google"&gt;Deploy to Google&lt;a class="headerlink" href="#deploy-to-google" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Finally, it's time to deploy this application to Google. From within the same directory where &lt;code&gt;example-script.py&lt;/code&gt; resides, run:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gcloud app deploy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Wait a few minutes for the deployment to occur. When it's complete, the command prompt will say so and provide a URL where the application is accessible.&lt;/p&gt;
&lt;p&gt;The last thing that needs to be done, is repointing the slash commands to this new location. With it deployed to Google's Cloud Platform, the &lt;code&gt;ngrok&lt;/code&gt; provided URLs need to be changed. The endpoints remain the same though.&lt;/p&gt;
&lt;p&gt;Once the slash commands are changed and saved, test them out and enjoy the new slash commands hosted on Google's App Engine.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Set up Dynamic CloudFlare IP with Let's Encrypt</title><link href="https://andrewwegner.com/setup-lets-encrypt.html" rel="alternate"></link><published>2018-04-25T09:30:00-05:00</published><updated>2018-04-25T09:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-25:/setup-lets-encrypt.html</id><summary type="html">&lt;p&gt;Time to make the server accessible from the internet and secure it with an SSL certificate&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the two previous articles, I installed &lt;a href="https://andrewwegner.com/installing-nextcloud.html"&gt;NextCloud&lt;/a&gt; and &lt;a href="https://andrewwegner.com/installing-gitlab.html"&gt;GitLab&lt;/a&gt;. These are running on the server, inside my local network, with
no firewall rules set up to allow it to be accessible from the internet. That's great if I plan on sitting at home all the time and never
accessing anything from the outside. However, I do plan on that. That means I need to make this server accessible from the internet. On top
of that, I want to secure the connection to the server with SSL, so that I'm not uploading pictures or code in a way that everyone can read.&lt;/p&gt;
&lt;h2 id="setting-up-cloudflare"&gt;Setting up CloudFlare&lt;a class="headerlink" href="#setting-up-cloudflare" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This new server sits in my house, which sits on a residential ISP network. Obviously, this isn't going to have 24x7 uptime, but that's fine
with me. One thing that I will need, is a way to access this server regardless of the IP address my ISP has given me. This can (and does) change
frequently enough that it'd be annoying to keep track of my current IP manually.&lt;/p&gt;
&lt;p&gt;My solution: set up a DNS entry. In the two previous articles, I set up the Apache virtual hosts with subdomains:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;ServerName nas.example.com&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;ServerName gitlab.example.com&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's time to utilize those. Then I will only need to visit those URLs and Apache will handle routing to the correct application.&lt;/p&gt;
&lt;p&gt;I use CloudFlare to handle DNS for this blog. I described the process to &lt;a href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;set up CloudFlare&lt;/a&gt; a few years ago and never
looked at it again. "It just works." Hooray!&lt;/p&gt;
&lt;p&gt;For this, we're going to add two new A entries to reflect the subdomains I want to use. I'll point it at my IP address initially too.&lt;/p&gt;
&lt;h3 id="automating-the-ip-adddress-updates"&gt;Automating the IP adddress updates&lt;a class="headerlink" href="#automating-the-ip-adddress-updates" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The initial set up of the A entry/IP address takes a minute. The trick is automating that process every time your IP address changes. I
am doing that with a small Python script called &lt;a href="https://github.com/Ethaligan/cloudflare-ddns"&gt;&lt;code&gt;cloudflare-ddns&lt;/code&gt;&lt;/a&gt;. Clone this to the server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git clone https://github.com/ethaligan/cloudflare-ddns.git&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, we need to set up zone information. This is the configuration file that will be used to update your A records. Copy example.com.yml to the
name of your domain. For example:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cd zones&lt;/span&gt;
&lt;span class="err"&gt;cp example.com.yml andrewwegner.com.yml&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we need to edit the newly copied file to contain appropriate zone information, CloudFlare API information and your domain.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;%YAML 1.1&lt;/span&gt;
# &lt;span class="n"&gt;Your&lt;/span&gt; &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;email&lt;/span&gt; &lt;span class="n"&gt;address&lt;/span&gt;
&lt;span class="n"&gt;cf_email&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'your_cloudflare_email_address'&lt;/span&gt;

# &lt;span class="n"&gt;Your&lt;/span&gt; &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;API&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;
# &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;support&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cloudflare&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;us&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;200167836&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;do&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;find&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;my&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Cloudflare&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;API&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;
&lt;span class="n"&gt;cf_api_key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;YOUR_CLOUDFLARE_API&lt;/span&gt;

# &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;zone&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;
# &lt;span class="n"&gt;If&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt; &lt;span class="n"&gt;updating&lt;/span&gt; &lt;span class="s"&gt;'ddns.example.com'&lt;/span&gt; &lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;this&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="s"&gt;'example.com'&lt;/span&gt;
&lt;span class="n"&gt;cf_zone&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;

# &lt;span class="n"&gt;List&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;records&lt;/span&gt;
# &lt;span class="n"&gt;If&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt; &lt;span class="n"&gt;updating&lt;/span&gt; &lt;span class="s"&gt;'example.com'&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;its&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="s"&gt;'@'&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
# &lt;span class="n"&gt;Only&lt;/span&gt; &lt;span class="n"&gt;write&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;subdomain&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'ddns'&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="s"&gt;'ddns.example.com'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cf_records&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s"&gt;'nas'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
        &lt;span class="nb"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ERROR&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s"&gt;'gitlab'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
        &lt;span class="nb"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ERROR&lt;/span&gt;

# &lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="n"&gt;used&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;discover&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;IP&lt;/span&gt; &lt;span class="n"&gt;address&lt;/span&gt;
# &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;faster&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;may&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;system&lt;/span&gt;
# &lt;span class="n"&gt;Available&lt;/span&gt; &lt;span class="k"&gt;methods&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'http'&lt;/span&gt; &lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt;
&lt;span class="n"&gt;cf_resolving_method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, I am updating two subdomains (&lt;code&gt;nas&lt;/code&gt; and &lt;code&gt;gitlab&lt;/code&gt;) that are part of the &lt;code&gt;example.com&lt;/code&gt; domain. Those should be changed to reflect your set up.&lt;/p&gt;
&lt;p&gt;Last, we need to schedule this to run on a regular basis so that CloudFlare always points to the correct IP address. I did this with a crontab entry:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;*/30 * * * * python3 /path/to/cloudflare-ddns.py -z example.com&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, change &lt;code&gt;example.com&lt;/code&gt; to your domain, and it will use the appropriate YML file. With this entry, my DNS entries are updated every 30 minutes. That
is frequently enough for my needs.&lt;/p&gt;
&lt;h2 id="lets-encrypt-ssl"&gt;Let's Encrypt (SSL)&lt;a class="headerlink" href="#lets-encrypt-ssl" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the subdomains set up and working, it's time to install some SSL certificates. In previous articles, I had entries in my Apache virtual hosts that pointed to
SSL certificates. This is where we'll set those up.&lt;/p&gt;
&lt;p&gt;Let's Encrypt certificates are valid for 90 days. Renewing certificates, though, can be easily automated. Since I need my certificates to work through CloudFlare,
because it provides my DNS services, I use a hook in Let's Encrypt's ACME client &lt;a href="https://github.com/lukas2511/dehydrated"&gt;&lt;code&gt;dehydrated&lt;/code&gt;&lt;/a&gt; to handle everything.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cd ~&lt;/span&gt;
&lt;span class="err"&gt;git clone https://github.com/lukas2511/dehydrated&lt;/span&gt;
&lt;span class="err"&gt;cd dehydrated&lt;/span&gt;
&lt;span class="err"&gt;mkdir hooks&lt;/span&gt;
&lt;span class="err"&gt;git clone https://github.com/kappataumu/letsencrypt-cloudflare-hook hooks/cloudflare&lt;/span&gt;
&lt;span class="err"&gt;pip install -r hooks/cloudflare/requirements.txt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This downloads deydrated and then downloads the CloudFlare hook that is needed. It installs the required libraries too.&lt;/p&gt;
&lt;p&gt;The last bit of configuration that is needed is setting up a &lt;code&gt;config&lt;/code&gt; file in the &lt;code&gt;dehydrated&lt;/code&gt; directory.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;nano dehydrated/config&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add the following three lines&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;export CF_EMAIL=YOUR_CLOUDFLARE_EMAILADDRESS&lt;/span&gt;
&lt;span class="err"&gt;export CF_KEY=YOUR_CLOUDFLARE_API&lt;/span&gt;
&lt;span class="err"&gt;export CF_DEBUG=true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Substitute your CloudFlare login email and API key as appropriate. The &lt;code&gt;CF_DEBUG&lt;/code&gt; line can be set to &lt;code&gt;false&lt;/code&gt; if you don't wish debugging information to be printed to &lt;code&gt;logs/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Register with Let's Encrypt and accept their terms of service:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;./dehydrated --register --accept-terms&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, you're ready to generate/install the SSL certificates needed. One note: I needed to adjust the shebang line in hooks/cloudflare/hook.py to be &lt;code&gt;python3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Run the following commands to generate the certificates. These will end up in &lt;code&gt;dehydrated/certs&lt;/code&gt; with the full URL of each certificate.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;./dehydrated -c -d nas.example.com -t dns-01 -k 'hooks/cloudflare/hook.py'&lt;/span&gt;
&lt;span class="err"&gt;./dehydrated -c -d gitlab.example.com -t dns-01 -k 'hooks/cloudflare/hook.py'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The path to these files are what will go in your Apache Virtual Host files:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;SSLCertificateFile /path/to/dehydrated/certs/nas.example.com/cert.pem&lt;/span&gt;
&lt;span class="err"&gt;SSLCertificateKeyFile /path/to/dehydrated/certs/nas.example.com/privkey.pem&lt;/span&gt;
&lt;span class="err"&gt;SSLCertificateChainFile /path/to/dehydrated/certs/nas.example.com/chain.pem&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I set up a crontab entry for each of my subdomains to attempt to renew the certificate once a week. Dehydrated will not attempt to renew a certificate if it's not going to
expire in less than 30 days, so we aren't making unneeded calls to Let's Encrypt.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;0 1 6 * * /path/to/dehydrated/dehydrated -c -d nas.example.com -t dns-01 -k '/path/to/dehydrated/hooks/cloudflare/hook.py'&lt;/span&gt;
&lt;span class="err"&gt;10 1 6 * * /path/to/dehydrated/dehydrated -c -d gitlab.example.com -t dns-01 -k '/path/to/dehydrated/hooks/cloudflare/hook.py'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this final step, I have a home server that I can access from anywhere. It allows me to backup pictures automatically, holds my private repositories and is protected
by SSL. The SSL certificates renew automatically.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Setting up GitLab on the new server</title><link href="https://andrewwegner.com/installing-gitlab.html" rel="alternate"></link><published>2018-04-13T08:30:00-05:00</published><updated>2018-04-13T08:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-13:/installing-gitlab.html</id><summary type="html">&lt;p&gt;Let's set up some private repositories on GitLab&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Back when I ran Vipers, my fellow admins and I hosted a small set of code repositories -
SVN, Mercurial and Git - to host some of our custom code. We ran &lt;a href="https://rhodecode.com/"&gt;RhodeCode&lt;/a&gt; and
the fork, &lt;a href="https://kallithea-scm.org/"&gt;Kallithea&lt;/a&gt;, when RhodeCode close sourced some of it's code and
couldn't figure out if the license it used actually allowed themselves to do that. A private
repository was awesome for plugins, server configurations and personal projects.&lt;/p&gt;
&lt;p&gt;When the community was shuttered, some of the &lt;a href="https://github.com/AWegnerGitHub/Vipers-Server-Plugins"&gt;plugin code was migrated to GitHub&lt;/a&gt; and it's
sat there untouched since. My personal projects were either migrated to GitHub or
simply stored outside of version control if it couldn't go in a public repository. That was
less than ideal, but it worked. With the new home server set up, I wanted to get source control set
back up for my non-public personal projects.&lt;/p&gt;
&lt;p&gt;I rejected RhodeCode right away due to the experiences I had when they changed licenses. Turns out,
they had done it again in the meantime. I didn't want to deal with that. I attempted to install
Kallithea using their &lt;a href="http://kallithea.readthedocs.io/en/stable/installation.html"&gt;instructions&lt;/a&gt;, but I kept running into Python syntax errors. It wasn't
worth the time and effort to figure out the problem.&lt;/p&gt;
&lt;p&gt;So, I turned to &lt;a href="https://about.gitlab.com/"&gt;GitLab&lt;/a&gt;. It'd definitely overkill for what I really need, but it works and
if I ever truly decide to get fancy, I have a lot of other tools I can use. The &lt;a href="https://about.gitlab.com/pricing/self-hosted/feature-comparison/"&gt;core&lt;/a&gt; functionality
is what I'll be using and is free. The three other versions cost some money and contain features that
would be useful for large team, not a single developer or very small team.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;a class="headerlink" href="#installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="dependencies"&gt;Dependencies&lt;a class="headerlink" href="#dependencies" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Installing GitLab is pretty simple. There are a couple dependencies needed, but I already had both OpenSSH 
and Postfix installed, so I was able to skip the first step in the &lt;a href="https://about.gitlab.com/installation/#ubuntu"&gt;official installation guide&lt;/a&gt;. I installed
the Ubuntu Omnibus package.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get install -y curl openssh-server ca-certificates postfix&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="getting-the-package"&gt;Getting the package&lt;a class="headerlink" href="#getting-the-package" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The GitLab repository needs to added and then installed. To add the repository, issue this command:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To install the GitLab package, you need to provide an environment variable when you issue your
&lt;code&gt;apt-get install&lt;/code&gt; command. This will be the URL where you want to access your GitLab installation.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo EXTERNAL_URL="http://gitlab.example.com" apt-get install gitlab-ee&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="complete-the-installation"&gt;Complete the installation&lt;a class="headerlink" href="#complete-the-installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the install, above is complete, you need to log in to complete the process. In your browser,
navigate to the URL you provided above. Set/reset the password as prompted and then login. &lt;/p&gt;
&lt;h2 id="post-install-tweaks"&gt;Post-install Tweaks&lt;a class="headerlink" href="#post-install-tweaks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="using-apache-instead-of-nginx"&gt;Using Apache instead of Nginx&lt;a class="headerlink" href="#using-apache-instead-of-nginx" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The omnibus package comes with Nginx bundled. Unfortunately, I don't have any experience managing
an Nginx instance but do have experience with Apache. I want to use something that I know to make
my life easier. Fortunately, GitLab can handle this with a few &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/tree/master/web-server/apache"&gt;minor changes to the configuration&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; file you'll need to make several settings changes. You also need Apache 
already installed and the &lt;code&gt;www-data&lt;/code&gt; user (on Ubuntu) added to the &lt;code&gt;gitlab-www&lt;/code&gt; group.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find &lt;code&gt;nginx['enable']&lt;/code&gt; and set it to &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;web_server['external_users'], add&lt;/code&gt;www-data` to the array. Note that this is an array and not a single string.&lt;/li&gt;
&lt;li&gt;In `gitlab_rails['trusted_proxies'], add the IP address of the Apache web server. &lt;/li&gt;
&lt;li&gt;Change the gitlab workhorse settings to the following (default) values. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These may already be in the configuration file. If so, you probably don't need to modify them.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gitlab_workhorse['listen_network'] = "tcp"&lt;/span&gt;
&lt;span class="err"&gt;gitlab_workhorse['listen_addr'] = "127.0.0.1:8181"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, run &lt;code&gt;sudo gitlab-ctl reconfigure&lt;/code&gt; for the settings to take effect.&lt;/p&gt;
&lt;p&gt;Now, you need to configure Apache's virtual host. GitLab provides &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/tree/master/web-server/apache"&gt;example virtual hosts&lt;/a&gt;. Since I installed
the omnibus package and am using Apache 2.4, I selected the &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/blob/master/web-server/apache/gitlab-omnibus-apache24.conf"&gt;&lt;code&gt;gitlab-omnibus-apache24.conf&lt;/code&gt;&lt;/a&gt; file. Adjust all
instances of &lt;code&gt;YOUR_SERVER_FQDN&lt;/code&gt; to the fully qualified domain name of your server.&lt;/p&gt;
&lt;p&gt;This will go in &lt;code&gt;/etc/apache2/sites-available/&lt;/code&gt; and a symlink in &lt;code&gt;/etc/apache2/sites-enabled/&lt;/code&gt; will point to this file.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo touch /etc/apache2/sites-available/gitlab.conf&lt;/span&gt;
&lt;span class="err"&gt;sudo ln -s /etc/apache2/sites-available/gitlab.conf /etc/apache2/sites-enabled/gitlab.conf&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="use-ssl-to-access-gitlab"&gt;Use SSL to access GitLab&lt;a class="headerlink" href="#use-ssl-to-access-gitlab" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The example virtual host provided by GitLab uses HTTP only. I want to set up my instance to use HTTPS. I'll be 
doing this with &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;, like I did when I set up NextCloud in the previous post. I cover the exact 
&lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;steps for Let's Encrypt&lt;/a&gt; in another post. The keys referenced in the virtual host configuration file below created 
by that process. &lt;/p&gt;
&lt;p&gt;The first change to make is to redirect the HTTP version of your domain to HTTPS. The goal is that all traffic to
GitLab will go over SSL. Adjust the &lt;code&gt;ServerName&lt;/code&gt; variable as appropriate.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  ServerName gitlab.example.com
  ServerSignature Off

  RewriteEngine on
  RewriteCond %{HTTPS} !=on
  RewriteRule .* https://%{SERVER_NAME}%{REQUEST_URI} [NE,R,L]
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, everything in the &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/blob/master/web-server/apache/gitlab-omnibus-apache24.conf"&gt;sample&lt;/a&gt; virtual host file can be put in the &lt;code&gt;&amp;lt;VirtualHost *:443&amp;gt;&lt;/code&gt; block.&lt;/p&gt;
&lt;p&gt;At the top of this block, we need to reference the Let's Encrypt keys:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;SSLProtocol all -SSLv2&lt;/span&gt;
&lt;span class="err"&gt;SSLHonorCipherOrder on&lt;/span&gt;
&lt;span class="err"&gt;SSLCipherSuite "ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS"&lt;/span&gt;
&lt;span class="err"&gt;Header add Strict-Transport-Security: "max-age=15768000;includeSubdomains"&lt;/span&gt;
&lt;span class="err"&gt;SSLCompression Off&lt;/span&gt;
&lt;span class="err"&gt;SSLCertificateFile /path/to/dehydrated/certs/gitlab.example.com/cert.pem&lt;/span&gt;
&lt;span class="err"&gt;SSLCertificateKeyFile /path/to/dehydrated/certs/gitlab.example.com/privkey.pem&lt;/span&gt;
&lt;span class="err"&gt;SSLCertificateChainFile /path/to/dehydrated/certs/gitlab.example.com/chain.pem&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Save and restart Apache. You should be automatically redirected over HTTPS when you visit your GitLab URL.&lt;/p&gt;
&lt;h3 id="allow-spaces-in-repository-names"&gt;Allow spaces in repository names&lt;a class="headerlink" href="#allow-spaces-in-repository-names" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One of the only problems I ran into with GitLab is that, by default, repositories with spaces in them can't be viewed
in the web browser. It throws a &lt;code&gt;400 Bad Request&lt;/code&gt; when trying to view the directory. There is a &lt;a href="https://gitlab.com/gitlab-org/gitlab-ce/issues/32585"&gt;bug report&lt;/a&gt; 
regarding this problem. The developers are working on updating the samples in a way that is guaranteed to work through
the whole system. &lt;/p&gt;
&lt;p&gt;For me, though, the first comment which suggests a minor &lt;code&gt;RewireRule&lt;/code&gt; change works great. In the virtual host, fine the line&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;RewriteRule .* http://127.0.0.1:8181%{REQUEST_URI} [P,QSA,NE]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and remove the &lt;code&gt;NE&lt;/code&gt; so that it reads&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;RewriteRule .* http://127.0.0.1:8181%{REQUEST_URI} [P,QSA]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Restart Apache and you can navigate to the directory with a space.&lt;/p&gt;
&lt;h3 id="setting-up-smtp"&gt;Setting up SMTP&lt;a class="headerlink" href="#setting-up-smtp" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;GitLab can send out emails and requires the ability to do so when resetting a password, at minimum. I don't want this
email to be marked as spam, so I used one of the free providers from &lt;a href="https://docs.gitlab.com/omnibus/settings/smtp.html#smtp-settings"&gt;here&lt;/a&gt; and set up an account. After editing the 
&lt;code&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; file to match the provider I selected, I ran &lt;code&gt;gitlab-ctl reconfigure&lt;/code&gt;. Now any emails GitLab
sends out goes through the trusted email provider instead of coming directly from my residential IP address. This means 
my mail provider trusts it. I also send out less than 5 emails a month currently, so I am &lt;em&gt;well&lt;/em&gt; below the tier where I
lose my "free" status.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point, GitLab is set up over SSL on my server. I can log in and start setting up repositories. Migrating and importing 
the code bases I didn't want to put on a public GitHub account was very satisfying. Maybe I'll look into some of the 
more advanced features GitLab offers in the near future, but for the time being I'm happy with what I have and the 
knowledge that I can expand what I do with GitLab.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Travis CI doesn't keep your environment variable secure</title><link href="https://andrewwegner.com/travisci-insecure-environment-variables.html" rel="alternate"></link><published>2018-04-02T12:30:00-05:00</published><updated>2018-04-02T12:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-02:/travisci-insecure-environment-variables.html</id><summary type="html">&lt;p&gt;Travis CI does not keep your environment variables secure if you transfer a repository.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On December 27, 2017 I reported a security issue directly to the security team as their &lt;a href="https://github.com/travis-ci/travis-ci/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; recommends. I received an automated response that a human would
follow up with me soon. It was their end of year, two week vacation (which is awesome!). I sent the same email again on January 26, 2018 and received a response back from AJ Bowen, a Build Infrastructure Engineer at Travis CI on January 29, 2018. They'd created an internal issue to track the behavior and would follow up within two weeks.&lt;/p&gt;
&lt;p&gt;I followed up with AJ on February 28, 2018 and didn't receive a response. We're now over three months since my initial report. I believe it's time to make this more public so
that others know to be careful with their Travis CI managed environment variables.&lt;/p&gt;
&lt;h2 id="the-issue"&gt;The Issue&lt;a class="headerlink" href="#the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/"&gt;Travis CI &lt;/a&gt; is an application that allows you to automatically test and deploy applications after a commit is pushed to GitHub. I've used this ability to run unit tests,
&lt;a href="https://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html"&gt;automatically deploy updates to PyPI&lt;/a&gt;, and more recently when testing deployment to AWS using the Serverless framework. It's that last one that led me to this issue.&lt;/p&gt;
&lt;p&gt;Part of deploying to AWS requires that you have credentials to deploy. I didn't want to put my AWS deploy credentials in GitHub, even if they are &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Encrypting-environment-variables"&gt;encrypted&lt;/a&gt;. Instead,
I decided to set my variables in the &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Defining-Variables-in-Repository-Settings"&gt;Travis CI Settings&lt;/a&gt;. I went forward with my testing, watched the deploys happen as expected and eventually needed to transfer my
repository to a third party.&lt;/p&gt;
&lt;p&gt;I used GitHub to transfer the repository to the new owner. We tested a build and watched it deploy. The Travis CI console showed a successful deploy. The problem is,
it deployed to &lt;em&gt;my&lt;/em&gt; AWS account using &lt;em&gt;my&lt;/em&gt; AWS credentials. These "secure" environment variables had been transferred to a third party and were no longer in my control.&lt;/p&gt;
&lt;h2 id="reproduction-short-version"&gt;Reproduction - Short Version&lt;a class="headerlink" href="#reproduction-short-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Reproducing the issue is trivial. The short version is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On one GitHub account, create a repository with a &lt;code&gt;.travis.yml&lt;/code&gt; file&lt;/li&gt;
&lt;li&gt;On the Travis CI account associated with step 1, set up an environment variable and elect &lt;em&gt;not&lt;/em&gt; to show the value in the build log&lt;/li&gt;
&lt;li&gt;Transfer the GitHub repository to another account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, the environment variables defined in step 2 are accessible by the new owner from step 3.&lt;/p&gt;
&lt;h2 id="reproduction-long-version"&gt;Reproduction - Long Version&lt;a class="headerlink" href="#reproduction-long-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The detailed steps taken to reproduce this issue show that Travis CI is simply looking for the environment variable values and scrubbing those from the build logs. Once transferred, an edit can be introduced to show these variables with minimal work.&lt;/p&gt;
&lt;h3 id="create-a-repository"&gt;Create a repository&lt;a class="headerlink" href="#create-a-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Create a new repository and add something. For this test, I created a simple Python Hello World file, and named it &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;print("Hello World")&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit this change to your new repository.&lt;/p&gt;
&lt;h3 id="enable-travis-ci-integration"&gt;Enable Travis CI integration&lt;a class="headerlink" href="#enable-travis-ci-integration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Go to &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt; and log in with the GitHub account associated with the above step. Sync your account. Then enable integration by changing the repository switch.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Enable Integration" src="https://andrewwegner.com/images/1-travis-enable-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="create-a-travisyml-file"&gt;Create a .travis.yml file&lt;a class="headerlink" href="#create-a-travisyml-file" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the integration now in place, set up a basic build script by adding a &lt;code&gt;.travis.yml&lt;/code&gt; file to the repository.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"3.5"&lt;/span&gt;
&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This script will set up a build task and run your &lt;code&gt;hello.py&lt;/code&gt; file, using Python 3.5. You will see that "Hello World!" is printed in the build console.&lt;/p&gt;
&lt;p&gt;&lt;img alt="First Build" src="https://andrewwegner.com/images/2-travis-first-build.png"/&gt;&lt;/p&gt;
&lt;h3 id="add-environment-variables"&gt;Add Environment Variables&lt;a class="headerlink" href="#add-environment-variables" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that our build script is working, we can work on "deployment". Deployment to AWS (or other cloud services) requires that you provide credentials. I am not a fan of
including credentials in my repository, even if they are encrypted. Opting for an environment variable should be more secure, as the credentials are never in your repository
in the first place. &lt;strong&gt;It is important to note that you are still giving your credentials to Travis CI in this case.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To set up environment variables, click on "More Options" and "Settings" within the Travis CI application.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Travis Settings" src="https://andrewwegner.com/images/3-add-variable-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Now scroll down to "Environment Variables". Add the name of the variable and the value. Be sure to leave the default value of "Off" selected. You don't want to display this
value in the build log. Finally click "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a variable" src="https://andrewwegner.com/images/4-add-variable-2.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've added a second variable for further testing.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a second variable" src="https://andrewwegner.com/images/5-add-variable-3.png"/&gt;&lt;/p&gt;
&lt;p&gt;Notice that variable values are hidden from view after clicking "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Variable values hidden" src="https://andrewwegner.com/images/6-variables-added.png"/&gt;&lt;/p&gt;
&lt;h3 id="check-values-during-build"&gt;Check values during build&lt;a class="headerlink" href="#check-values-during-build" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the variables saved, restart your build.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Restart Build" src="https://andrewwegner.com/images/7-restart-build.png"/&gt;&lt;/p&gt;
&lt;p&gt;When the build has completed, check the build log. Even though we aren't using these values yet, we can see the environment variables exist and are "Secure".&lt;/p&gt;
&lt;p&gt;&lt;img alt='"Secure" Variables' src="https://andrewwegner.com/images/8-variables-secure.png"/&gt;&lt;/p&gt;
&lt;h3 id="accessing-the-values"&gt;Accessing the values&lt;a class="headerlink" href="#accessing-the-values" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;These values are not actually secure. Travis CI is filtering for the values of these environment variables and if the specific string is found, it is scrubbed from
the log. We can see this with a small change to &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;aws_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_ACCESS_KEY_ID'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;aws_secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_SECRET_ACCESS_KEY'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS KEY ID: |{}{}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS SECRET KEY: |{} {}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, we are splitting the values of the environment variables in half. For the &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt; value, you smash these two together. This will match the
environment variable value, and will not be shown because the pattern still matches the value:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;|{}{}|&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, we split the two halves with a space and print it out. This will be shown, because the extra space no longer matches the exact value of the
environment variable.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;|{} {}|&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit and push the change to GitHub. In Travis CI, we see the following in the build log:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Accessing the values" src="https://andrewwegner.com/images/9-variables-filtered-by-match.png"/&gt;&lt;/p&gt;
&lt;p&gt;As expected, the first pattern is hidden because it matches the environment variable. The second pattern is shown, because the space in the middle means the pattern no longer
matches.&lt;/p&gt;
&lt;h3 id="transfer-the-repository"&gt;Transfer the repository&lt;a class="headerlink" href="#transfer-the-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've shown the variables are accessible, it's time to transfer the repository to a new owner. In GitHub, this can be accomplished by going to the repository settings
and going down to the red "danger area". Once you've entered the name of the current repository and the name of the new owner, we wait for the new owner to accept the transfer.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Transfer the repository" src="https://andrewwegner.com/images/10-transfer-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="build-with-the-new-owner"&gt;Build with the new owner&lt;a class="headerlink" href="#build-with-the-new-owner" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Make a change and commit it to the new repository. I simply modified the "Hello World" line:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;print("Hello World from new owner!")&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A new build will kick off. You can see that the repository has transferred to the new owner in the build log. You can also see the environment variables were transfered to the
new owner. Other than the new owner being listed, the build log shows the same output as before&lt;/p&gt;
&lt;p&gt;&lt;img alt="Everything has transfered" src="https://andrewwegner.com/images/11-build-after-transfer.png"/&gt;&lt;/p&gt;
&lt;h3 id="variables-in-the-ui"&gt;Variables in the UI&lt;a class="headerlink" href="#variables-in-the-ui" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You can also see these variables have transferred by going back to "More Options", then "Settings" in Travis CI. The values are still hidden behind the input password field.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Variables in UI" src="https://andrewwegner.com/images/12-variables-transfered.png"/&gt;&lt;/p&gt;
&lt;h2 id="impact-of-bug"&gt;Impact of bug&lt;a class="headerlink" href="#impact-of-bug" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The example above shows two problems. The bigger problem, in my opinion, is that environment variables are transferred to a new owner. The secondary problem is that "secure"
variables are really just obfuscated. Accessing them is trivial. With this demonstration, we added in a step to show that the variables can be seen by the original
owner. However, it is just as likely that the new owner could introduce such a change after the repository is transferred.&lt;/p&gt;
&lt;p&gt;This bug requires the owner of the repository to perform the "dangerous" GitHub action of transferring a repository. That means it's impact is limited. However, it's just as
likely that the original owner has forgotten that environment variables were set up in Travis CI, an entirely separate system.&lt;/p&gt;
&lt;p&gt;When a GitHub repository is transferred to a new owner, the environment variables in Travis CI should not travel with. This is especially true for the "secure" variables. I'd
rather that a build breaks after the transfer due to the lack of appropriate variables being set up than having my cloud credentials be sent to a third party.&lt;/p&gt;
&lt;h2 id="mitigation"&gt;Mitigation&lt;a class="headerlink" href="#mitigation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Mitigation of this bug, until Travis CI stops transferring environment variables to new repository owners, requires the original owner to remove the variables prior to
transferring the repository. One of the steps that the owner should take is to log into Travis CI and ensure all secure variables have been removed from the Travis CI
environment. This will break the builds, but it will also ensure that private variables aren't leaked unintentionally to a third party.&lt;/p&gt;
&lt;h2 id="repository"&gt;Repository&lt;a class="headerlink" href="#repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The repository for testing is available on &lt;a href="https://github.com/AWegnerGitHub/TravisIssue"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This issue has been reported in the following places:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/travis-ci/travis-ci/issues/9430"&gt;Travis CI Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=16737099"&gt;Hacker News&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chat.stackexchange.com/transcript/message/43757867#43757867"&gt;Charcoal HQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="technical"></category></entry><entry><title>Installing NextCloud</title><link href="https://andrewwegner.com/installing-nextcloud.html" rel="alternate"></link><published>2018-03-27T23:30:00-05:00</published><updated>2018-03-27T23:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-03-27:/installing-nextcloud.html</id><summary type="html">&lt;p&gt;The ZFS pool is set up. It's time to use all that storage space and install NextCloud.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the last post, I described how I &lt;a href="https://andrewwegner.com/zfs-pool-on-ubuntu.html"&gt;set up ZFS on the new server&lt;/a&gt;. With a newly configured operating system and tons of space, it's time to start using it. One of the goals
I &lt;a href="https://andrewwegner.com/new-house-server.html"&gt;mentioned&lt;/a&gt; when I set up this server was the ability to:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Back up data from all devices in the house automatically. As camera phones have gotten better, we've found that we carry our bulky digital camera less and less. The problem
 with the phone camera is that we need to get the pictures to the computer. I don't want to hunt down a data cable or email the pictures to myself. I'm also not a fan of
 posting everything to social media. I want my phone to send the pictures to a backup location automatically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm going to accomplish that by hosting an instance of &lt;a href="https://nextcloud.com/"&gt;NextCloud&lt;/a&gt; on this new server. Fortunately, the install process is pretty simple for this one. NextCloud provides
&lt;a href="https://nextcloud.com/install/"&gt;installation instructions&lt;/a&gt;. When I installed it in mid-February 2018, it was on version 12.x. As of this post, in late March 2018, it's on version 13.x. I'll cover install
and upgrade processes in this post.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;a class="headerlink" href="#installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;a class="headerlink" href="#prerequisites" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For NextCloud you'll need either MySQL or MariaDB. I host it via Apache2, so we'll have that installed too. NextCloud is written in PHP, meaning we need that too.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get install apache2 mariadb-server php7.0 libapache2-mod-php7.0 php7.0-mbstring php7.0-curl php7.0-zip php7.0-gd php7.0-mysql php7.0-mcrypt php7.0-bcmath php7.0-xml php7.0-json php7.0-tidy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Enable the Apache2 rewrite module and restart the web server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo a2enmod rewrite&lt;/span&gt;
&lt;span class="err"&gt;sudo service apache2 restart&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="set-up-the-database"&gt;Set up the database&lt;a class="headerlink" href="#set-up-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You'll need to create a database for NextCloud. Log into your database using credentials that can create new users and databases. &lt;code&gt;root&lt;/code&gt; will work.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;mysql -uroot -p&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, execute a couple SQL statements to create a database and create a user that can access the database. Make sure you use a secure password.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;CREATE DATABASE nextcloud;&lt;/span&gt;
&lt;span class="err"&gt;GRANT ALL PRIVILEGES ON nextcloud.* TO 'nextclouduser'@'localhost' IDENTIFIED BY 'YOURSECUREPASSWORDHERE';&lt;/span&gt;
&lt;span class="err"&gt;FLUSH PRIVILEGES;&lt;/span&gt;
&lt;span class="err"&gt;\q&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="download-nextcloud"&gt;Download NextCloud&lt;a class="headerlink" href="#download-nextcloud" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned above, I initially installed version 12 of NextCloud. The latest version can be found on the &lt;a href="https://nextcloud.com/install/"&gt;NextCloud install page&lt;/a&gt;. The URL from that page should be
used instead of the version 12 link in the following code block. The code block below will be putting NextCloud in the default location Ubuntu has Apache look. You can modify
that as needed. If you do so, the virtual host will need to be modified slightly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo cd /tmp &amp;amp;&amp;amp; wget wget https://download.nextcloud.com/server/releases/nextcloud-12.0.2.zip&lt;/span&gt;
&lt;span class="err"&gt;sudo unzip nextcloud-12.0.2.zip&lt;/span&gt;
&lt;span class="err"&gt;sudo mv nextcloud/ /var/www/html&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We need to adjust ownership of the files so that Apache can read them. The default user and group, in this case is &lt;code&gt;www-data&lt;/code&gt;. If you have configured your server to use a
different user or group, adjust this command accordingly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo chown www-data:www-data -R /var/www/html/nextcloud&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="create-the-virtual-host"&gt;Create the Virtual Host&lt;a class="headerlink" href="#create-the-virtual-host" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll be exposing this to the internet and I'll be accessing it via the internet. That means I really don't want to send data unencrypted to or from NextCloud. I'll be setting
up the standard port 80 web server traffic to redirect to the secure port of 443. I cover &lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;generating SSL certificates&lt;/a&gt; in another post. I use &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;. The keys
referenced in the virtual host configuration file below created by that process.&lt;/p&gt;
&lt;p&gt;Create a new virtual host.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo touch /etc/apache2/sites-available/nextcloud.conf&lt;/span&gt;
&lt;span class="err"&gt;sudo ln -s /etc/apache2/sites-available/nextcloud.conf /etc/apache2/sites-enabled/nextcloud.conf&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you need to edit this newly created file&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo nano /etc/apache2/sites-available/nextcloud.conf&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Paste the following:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerAdmin YOUR@EMAILADDRESS
    DocumentRoot /var/www/html/nextcloud/
    ServerName nas.example.com
    Redirect permanent / https://nas.example.com/

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:443&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerName nas.example.com
    DocumentRoot /var/www/html/nextcloud/
    RewriteCond %{THE_REQUEST} ^.*/index\.php
    RewriteRule ^(.*)index.php$ /$1 [R=301,L]
    SSLEngine on
    SSLCertificateFile /path/to/dehydrated/certs/nas.example.com/cert.pem
    SSLCertificateKeyFile /path/to/dehydrated/certs/nas.example.com/privkey.pem
    SSLCertificateChainFile /path/to/dehydrated/certs/nas.example.com/chain.pem
    &lt;span class="nt"&gt;&amp;lt;IfModule&lt;/span&gt; &lt;span class="err"&gt;mod_headers.c&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        Header always set Strict-Transport-Security "max-age=15552000; includeSubDomains"
    &lt;span class="nt"&gt;&amp;lt;/IfModule&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
 &lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are two separate virtual host configurations being created here. The first one, on port 80, is setting up the permanent redirect to the HTTPS site.&lt;/p&gt;
&lt;p&gt;In the secure virtual host configuration, we're setting a small rewrite rule to provide nicer URLs and configuring the SSL certificates to use. The &lt;code&gt;DocumentRoot&lt;/code&gt; variables
should match the path you installed NextCloud into in the previous step.&lt;/p&gt;
&lt;h3 id="application-configuration"&gt;Application Configuration&lt;a class="headerlink" href="#application-configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are a few settings that you need to change in the NextCloud configuration. Do this by editing &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;. If this file doesn't exist,
you need to copy &lt;code&gt;/var/www/html/nextcloud/config/config.sample.php&lt;/code&gt; to &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The important settings to check are:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="ss"&gt;`datadirectory`&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;In&lt;/span&gt; &lt;span class="n"&gt;my&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;this&lt;/span&gt; &lt;span class="n"&gt;was&lt;/span&gt; &lt;span class="n"&gt;pointed&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="n"&gt;created&lt;/span&gt; &lt;span class="k"&gt;when&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;set&lt;/span&gt; &lt;span class="n"&gt;up&lt;/span&gt; &lt;span class="n"&gt;my&lt;/span&gt; &lt;span class="n"&gt;ZFS&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="ss"&gt;`overwrite.cli.url`&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Changed&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;point&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;HTTPS&lt;/span&gt; &lt;span class="n"&gt;version&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;URL&lt;/span&gt; &lt;span class="n"&gt;I&lt;/span&gt; &lt;span class="n"&gt;want&lt;/span&gt; &lt;span class="k"&gt;to&lt;/span&gt; &lt;span class="k"&gt;use&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="complete-the-installation"&gt;Complete the installation&lt;a class="headerlink" href="#complete-the-installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Restart Apache and the navigate to the domain you've set up for your NextCloud installation. I am assuming that you know how to set up a DNS record for the server name
you specified in your virtual host configuration.&lt;/p&gt;
&lt;p&gt;Once you've reached the domain in your web browser, follow the instructions on screen. You'll need the database username and password you created above. You'll also create an
administration user.&lt;/p&gt;
&lt;h3 id="upgrading"&gt;Upgrading&lt;a class="headerlink" href="#upgrading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After some time, NextCloud will update. You should apply these updates, as they'll include new features and security patches. Log into NextCloud using your administration user.
Click on the Gear icon in the upper right and pick "Settings". On the left hand side, select "Basic settings". Half way down the page you'll see the version you are currently
running and whether or not there is an update available. If there is, you can begin the update from here.&lt;/p&gt;
&lt;p&gt;NextCloud does not support skipping versions when updating. This means if you are on version 12, you can upgrade to version 13. You can not, however, upgrade directly from 12 to 14.&lt;/p&gt;
&lt;p&gt;Additionally, there was a very minor hiccup when I upgraded the underlying PHP version. I covered that process in a &lt;a href="https://andrewwegner.com/updating-php-ubuntu-1804.html"&gt;later post&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="syncing-data"&gt;Syncing data&lt;a class="headerlink" href="#syncing-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;NextCloud provides client applications that allow you to automatically sync data to your install. There are clients for both computers and mobile devices. My use case only
requires the mobile clients right now, but that may change in the future. From the &lt;a href="https://nextcloud.com/install/"&gt;install page&lt;/a&gt;, you can find the clients for Android, iOS and Windows devices. Select
the appropriate installer on your device.&lt;/p&gt;
&lt;p&gt;Once the mobile client is installed, you need to provide the URL to your installation and a username and password that can access your information. I've enabled automatic
uploads of new pictures from my devices only when I'm on a wireless connection (no sense wasting mobile data). This, however, is why I wanted the SSL certificates. The client
doesn't let me whitelist uploading from specific networks. I'd prefer I don't send my pictures unencrypted.&lt;/p&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been using NextCloud for almost three months so far. I love it. Previously, I'd have to find a data cable and remember to manually backup my pictures once and a while. Now,
it "just happens". If I take a picture at home, it's backed up within seconds. If I take a bunch of pictures while I'm out of the house, my pictures are backed up within
minutes of me getting home.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Review of Udemy's Django Course from Basics to Advance</title><link href="https://andrewwegner.com/django-course-basic-to-advance.html" rel="alternate"></link><published>2018-02-20T22:45:00-06:00</published><updated>2018-02-20T22:45:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-02-20:/django-course-basic-to-advance.html</id><summary type="html">&lt;p&gt;My review of the Django Course from Basics to Advance course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the &lt;a href="https://andrewwegner.com/new-house-server.html"&gt;new server&lt;/a&gt; coming along nicely, I wanted to take a quick refresher on Django. Last summer I went through another &lt;a href="https://andrewwegner.com/django-fullstack-bootcamp-course-review.html"&gt;Django course&lt;/a&gt;. That
was a decent course. I didn't need anything that intensive or that focused on the non-Django portions though. I have a couple plans for web control panels
that will help me manage the aspects of the new server I care most about. I decided to take a look at &lt;a href="https://www.udemy.com/django-course-from-basics-to-advance/"&gt;Django Course from Basics to Advance&lt;/a&gt; by Bucky Roberts.
It is billed as a five hour course and seemed to hit major aspects of the framework. It was released in January 2018, so it was brand new at the time I signed up.&lt;/p&gt;
&lt;p&gt;Spoiler alert: &lt;em&gt;Avoid this course&lt;/em&gt;. It's a waste of money. The bad grammar in the title should have been the red flag that made me avoid it. Unfortunately, that was
only the start of my issues with the course.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-course"&gt;Thoughts on the course&lt;a class="headerlink" href="#thoughts-on-the-course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Literally ten seconds into the first lecture: "If you guys were wondering what the F Django is, it's not a movie, well it is a movie." It only goes
down hill from there. A few complaints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A majority of the lectures start with "Alright Hauses"&lt;/li&gt;
&lt;li&gt;"Think of [Django] like PHP, if you guys are fuzzy on it, but cooler."&lt;/li&gt;
&lt;li&gt;Lecture 3 includes a rant about what an "app" is and how everyone is developing "apps" now.&lt;/li&gt;
&lt;li&gt;In lecture 10, the instructor starts with a rant about an overweight airline passenger sitting next to them on a plane&lt;/li&gt;
&lt;li&gt;Insults and mocking of front end developers&lt;/li&gt;
&lt;li&gt;One of the lectures ends with "To be honest, my mom keeps texting me and it's kind of annoying."&lt;/li&gt;
&lt;li&gt;Another lecture is interrupted with this train of thought: "There is a dog barking outside. It's annoying me."&lt;/li&gt;
&lt;li&gt;Finally, one lecture ends with "Thank you guys for watching. Don't forget to subscribe!"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's a YouTube channel. The instructor uploaded their YouTube channel to Udemy. Not only that, they uploaded two year old tutorial videos. It's not
even current!&lt;/p&gt;
&lt;p&gt;There are technical issues with the course too:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The instructor is using Django 1.9. There is three years out of date at this point.&lt;/li&gt;
&lt;li&gt;Installation instructions tell users to use administration or &lt;code&gt;sudo&lt;/code&gt; rights for all Python libraries&lt;/li&gt;
&lt;li&gt;Installation instructions are done using &lt;code&gt;easy_install&lt;/code&gt; not &lt;code&gt;pip&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the &lt;code&gt;urls.py&lt;/code&gt; files that define URL routes, there are lines that look like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;url(r'^admin/', admin.site.urls)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The instructor attempts to describe the &lt;code&gt;r&lt;/code&gt; in front of &lt;code&gt;'^admin/'&lt;/code&gt; by saying:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Whenever I type "r", it means 'regular expression'.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is just flat wrong. &lt;code&gt;r&lt;/code&gt; indicates a &lt;a href="https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals"&gt;raw string&lt;/a&gt;. From the documentation:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Both string and bytes literals may optionally be prefixed with a letter 'r' or 'R'; such strings are called raw strings and treat backslashes as literal characters.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Don't waste your time with this. Don't look at it. Don't think about it. This course is a YouTube channel. If you really want to watch a two year old series running a
three year old version of Django &lt;a href="https://www.youtube.com/watch?v=qgGIqRFvFFk&amp;amp;list=PL6gx4Cwl9DGBlmzzFcLgDhKTTfNLfX1IK"&gt;watch it on YouTube&lt;/a&gt;. It's not worth it. The information is outdated and wrong in many spots. The instructor uploaded this course for
a quick dollar. They didn't build this course for Udemy. They built it for YouTube and you can tell. The quality of content here is not what I've come to expect from
Udemy course.&lt;/p&gt;
&lt;p&gt;Fortunately for me, Udemy Support was very helpful when I requested a refund. I listed most of the complaints I did above and mentioned it course was just a
YouTube channel that had been uploaded to Udemy. I was issued a refund in under an hour. I also left my first public review of a course on Udemy so that other students
know they can get the same content elsewhere.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Course Review" src="https://andrewwegner.com/images/django-course-basics-to-advance-review-screenshot.png"/&gt;&lt;/p&gt;
&lt;p&gt;I still want to find a quick refresher. I'll have to go hunting for that later.&lt;/p&gt;
&lt;hr/&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Setting up a ZFS pool on Ubuntu 16.04</title><link href="https://andrewwegner.com/zfs-pool-on-ubuntu.html" rel="alternate"></link><published>2018-02-15T22:30:00-06:00</published><updated>2018-02-15T22:30:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-02-15:/zfs-pool-on-ubuntu.html</id><summary type="html">&lt;p&gt;With the backup server assembled, it's time to start configuring it. This post covers setting up the ZFS pool for all the data&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/new-house-server.html"&gt;Previously&lt;/a&gt; in this series, the new NAS was assembled. Ubuntu 16.04 has been installed and updated. It's time to do something with all those hard drives! &lt;/p&gt;
&lt;p&gt;I'll be setting the seven 4TB drives in a single &lt;a href="https://en.wikipedia.org/wiki/ZFS"&gt;ZFS&lt;/a&gt; pool. I'm using ZFS for protection against data corruption. It offers several other &lt;a href="https://wiki.ubuntu.com/ZFS"&gt;features&lt;/a&gt; too. I'll
be using dual parity, which means I could lose two drives and be able to recover. The goal is never to test this, but I'd rather not go through a &lt;a href="https://andrewwegner.com/backup-your-data.html"&gt;data loss scare&lt;/a&gt; again.&lt;/p&gt;
&lt;p&gt;Before we begin, it's a good idea to ensure Ubuntu has been updated.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the update complete, let's get started. &lt;/p&gt;
&lt;h2 id="installing-zfs"&gt;Installing ZFS&lt;a class="headerlink" href="#installing-zfs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Installing the ZFS file system is simple on Ubuntu. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo apt-get install zfs parted&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ta-da! Your system is now capable of setting up ZFS pools. The &lt;code&gt;parted&lt;/code&gt; package will be used to set up a ZFS pool shortly.&lt;/p&gt;
&lt;h2 id="setting-up-our-pool"&gt;Setting up our pool&lt;a class="headerlink" href="#setting-up-our-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Pools are the basic building block of ZFS. A pool is made up of the underlying devices that will store the data. Setting up our ZFS pool requires a little bit of prep work
for our new drives. First, ensure that the &lt;code&gt;zfs&lt;/code&gt; package installed correctly by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo zpool status&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point in the process, you should get the message &lt;code&gt;no pools available&lt;/code&gt;. &lt;/p&gt;
&lt;h3 id="adding-the-gpt-label"&gt;Adding the GPT label&lt;a class="headerlink" href="#adding-the-gpt-label" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'm setting up this pool with brand new drives. We need to add a &lt;code&gt;GPT&lt;/code&gt; label to each disk so that ZFS doesn't complain about disks having an &lt;code&gt;invalid vdev specification&lt;/code&gt; 
when we create the pool. To do this, we'll find the names of our drives first&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;ls -l /dev/sd*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On my system, I get a result similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;brw-rw---- 1 root disk 8,   0 Feb 13 09:23 /dev/sda&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,   1 Feb 13 09:23 /dev/sda1&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,   2 Feb 13 09:23 /dev/sda2&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,   5 Feb 13 09:23 /dev/sda5&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  16 Feb 13 09:23 /dev/sdb&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  32 Feb 13 09:23 /dev/sdc&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  48 Feb 13 09:23 /dev/sdd&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  64 Feb 13 09:23 /dev/sde&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  80 Feb 13 09:23 /dev/sdf&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8,  96 Feb 13 09:23 /dev/sdg&lt;/span&gt;
&lt;span class="err"&gt;brw-rw---- 1 root disk 8, 112 Feb 13 09:23 /dev/sdh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We'll be adding the &lt;code&gt;GPT&lt;/code&gt; labels to each of the unformatted drives. The unformatted ones are the listed drives that don't have a numeral as well. For me, that means we'll
be working with &lt;code&gt;sdb&lt;/code&gt;, &lt;code&gt;sdc&lt;/code&gt;, &lt;code&gt;sdd&lt;/code&gt;, &lt;code&gt;sde&lt;/code&gt;, &lt;code&gt;sdf&lt;/code&gt;, &lt;code&gt;sdg&lt;/code&gt; and &lt;code&gt;sdh&lt;/code&gt;. The &lt;code&gt;sda&lt;/code&gt; drive has been formatted and contains partitions already. Those are &lt;code&gt;sda1&lt;/code&gt;, &lt;code&gt;sda2&lt;/code&gt; and &lt;code&gt;sda5&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;For each drive, except &lt;code&gt;sda&lt;/code&gt; in my case, we need to run the &lt;code&gt;parted&lt;/code&gt; command.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo parted /dev/sdb&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will give you a short dialog. All you will need to do is issue the &lt;code&gt;mklabel GPT&lt;/code&gt; command and then quit (using &lt;code&gt;q&lt;/code&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;GNU Parted 3.2&lt;/span&gt;
&lt;span class="err"&gt;Using /dev/sdb&lt;/span&gt;
&lt;span class="err"&gt;Welcome to GNU Parted! Type 'help' to view a list of commands.&lt;/span&gt;
&lt;span class="err"&gt;(parted) mklabel GPT&lt;/span&gt;
&lt;span class="err"&gt;(parted) q&lt;/span&gt;
&lt;span class="c"&gt;Information: You may need to update /etc/fstab.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="getting-device-ids"&gt;Getting device IDs&lt;a class="headerlink" href="#getting-device-ids" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the &lt;code&gt;GPT&lt;/code&gt; labels are added, we can create our pool. However, we're not going to use the device paths returned above. Theoretically, those can change (especially if you 
replace a drive). That would be bad and mess with the entire ZFS pool. Instead we're going to create the pool by using the device id. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;ls -l /dev/disk/by-id/*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This returns output similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee20f1d3114&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdc&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee20f3ba2b9&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdg&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee2647227b7&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdb&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee26490a21e&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdd&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee2b9c81501&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdh&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee2b9e6ab61&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdf&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x50014ee2b9e6b857&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sde&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x5001b444a9525c87&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x5001b444a9525c87&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part1&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda1&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x5001b444a9525c87&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part2&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda2&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;wwn&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="n"&gt;x5001b444a9525c87&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part5&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda5&lt;/span&gt;

&lt;span class="p"&gt;...&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K0HLKUXT&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdb&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K0HLKXS0&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdc&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K4YJ6T0U&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdg&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K5LCEYN4&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdf&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K6VNN6TA&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sde&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K6VNNTXY&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdd&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K7TSA4VS&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sdh&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;  &lt;span class="mi"&gt;9&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WDS100T1B0A&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;H9H0_174256421671&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WDS100T1B0A&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;H9H0_174256421671&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part1&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda1&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WDS100T1B0A&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;H9H0_174256421671&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part2&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda2&lt;/span&gt;
&lt;span class="n"&gt;lrwxrwxrwx&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;13&lt;/span&gt; &lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WDS100T1B0A&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="n"&gt;H9H0_174256421671&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;part5&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;sda5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that both formats symlink to the same location. This means you can pick which ever format you like better. However, I recommend the second one that contains the 
device serial number. It'll make it easier to determine problem disks in the future. &lt;/p&gt;
&lt;h3 id="create-the-pool"&gt;Create the pool&lt;a class="headerlink" href="#create-the-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've determined the device ides for each of our hard drives, it's time to actually create the pool. As I mentioned above, we'll be creating using dual parity
(&lt;code&gt;raidz2&lt;/code&gt;). We'll be naming our pool &lt;code&gt;data&lt;/code&gt;. Once this command is complete, &lt;code&gt;/data&lt;/code&gt; will be where this pool resides.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo zpool create data raidz2 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a little while, but a surprisingly smaller amount of time than I initially expected. &lt;/p&gt;
&lt;p&gt;Once the creation is complete, take a look at the status of your new pool:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt; &lt;span class="n"&gt;zpool&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;

  &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;data&lt;/span&gt;
 &lt;span class="k"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ONLINE&lt;/span&gt;
  &lt;span class="n"&gt;scan&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;none&lt;/span&gt; &lt;span class="n"&gt;requested&lt;/span&gt;
&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

        &lt;span class="n"&gt;NAME&lt;/span&gt;                                          &lt;span class="k"&gt;STATE&lt;/span&gt;     &lt;span class="k"&gt;READ&lt;/span&gt; &lt;span class="k"&gt;WRITE&lt;/span&gt; &lt;span class="n"&gt;CKSUM&lt;/span&gt;
        &lt;span class="k"&gt;data&lt;/span&gt;                                          &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
          &lt;span class="n"&gt;raidz2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;                                    &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K0HLKUXT&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K0HLKXS0&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K6VNNTXY&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K6VNN6TA&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K5LCEYN4&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K4YJ6T0U&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;
            &lt;span class="n"&gt;ata&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WDC_WD40EFRX&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;68&lt;/span&gt;&lt;span class="n"&gt;N32N0_WD&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;WCC7K7TSA4VS&lt;/span&gt;  &lt;span class="n"&gt;ONLINE&lt;/span&gt;       &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="k"&gt;No&lt;/span&gt; &lt;span class="n"&gt;known&lt;/span&gt; &lt;span class="k"&gt;data&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That last line is important. No known data errors is good. &lt;/p&gt;
&lt;h2 id="create-datasets"&gt;Create datasets&lt;a class="headerlink" href="#create-datasets" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Where pools are the basic building blocks of ZFS, datasets is a term for a ZFS file system, volume, snapshot or clone. Each dataset can be managed and configured differently.
This means that you can compress one dataset, but leave the others alone. You can put a quota on one, but leave the others without a quota. Creating a dataset is pretty easy:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cd /&lt;/span&gt;
&lt;span class="err"&gt;sudo zfs create data/storage&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a dataset that exists at &lt;code&gt;/data&lt;/code&gt; named &lt;code&gt;storage&lt;/code&gt;. You can have child datasets that inherit attributes from parents (or even grandparents) by doing something
like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sudo zfs create data/storage/music&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create the new dataset at &lt;code&gt;/data/storage&lt;/code&gt; named &lt;code&gt;music&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you've set up your datasets, you can see they were all created and how much space they have available by issuing &lt;code&gt;sudo zfs list&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="set-up-complete"&gt;Set up complete&lt;a class="headerlink" href="#set-up-complete" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With that, we've finished setting up ZFS on Ubuntu 16.04. I set up a few datasets for my purposes. I'm one step closer to getting this running and handling all of the 
digital data in the house. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>...and then there was a backup server</title><link href="https://andrewwegner.com/new-house-server.html" rel="alternate"></link><published>2018-02-12T15:15:00-06:00</published><updated>2018-02-12T15:15:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-02-12:/new-house-server.html</id><summary type="html">&lt;p&gt;Technical discussion about the new backup server&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my &lt;a href="https://andrewwegner.com/backup-your-data.html"&gt;last post&lt;/a&gt;, I covered the events that lead to my data loss scare. Faulty, untested, backups will bite you every time. The question 
is just, "when will it happen?". By mid-to-late January (three months later), I'd gotten everything back from &lt;a href="http://sertdatarecovery.com"&gt;SERT Data Recovery&lt;/a&gt; and
was happy that everything was recovered. It was time to finally build that huge NAS.&lt;/p&gt;
&lt;h2 id="server-goals"&gt;Server Goals&lt;a class="headerlink" href="#server-goals" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A NAS for a home backup solution could be something as simple as a prebuilt device with a couple hard drives. I'm a bit of a geek and have a lot of digital data, not to 
mention family pictures, years worth of programs I've written, and a digital music and movie collection. I'm a digital pack rat, but a well organized digital pack rat. 
I also wanted to get more out of this server than "plug the device into the router". I ran game servers for &lt;a href="https://andrewwegner.com/thanks-for-all-the-fish.html"&gt;Vipers&lt;/a&gt; for five years. I did a little bit of server 
work at Caterpillar. I've toyed with server virtual machines off and on for testing various packages and software over the years. Through all of this, though, I've 
never had a server in the house that I could use to run some of my scripts on. Those always ran on my desktop because it was always on. This server was going to change that. &lt;/p&gt;
&lt;p&gt;I had several goals when building this thing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have more storage space than I needed for several years. I didn't want to rebuild this in 18 months because I was bad at planning. Years ago when I built my computer
 for college, I stuck two 120 gigabyte hard drives in the machine and thought I'd never fill that. When I came home that first summer, I already had to upgrade hard drives 
 because I was low on space. &lt;/li&gt;
&lt;li&gt;Run a server version of Linux. I don't want to buy a license for a Microsoft server product and my Microsoft Academic Licenses expired a while ago. During my time with Vipers, I used a Red Hat variant of Linux. At Caterpillar we used Ubuntu. &lt;/li&gt;
&lt;li&gt;Utilize &lt;a href="https://en.wikipedia.org/wiki/ZFS"&gt;ZFS&lt;/a&gt; for protection against data corruption. This combined with my more recent usage of Ubuntu lead me to decide on using Ubuntu Server for the operating system. 
 At the time of this post, I'll be using the 16.04 LTS version. I'll continue to upgrade to future LTS versions.&lt;/li&gt;
&lt;li&gt;Back up data from all devices in the house automatically. As camera phones have gotten better, we've found that we carry our bulky digital camera less and less. The problem
 with the phone camera is that we need to get the pictures to the computer. I don't want to hunt down a data cable or email the pictures to myself. I'm also not a fan of 
 posting everything to social media. I want my phone to send the pictures to a backup location automatically.&lt;/li&gt;
&lt;li&gt;Host my personal git repositories and personal projects.&lt;/li&gt;
&lt;li&gt;Be able to stream music and movies to other devices on the network.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="hardware"&gt;Hardware&lt;a class="headerlink" href="#hardware" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now that I've decided my goals, it was time to pick out hardware. The biggest decision was to determine how much storage space I'd be getting. The idea was that hard drives
would be the majority of the cost of this machine. In the end, I went with the following hardware:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rosewell 4U server chasis. It's rack mountable for the future when I can convince myself that a server rack in the basement is a thing I want to spend money on and haul around.&lt;/li&gt;
&lt;li&gt;Supermicro MBD-X11SSM-F-O Micro AT server motherboard (LGA 1151)&lt;/li&gt;
&lt;li&gt;Intel Xeon E3-1230 V5 3.4 Ghz processor&lt;/li&gt;
&lt;li&gt;2x Supermicro certified MEM-DR416L-SL01-EU21 16 GB DDR4-2133 ECC server memory. Take careful note of that model. I originally ordered MEM-DR416L-SL01-ER21 (notice 
 the single "R" to "U" character difference). The motherboard did not like the ER21 at all. &lt;/li&gt;
&lt;li&gt;EVGA 650 power supply (I've been really happy with EVGA power supplies on my last 4 machine builds).&lt;/li&gt;
&lt;li&gt;1x Western Digital Blue 1 terabyte SSD (for the operating system and other applications)&lt;/li&gt;
&lt;li&gt;7x Western Digital Red 4 terabyte hard drives (for all the data)&lt;/li&gt;
&lt;li&gt;Enough SATA cables for all 8 drives&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'll be running ZFS in RAIDZ2 (dual parity). This means with 7 drives, two will be effectively parity drives. I'll have a total of 20 terabytes, minus formatting, for data. After formatting this comes down to a little over 16 terabytes of usable space. Considering that the rest of the household has a combined 5 terabytes, if I use up every available bit, I'm hoping that 16 will last me a while.&lt;/p&gt;
&lt;h3 id="that-ram"&gt;That RAM...&lt;a class="headerlink" href="#that-ram" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I went with the Supermicro board based on a recommendation from a friend. Supermicro's site is really good. It has &lt;a href="https://www.supermicro.com/products/motherboard/Xeon/C236_C232/X11SSM-F.cfm"&gt;tested compatible hardware lists&lt;/a&gt; and, it turns out, 
a knowledgeable person behind their online store's chat feature. The problem that I ran into when building this machine is that the compatible RAM was really hard to find. 
I didn't realize that and ordered the mother board in my first batch of components. When I finally went to look for RAM, I failed to notice a single character difference between
the EU21 version that I needed and the ER21 version that I ordered first. &lt;/p&gt;
&lt;p&gt;I assembled the machine, plugged everything in, and turned on the new server. Then it beeped at me. A lot. After some troubleshooting, re-seating the RAM and &lt;em&gt;finally&lt;/em&gt;
 realizing that I ordered the wrong stuff, I exchanged what I ordered with what I needed. The EU21 RAM worked perfectly. &lt;/p&gt;
&lt;h2 id="whats-next"&gt;What's next&lt;a class="headerlink" href="#whats-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The hardware is assembled. Ubuntu 16.04 Server has been installed. The next step is configuring the server to be the backup solution for the entire house and meeting my other 
goals. I'll have a few more posts in this series on how I accomplished those goals. Stay tuned!&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Well, there goes my data...</title><link href="https://andrewwegner.com/backup-your-data.html" rel="alternate"></link><published>2018-01-27T00:04:00-06:00</published><updated>2018-01-27T00:04:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-01-27:/backup-your-data.html</id><summary type="html">&lt;p&gt;Learn from my mistake and test your backups&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;October 2017 started nicely. The weather was still good. Fall hadn't really arrived yet, though I was still raking some leaves. Halloween was approaching and
soccer season had just ended so I had time of weekends to do a few more projects. Then in mid-October one of my hard drives died. It was sudden. There were
no SMART warnings. There wasn't any weird sounds.&lt;/p&gt;
&lt;p&gt;In fact, the only indication that there was a problem initially was that one of my running applications couldn't access a log file. I didn't think any of it.
I took a few minutes to install a Windows update that had been nagging me for a day or so and rebooted the machine. A reboot on my desktop normally takes twenty-ish
seconds.&lt;/p&gt;
&lt;p&gt;As the reboot stretched into the fifth minute, I realized there was a problem. However, I was initially getting ready to blame that Windows update.&lt;/p&gt;
&lt;h2 id="a-data-disaster"&gt;A Data Disaster&lt;a class="headerlink" href="#a-data-disaster" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Finally, the reboot finished and I logged into the machine. Immediately, I received alerts that files couldn't be accessed and programs couldn't start. I tried to launch
Firefox and was told it couldn't be found. "Well, this is bad," I thought. Turns out that was an understatement. After a short investigation, I found that one of my hard drives wasn't being detected by Windows.&lt;/p&gt;
&lt;p&gt;On my desktop, I have three hard drives. The first is, a decently sided solid state machine that hosts the operating system. The second is a large solid state drive that
holds my game installs. The third is a large spinning hard drive (Seagate), which is where I install software and hold my data. The missing drive was the large one that holds
my data.&lt;/p&gt;
&lt;p&gt;Panic set in. However, I had just backed stuff up to my trusty external hard drive. "At most I'll lose a week's worth of stuff. And, I still have the pictures on phones and
camera SD cards," I said, trying to comfort myself. I also new I had at least two brand new and unused drives identical to the one that had just had a problem. Those were the
result of cheap hard drives when I build my desktop and the promise that one day I'd build a true backup solution for the house. Yeah, hadn't done that yet.&lt;/p&gt;
&lt;p&gt;After messing with the missing drive by unplugging it and rebooting (bringing back normal boot times), swapping it to another SATA port ("hey, maybe it's the motherboard"),
trying to access it in a Linux LiveCD and plugging it into an external drive, I concluded that it was dead. I pulled it from the desktop, resisted smashing it to pieces in
frustration and plugged one of it's unused siblings in.&lt;/p&gt;
&lt;p&gt;Windows booted right up. I had an empty hard drive. I'd be spending a day reinstalling software, but I could handle that. I plugged in my backup external drive and started
copying data back into place. I breathed a sign of relief when all the family pictures were restored. I lost a weekend, but everything looked good. I went to bed Sunday night
happy and planning on finally building that backup solution. "That was almost a disaster!"&lt;/p&gt;
&lt;h2 id="the-problem-appears"&gt;The Problem Appears&lt;a class="headerlink" href="#the-problem-appears" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On Monday morning, I saw the family off to school and work and then settled in for my day. I went to pull up a personal project that I'd work on for an hour or so before the
work day began. Well, it turns out that one of the things I stored on that drive that hosts all my data was my personal projects. It also turns out that I never actually
backed up my personal projects.&lt;/p&gt;
&lt;p&gt;More than decade worth of personal programming projects, horrible attempts at graphic work (seriously...graphics aren't my thing), notes for games that I'd love to design if
I ever get the time were gone. I dug through my most immediate backup. I found old drives - because "you never know when you'll need it" - and dug through those. Nothing. I
have no idea how I missed this rather important directory in all my various manual and semi-automated backup routines over the years.&lt;/p&gt;
&lt;p&gt;I'd either have to suck it up and lose that history or get serious about data recovery.&lt;/p&gt;
&lt;h2 id="data-recovery-attempt"&gt;Data Recovery Attempt&lt;a class="headerlink" href="#data-recovery-attempt" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Back in college, I was manager of the university's help desk. One of the tasks we performed was data recovery for students. Usually this was on flash drives that had "suddenly
deleted a paper", but occasionally we'd have to work on a hard drive too. Our recovery efforts were limited to a quick run of a handful of applications that attempted to
recovery deleted files. In the world of stressed students, this was all that was usually needed. If you could recover that term paper, thesis paper or dissertation, you were
a hero.&lt;/p&gt;
&lt;p&gt;That's what I tried. I hoped it'd work. Windows still couldn't see the back drive. A Linux LiveCD could see that a drive existed, but couldn't find any data. That was still
progress. I ran software for almost two days as it tried to find anything for me to recovery.&lt;/p&gt;
&lt;p&gt;Nothing. Nothing at all. It looked like some how erased everything from the drive. I was back to my choices - lose the history or find a professional.&lt;/p&gt;
&lt;p&gt;I went with a professional. I couldn't lose that much of my history. I still those projects for both personal and professional work.&lt;/p&gt;
&lt;h2 id="sert-data-recovery"&gt;SERT Data Recovery&lt;a class="headerlink" href="#sert-data-recovery" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I went with &lt;a href="http://sertdatarecovery.com"&gt;SERT Data Recovery&lt;/a&gt;. The technician over the phone explained their process. They asked questions that made me confident in their
ability to at least diagnose the problem, and most importantly were thousands of dollars cheaper than a competitor I spoke with. They explained their pricing structure (they
provide a quote and it won't be a giant range), and pricing for replacement parts and allowed me to either send in an empty drive or pay for one that my data would be returned
to me on. They answered my questions.&lt;/p&gt;
&lt;p&gt;They also didn't scold me for doing the single most damaging thing to a drive. I had done it repeatedly. I had turned the bad drive back on. I had turned it on and let it spin
for days as I attempted to recover data.&lt;/p&gt;
&lt;p&gt;I shipped them the drive. After the initial diagnosis came back - one of the platter heads had stopped working - I paid for the replacement part and waited. Eventually the
data was recovered with a 100% recovery rate. I was ecstatic. My data was shipped back to me and I quickly transferred my projects to the new drive.&lt;/p&gt;
&lt;p&gt;My only complaint in the entire process was that the recovery process took almost seven weeks. I shipped the drive at the end of October and received the data back the week
before Christmas. However, all of my data was recovered, so it's a pretty minor complaint.&lt;/p&gt;
&lt;h2 id="whats-next"&gt;What's next?&lt;a class="headerlink" href="#whats-next" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been a little over a month since I've transferred my data to a the new drive in my desktop. I've manually run my back up process two or three times. I'm pretty much where
I was at the beginning of October. Crossing my fingers that when I get on the computer in the morning, all my data will be there. That's not acceptable any more.&lt;/p&gt;
&lt;p&gt;I'm finally building the backup solution. It'll be a huge (for a family) NAS. The goal is to be able to back up from Windows, Ubuntu and a couple Android phones automatically.&lt;/p&gt;
&lt;p&gt;The next entry will cover the device itself and my choices for certain hardware. I'll follow that up with an article on the software set up to get the entire thing working.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>How I found an awesome remote only job</title><link href="https://andrewwegner.com/how-i-found-an-awesome-remote-only-job.html" rel="alternate"></link><published>2017-11-28T09:01:00-06:00</published><updated>2017-11-28T09:01:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-11-28:/how-i-found-an-awesome-remote-only-job.html</id><summary type="html">&lt;p&gt;A brief walkthrough of my job hunting process&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been over three months since I &lt;a href="https://andrewwegner.com/a-decade-at-caterpillar.html"&gt;left my position at Caterpillar&lt;/a&gt;, but
leaving that job wasn't as simple as finding a position and changing jobs. Since
my initial post that I was changing positions, I've gotten questions from several
professional contacts that were also looking to move, but weren't entirely sure
of the process I used to find my new job. I hope to answer some of those
questions with this post.&lt;/p&gt;
&lt;h2 id="new-job-criteria"&gt;New Job Criteria&lt;a class="headerlink" href="#new-job-criteria" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;One of the advantages I had during this search was that I had a job already. This
allowed me to hunt for a job at my own pace. I didn't need a new position
immediately. The slower pace also let me set my own criteria for what I wanted
in a new job.&lt;/p&gt;
&lt;h3 id="full-time-work-from-home"&gt;Full time work from home&lt;a class="headerlink" href="#full-time-work-from-home" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At Caterpillar, I worked from home one to two days a week. I did this for several
years and enjoyed it. I found that I was much more productive. I was able to focus
on the work that needed to be done that day because the distractions of working
in a cube farm weren't present. I didn't hear the side conversations that I wasn't
involved in. I didn't get the "hey can you help me" questions that could be solved
with a few seconds of trying some new code. I was able to concentrate on the task
and not context switch frequently.&lt;/p&gt;
&lt;p&gt;Additionally, the drive to and from the office was consuming almost two hours a
day. In the winter, this was brutal. I was leaving as the sun rose and getting
home well after it had set. I wasn't seeing the family.&lt;/p&gt;
&lt;p&gt;My most important criteria was born from these two. I wanted to be able to work
from home, full time. I was not opposed to the occasional yearly get together,
but I didn't want to go into an office on a regular basis.&lt;/p&gt;
&lt;h3 id="pay-and-benefits-must-improve"&gt;Pay and benefits must improve&lt;a class="headerlink" href="#pay-and-benefits-must-improve" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Caterpillar had great benefits. I don't remember ever worrying about health
coverage, or prescription drug coverage. Pay was "industry average", which
always seemed a bit lower than what sites like &lt;a href="https://www.glassdoor.com"&gt;glassdoor.com&lt;/a&gt; said I should
make. Part of this was due to the yearly bonus I was eligible for. This was
dependent on the business performance and not guaranteed. It also fluctuated a lot.
The fact that Caterpillar went through nearly five years of poor market performance
didn't help with those bonuses either.&lt;/p&gt;
&lt;p&gt;A new position would need to meet or exceed the health benefits I had. The pay
would need to improve too. Working from home would have the advantage of not
paying for gas for the car as frequently. It'd also reduce the maintenance costs
of putting so many miles on the car.&lt;/p&gt;
&lt;h3 id="something-challenging"&gt;Something challenging&lt;a class="headerlink" href="#something-challenging" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A new position is going to bring new challenges. It's new. You don't know the job.
But, I wanted it to be challenging after I made it over that initial period of
adjustment. I started looking for a job that would utilize my programming skills,
leadership skills from the projects I've led, and maybe some of the community
management skills I had from Team Vipers and various StackExchange communities I
participate in.&lt;/p&gt;
&lt;h2 id="the-search"&gt;The search&lt;a class="headerlink" href="#the-search" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I had my initial, if broad, criteria defined. The next step was to start the hunt.
I utilized several sites to help with the initial search and to help narrow
down the list of companies I'd really like to talk with.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://remoteok.io/"&gt;remote|ok&lt;/a&gt; - A job board that updates throughout the day, yet doesn't have
 thousands of postings. It is specific to the "IT-ish" world. This was helpful
 in finding companies that are open to remote jobs, because I'd see those companies
 listings repeatedly over the course of my hunt.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://weworkremotely.com/"&gt;We Work Remotely&lt;/a&gt; - Another "IT-ish" job board that updates one or two
 times a day. It has multiple categories of jobs and usually is pulling in
 positions from other job boards. I preferred using this over the source sites
 because this had a much smaller set of jobs and was restricted to my area of
 interest.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/jobs"&gt;Stack Overflow Jobs&lt;/a&gt; - I have a love/hate relationship with Stack Overflow
 Jobs. On the one hand, it had &lt;a href="https://meta.stackoverflow.com/search?q=user%3A189134+%5Bjobs%5D"&gt;so many UI/UX issues&lt;/a&gt;. On the other hand,
 it makes it really easy to find remote jobs and narrow it down to only jobs
 I'm interested in. This is where I eventually found the posting for the job I
 took.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If I'm being honest, my search for a job took over eighteen months. I found
several jobs that were interesting and that I applied for, but the process was
slow. There were several false starts, several job applications were ignored,
and several interviews that didn't move forward at either my choice or the
company's choice.&lt;/p&gt;
&lt;h2 id="keeping-it-all-straight"&gt;Keeping it all straight&lt;a class="headerlink" href="#keeping-it-all-straight" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I put out a lot of job applications. This meant that I needed to adjust my
resume and cover letter to each company. I needed to keep track of when I applied,
who I interacted with, when interviews were scheduled, and when to give up on
a job.&lt;/p&gt;
&lt;p&gt;Enter: &lt;a href="https://trello.com/"&gt;Trello&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Trello Job Search Board" src="https://andrewwegner.com/images/trello-job-board.png"/&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prep: This is a reminder to update resume and cover letter for each position,
 and a list of the labels I utilize. The colored labels made it easy to identify
 the current status, and whether this was a local or remote position.
 After searching for about nine months, I started to consider office positions
 in a few specific cities.&lt;/li&gt;
&lt;li&gt;Interesting Positions: All new jobs I was considering would go here. It'd
 consist of a link to the job posting. This was made really easy by utilizing
 a &lt;a href="https://trello.com/add-card"&gt;bookmarklet&lt;/a&gt; provided by Trello that would send any link to this list on
 this board.&lt;/li&gt;
&lt;li&gt;Companies to watch: As my hunt continued, I found several companies that
 seemed interesting or that had expressed interest in my skill set. I set up
 links to the job pages for each of these companies so that I could see if anything
 new and interesting was posted.&lt;/li&gt;
&lt;li&gt;Submitted applications: After updating my resume and cover letter, filling out
 the application forms, and pressing submit, a job posting would be moved from
 "Interesting Positions" to "Submitted Applications".&lt;/li&gt;
&lt;li&gt;Interviews: When a company liked an application and scheduled an interview, I'd
 move the card to this step. Additionally, I'd add a comment with the name of the
 people I'd be talking with - Human Resources representative, technical leads, managers -
 so that I knew who I'd be talking with.&lt;/li&gt;
&lt;li&gt;Recheck opening availability: If a card sat in "Interesting Positions" for a
 period of time, I needed to check if the position  was still available before
 finally submitting an application. There were many times that I'd mark a job
 as interesting and then never apply. This list helped keep the viable list of
 positions down to what was still available.&lt;/li&gt;
&lt;li&gt;Cold Opportunities / Rejections: Just as I ignored positions, my applications
 were ignored many times. Other times, an interview process would just fizzle out.
 These seemed like the company didn't want to send a rejection notice and hoped
 that ignoring me would provide a hint. It was unprofessional, and I wouldn't look
 at those companies again. Other times, official rejection responses would be sent
 back. I appreciated these, even though they were rejections.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="butler-for-trello"&gt;Butler for Trello&lt;a class="headerlink" href="#butler-for-trello" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The last list on the board was &lt;a href="https://butlerfortrello.com/"&gt;Butler for Trello&lt;/a&gt;. This is the system that
automated a lot of the moving of jobs through the process and applying proper labels.
When a new job was added to the "Interesting Positions" list, a due date was added
for one month from now. Triggering off this due date, the butler would move cards
to "Recheck" if the due date was exceeded.&lt;/p&gt;
&lt;p&gt;When a card was moved to "Submitted Applications" the due date was changed to be
three weeks from now. The thought here was that if I haded heard from the company
in three weeks, I was probably being ignored and thus rejected.&lt;/p&gt;
&lt;p&gt;This automation helped keep the board clean and usable. I was always presented
with a list of openings I was interested in that were current. Moving through
the interview process, the cards would be moved if a period of time was exceeded.
I didn't need to remember to move stuff based on when I submitted an application,
or when the last interview was. It just happened.&lt;/p&gt;
&lt;p&gt;It was amazing.&lt;/p&gt;
&lt;h2 id="getting-the-job"&gt;Getting the job&lt;a class="headerlink" href="#getting-the-job" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I said above, this was a long process. That list of cold opportunities and
rejections is pretty long. I talked to a lot of different companies and went
through a lot of different interviews. Eventually, though, I found a job
advertising a Senior Integration Tester at a new start up.&lt;/p&gt;
&lt;p&gt;The interview process consisted of 4 interviews - one with the Senior Vice President
of Development, and three individual interviews with team leads (my peers). I also
needed to submit a project demonstrating how I'd test the API.&lt;/p&gt;
&lt;p&gt;The interviews felt like conversations. We discussed my project. I had to defend
a few decisions, but there were no wrong answers. Everyone was professional, yet
personable.&lt;/p&gt;
&lt;p&gt;After all of this, an offer was presented and after some last minute "do I really
want to make a big change in my life" doubts were squashed, I accepted. I love the
job. &lt;/p&gt;</content><category term="job"></category><category term="technical"></category></entry><entry><title>Review of Udemy's AWS Serverless APIs &amp; Apps - A Complete Introduction course</title><link href="https://andrewwegner.com/aws-serverless-apis-apps-review.html" rel="alternate"></link><published>2017-10-20T11:17:00-05:00</published><updated>2017-10-20T11:17:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-10-20:/aws-serverless-apis-apps-review.html</id><summary type="html">&lt;p&gt;My review of the AWS Serverless APIs &amp;amp; Apps course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been involved with the &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt; spam hunting project for several years. In that time It's grown from
a small Python script to a large combination of Python, Ruby and user scripts. The infrastructure hasn't really changed
in that time, though, and it's starting to show. SmokeDetector, the Python script, is run by multiple users so that
random network problems that kill the instance don't take the entire system off line. Arguably, the project should
work on fixing this instability, but the alternative that we came up with works too.&lt;/p&gt;
&lt;p&gt;At least it did. Now this distributed way of running is starting to cause issues. Keeping each instance in sync
with one another is a very difficult problem. We've built a decent solution to this for handling spam patterns,
but we've failed to replicate this for other things like permission sets or notifications. Adding this involves
integration with GitHub and a series of new commands. It's painful.&lt;/p&gt;
&lt;p&gt;One of the recent discussions to solve this problem was a centralized database. That brings me to this course.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://ude.my/UC-1ESFUC2V"&gt;AWS Serverless APIs &amp;amp; Apps - A Complete Introduction&lt;/a&gt; by Maximilian Schwarzmüller on Udemy
looked like a good overview for AWS lambda and DynamoDB, two solutions the SmokeDetector project was looking
into using.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-course"&gt;Thoughts on the course&lt;a class="headerlink" href="#thoughts-on-the-course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course provides a good overview of Amazon's API Gateway, AWS Lambda and several other Amazon services. There
is a little bit of coding involved - using NodeJS - but a large majority is dedicated to working in the various Amazon
consoles. Except for one optional lecture, the entire course can be completed using Amazon's free tier. This is
great for a course and one of the factors I used to determine if I really wanted to take the course. The instructor
is very clear, throughout the course, which aspects cost additional money so that no unexpected charges show up
from Amazon.&lt;/p&gt;
&lt;p&gt;The course covers the API Gateway, AWS permissions, AWS Lambda, body mapping templates, DynamoDB, authentication with
Cognito and hosting a serverless SPA. At first glance this seems like a lot to cover in an 8 hour course. The instructor
has broken these into small digestible lectures that do a good job of introducing each new service, explaining the theory
behind each and then using the service to implement functionality into the course long project.&lt;/p&gt;
&lt;p&gt;A course long project is a good way to show how each of these Amazon services are useful to a larger project. Instead of
focusing on a small example project where it is difficult to expand the course work into the real world, a real world
project with various requirements is used. This project uses each of the services I mentioned above in a natural way.
Implementing new functionality doesn't feel forced, instead it is something that users would expect from a modern application.&lt;/p&gt;
&lt;p&gt;I am very happy with this course. Everything was very well presented. The project was useful because I can easily understand
how each of the Amazon services function. I also have a good idea how the console works and how to troubleshoot problems
because of the work that was done in this course.&lt;/p&gt;
&lt;p&gt;My only complaint with regard to this course is that the video lectures are interrupted with text based lectures consisting
of more details and links to documentation. I appreciate these links and used several of them, but the interruption of the
videos to present these broke the nice flow of the lectures. Presenting these links at the end of the section, I think would be
less of an interruption. This was a minor thing, though, and doesn't take away from how much I enjoyed the course.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I feel that I have a decent understanding of Amazon's services at this point. I am looking forward to applying this new
knowledge and, hopefully, improving the SmokeDetector infrastructure at the same time. I highly recommend this course
if you are thinking of migrating anything to Amazon. I feel much more comfortable about moving aspects of a project
to this new solution.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-1ESFUC2V"&gt;&lt;img alt="AWS Serverless APIs and Apps Completion" src="https://andrewwegner.com/images/udemy-aws-serverless-apis-apps.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Collecting Diamonds on Stack Exchange</title><link href="https://andrewwegner.com/collecting-diamonds-on-stack-exchange.html" rel="alternate"></link><published>2017-08-18T10:06:00-05:00</published><updated>2017-08-18T10:06:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-08-18:/collecting-diamonds-on-stack-exchange.html</id><summary type="html">&lt;p&gt;I've picked up a couple moderation diamonds recently. A reflection on the Stack Overflow election.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;It's been over two years since I first ran for moderator on Stack Overflow. &lt;a href="https://andrewwegner.com/i'm-running-to-be-a-moderator-of-stack-overflow.html"&gt;I've ran for moderator&lt;/a&gt; &lt;a href="https://andrewwegner.com/i'm-running-for-moderator-on-stack-overflow-again.html"&gt;three times&lt;/a&gt;, &lt;a href="https://andrewwegner.com/third-times-the-charm.html"&gt;previously&lt;/a&gt; on Stack Overflow. 
In each election I've done better, coming in fifth in the third election. Well, it's been a little over 8 months since the last one and new moderators are needed
again. I decided to run once more with the knowledge that if I lost, I probably wouldn't run again in the next election. &lt;/p&gt;
&lt;h2 id="nomination-phase"&gt;Nomination Phase&lt;a class="headerlink" href="#nomination-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The nomination phase started off as usual, with a handful of users posting their nomination. This time there were 12 candidates, meaning there would be a primary
to narrow it down to 10 before the final election. My nomination was the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I'm &lt;strong&gt;Andy&lt;/strong&gt;. I've answered the questions posted by the community &lt;a href="https://meta.stackoverflow.com/questions/352386/2017-moderator-election-qa-questionnaire/352388#352388"&gt;here&lt;/a&gt; I encourage you to take a look.&lt;/p&gt;
&lt;h2 id="why-should-you-vote-for-me"&gt;Why should you vote for me?&lt;a class="headerlink" href="#why-should-you-vote-for-me" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I've been a moderator on &lt;a href="https://communitybuilding.stackexchange.com/"&gt;Community Building&lt;/a&gt; for several years. I was appointed to a moderator position on &lt;a href="https://hardwarerecs.stackexchange.com/"&gt;Hardware Recommendations&lt;/a&gt;. I know the moderator 
tools and have worked with the current moderators.&lt;/li&gt;
&lt;li&gt;I'm active in the review queues (I am the top reviewer in the Low Quality Post reviewers, with over 26,500 reviews in this queue). I also enjoy the other 
moderation aspects of Stack Exchange.&lt;/li&gt;
&lt;li&gt;I believe that moderation can be tool assisted. I've helped to flag a sizable percentage of &lt;a href="https://meta.stackoverflow.com/questions/280546/can-a-machine-be-taught-to-flag-comments-automatically"&gt;comments&lt;/a&gt; on Stack Overflow. I've helped build the community 
&lt;a href="https://meta.stackexchange.com/questions/291301/can-a-machine-be-taught-to-flag-spam-automatically"&gt;spam detection bot&lt;/a&gt;. These types of tools help eliminate the obvious bad stuff so that moderation time can be spent on the less obvious stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have a history of good community moderation, am here consistently, and believe I can help the current team.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Candidate Score" src="https://andrewwegner.com/images/2017_candidate_score.png"/&gt;&lt;/p&gt;
&lt;h3 id="nomination-reflections"&gt;Nomination Reflections&lt;a class="headerlink" href="#nomination-reflections" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An astute reader may have noticed this is pretty similar to previous nomination posts. There are a couple major differences though. The first thing is that I am the 
the number one Low Quality Posts reviewer on the site. I am pretty proud of this particular statistic. It shows just how much work I've done during my tenure at Stack 
Overflow to improve the quality of the site. The unfortunate thing is that I'd probably lose this position as a moderator because they don't sit in the review queues.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Low Quality Posts" src="https://andrewwegner.com/images/number_1_low_quality_reviewer.png"/&gt;&lt;/p&gt;
&lt;p&gt;The other major change was that I had picked up a moderator position on Hardware Recommendations. That happened at the end of June. Hardware Recommendations is about ten 
times the size of Community Building (a site I've moderated for several years). It's also a couple orders of magnitude &lt;em&gt;smaller&lt;/em&gt; than Stack Overflow. &lt;/p&gt;
&lt;h2 id="primary-phase"&gt;Primary Phase&lt;a class="headerlink" href="#primary-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The most exciting part of the election season is the primary phase. The community can see the scores of users over time and have built tools to watch those numbers change 
over time. It turns out that this time, my numbers were really high.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Primary Results Table" src="https://andrewwegner.com/images/2017-07-SO-Election-Primary-Results.png"/&gt;&lt;/p&gt;
&lt;p&gt;There were plenty of good people in the election this time. One interesting thing that I found was that a lot of candidates, like me, were supportive of automation. Several
users utilized bots that posted low quality content to various chat rooms. This is a big change from previous elections. It was a welcome change. I think that automated
quality content checking can help a lot.&lt;/p&gt;
&lt;h2 id="election"&gt;Election&lt;a class="headerlink" href="#election" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The election ended on August 1st. (&lt;a href="https://andrewwegner.com/a-decade-at-caterpillar.html"&gt;A busy day for me, apparently&lt;/a&gt;). It was a close election. Most surprisingly, no one won in the first round with everyone else 
picking up carry over votes to get second. I think that speaks to the quality of the candidates. After &lt;a href="https://www.opavote.com/results/5927932925050880"&gt;8 rounds in OpaVote&lt;/a&gt;, both Cody Gray and I were elected the two newest moderators on Stack Overflow!&lt;/p&gt;
&lt;p&gt;&lt;img alt="Election Results - OpaVote" src="https://andrewwegner.com/images/2017_opavote_results.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Election Results" src="https://andrewwegner.com/images/2017_election_results.png"/&gt;&lt;/p&gt;
&lt;h2 id="post-election"&gt;Post Election&lt;a class="headerlink" href="#post-election" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The election ended a few weeks ago. I handled more moderator flags in my first hour as a Stack Overflow moderator than I had at both Community Building and 
Hardware Recommendations combined. What I'm saying...Stack Overflow has a &lt;em&gt;ton&lt;/em&gt; of flags that need to be handled. In good news, since the election, we have gotten the
moderator queue down from about 1,100 flags to about 75 at any given time. I doubt it will stay that low, but it's still nice to see that I was immediately helpful.&lt;/p&gt;
&lt;p&gt;Finally, since the election I turned off the comment flagging bot. It had been used for just over 3 years. The community is currently &lt;a href="https://meta.stackoverflow.com/q/354719/189134"&gt;debating&lt;/a&gt; whether or not it should
run under a moderator account. The thing that I am finding more interesting about this discussion is that the community seems to agree it's helpful, &lt;a href="https://meta.stackoverflow.com/a/354723/189134"&gt;respects&lt;/a&gt; the 99+%
accuracy, would love for Stack Exchange themselves to run this tool, but doesn't want the bot to run with moderator privileges. There is, however, a very sizable portion of
the community that &lt;em&gt;does&lt;/em&gt; want this done under my account. We'll see how this plays out, but I'm hoping to be able to use the bot again soon.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="moderation"></category></entry><entry><title>A reflection on my decade at Caterpillar</title><link href="https://andrewwegner.com/a-decade-at-caterpillar.html" rel="alternate"></link><published>2017-07-31T12:00:00-05:00</published><updated>2017-07-31T12:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-07-31:/a-decade-at-caterpillar.html</id><summary type="html">&lt;p&gt;My career at Caterpillar has come to an end. This is a reflection on the last decade.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="right-out-of-college"&gt;Right out of college&lt;a class="headerlink" href="#right-out-of-college" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Ten and a half years ago, I was the manager at the university help desk and less than six months from graduation. I hadn't
heard back from the company I interned with. I was getting concerned. I went to the university's yearly career fair. I had
companies I wanted to talk with, a few that looked interesting and a handful that I knew handed out decent freebies, so I'd
stop by those too. After all, what college student is going to turn down a freebie?&lt;/p&gt;
&lt;p&gt;I don't remember what company I was speaking with. I remember it wasn't going well. The interviewer was making unfunny jokes about
the location of my home town and how far it was from their place of operations. I was slowly trying to extract myself from the
conversation and really wanted to take my resume back too. Finally, I was free and turned to walk away and almost knocked over
a recruiter from the next booth over. I apologized and she beamed at me. She also apologized but said it was because she'd been
listening to the conversation I'd just had. I had sounded like someone she was looking to hire.&lt;/p&gt;
&lt;p&gt;I stepped over to the booth and was introduced to the Logistics arm of Caterpillar. The interview on campus and follow up all day
interviews about two weeks later went very well. I was offered a job at a salary I was happy with. It turned out that the
company I'd had my internship with would eventually offer me a job and not even come close to the starting salary Caterpillar offered,
which made me even more satisfied. I was to start in June following graduation.&lt;/p&gt;
&lt;h2 id="the-first-day"&gt;The first day&lt;a class="headerlink" href="#the-first-day" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My degree is not in Logistics or transportation management, yet that would be the team I was joining. I was given my boss's name. I showed up,
bright eyed and ready to begin my career at a company known the world over, and was told by the receptionist that my boss no longer worked
at this facility. She'd moved to a new area of the company less than two weeks ago.&lt;/p&gt;
&lt;p&gt;Eventually, I was introduced to my new boss and the team. I was handed off to my team lead and we promptly started going over a gigantic system.
I remember being overwhelmed and confused. My college degree didn't use terms like "bill of lading" or "route optimization". I tried to keep up.
Eventually, lunch rolled around. I was handed a set of instructions on how to get myself added to the system and told to follow those after lunch.
I was young and eager. I followed the directions. In doing so, I learned how to add myself to the system. The company also learned a lesson that day:
their instructions were wrong. I followed exactly what I was given. In doing so, I locked out the system administrator account for the transportation
management system. This was a 'mistake' that is still brought up a decade later. On day one, it's a horrifying experience. A bit later, it's a harmless
first day mistake that took a few minutes for an experienced technician to resolve.&lt;/p&gt;
&lt;p&gt;Fortunately, day two went much better.&lt;/p&gt;
&lt;h2 id="a-revolving-door-of-bosses"&gt;A revolving door of bosses&lt;a class="headerlink" href="#a-revolving-door-of-bosses" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first four years at Caterpillar, I met many great transportation consultants. They were very smart, had worked with many other companies and had
been all over the world. I was a bit jealous of their ability to travel. These consultants taught me about managing transportation, about setting up
a system for a new company, and helped me design and build tools to improve Caterpillar's ability to do the same. They also taught me something else
about Caterpillar: if you aren't a Caterpillar employee, your opinion matters less. They are paid a &lt;em&gt;ton&lt;/em&gt; more than me and my more senior coworkers, but
if an idea doesn't come from an employee, it's not given fair consideration by management.&lt;/p&gt;
&lt;p&gt;The problem with this should be obvious. Those with the most experience setting up and managing systems to get parts and supplies on time to our facilities
weren't able to provide suggestions for how to improve the system even more. System growth stagnated and my first boss was replaced. The second boss came
from overseas and had experience we were trying to move to the US. Their assignment in the US lasted a year or so, and I was given a new boss again. A fourth
boss was assigned about nine months before I eventually moved to another division. Four bosses in four years.&lt;/p&gt;
&lt;p&gt;Through all of this, though, I built and managed some amazing applications. These included a brand new order processing system, a container management
system, and a dashboard to unify all of the different systems into one quick at a glance system. During one of the boss transitions, I was moved to sit with
my users and learn their pain points. This was one of the best decisions that came out of these first four years. By sitting with the users and talking with
them daily, I learned exactly what they had problems with. I designed simple work-arounds, automated external tools and ways to improve their pain points. My
yearly review reflected how much the customers appreciated my help and me sitting with them.&lt;/p&gt;
&lt;p&gt;Eventually, I was moved back with the rest of the IT team. At that point, I felt a bit like an outsider. I'd been sitting with my users for over a year. None of
my coworkers had been given the opportunity to do so. I was moving from the trenches back to the ivory tower. I lost the interaction with my users and I think
my team suffered because of this. We were slower to respond to issues, because now the users had to go through the official channels of calling the helpdesk
and waiting until a member of my team was assigned the problem to work with. Simple questions couldn't be answered with a two minute conversation.&lt;/p&gt;
&lt;p&gt;During this move, a third party logistics service was brought in to 'improve' our processes. It turns out that a start up company without a large customer doesn't
know how to manage transportation for a company that spends hundreds of millions of dollars a year to move stuff around. The relationship didn't improve over time.
Instead, each side attempted blame the other for the smallest of issues. After being assigned the task of ensuring our data was transferred every day by an early time,
I started looking for another position in the company. I was tried of getting up early and missing time with the family.&lt;/p&gt;
&lt;h2 id="the-long-drive"&gt;The long drive&lt;a class="headerlink" href="#the-long-drive" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I found a new position fairly quickly. It was recommended to me by a friend I knew outside of work. It was a Python development position for a tool used by the entire
division. I interviewed, was offered the job, and then told by my boss I couldn't move yet. Despite asking ahead of time, the answer had changed once I was actually
offered the job. I spent months waiting to be allowed to move. Eventually, I was allowed to move.&lt;/p&gt;
&lt;p&gt;The one down side of this new job was its distance from my house. My first job was about 15-20 minutes away. This new one was 45 minutes away, on a good traffic day.
It was worth it though. I liked the job better. I worked much more closely with my users and over the next six years the job evolved from supporting a desktop application
to building an entire analytic environment. We built a system to track failure reasons and determine who was responsible for paying a warranty (saved millions of dollars every year since implementation), a predictive failure dashboard allowing service engineers to reach out to customers before something happened, expand from desktop to web
development and deploy a large expensive environment for hosting tons of sensor data from machines around the world.&lt;/p&gt;
&lt;h2 id="the-down-turn"&gt;The down turn&lt;a class="headerlink" href="#the-down-turn" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Unfortunately, the economic situation for Caterpillar, especially after the down turn, was always "it's going to get worse before it gets better". For years, I watched
rounds of layoffs. I watched employees with decades of experience be escorted out while under-performing employees remained in place. Decades and decades of knowledge
walked out the door, never to return and were replaced, most often, with nothing.&lt;/p&gt;
&lt;p&gt;My team avoided the brunt of these layoffs, but they were never far from our doorstep. The looming threat of "maybe next time", was always there. With a large number
of layoffs, it's not surprising that someone would walk out with confidential information. It happened. IT and HR cracked down on the rest of us. First came the removal
of little things - USB access - then came the increased security on the laptops. Security software that took 4GB of memory on a fresh install. On day one of a new machine,
half of your system resources went to "security". Restarting your computer was a 15 minute process due to this software.&lt;/p&gt;
&lt;p&gt;Then HR stated that you &lt;em&gt;must&lt;/em&gt; be in the building 8 hours a day. Working from home in the evenings didn't count. This was the straw that started my job search. With a 45-60
minute drive each way, I'd come to an agreement with my boss that I'd spend a majority of the day in the office but do releases in the evenings from home. This allowed me to
be with my family at nights and finish the day after they'd gone to bed. HR's new rules eliminated this. So, I worked out the ability to work from home two days a week. This
still wasn't ideal for those three nights that I was home later, but it improved home life a bit, for a while.&lt;/p&gt;
&lt;p&gt;The kids were growing and starting to be involved in more after school activities. Activities that I had to pick and choose whether or not I could attend due to this
decree to keep my chair warm in the office. I hated missing these things. The kids hated me missing them. Then HR "reminded" us that it was still required that we are
in the office for 8 hours a day. This didn't feel like a professional work environment any more. It felt like we were being treated like little kids by HR.&lt;/p&gt;
&lt;h2 id="the-new-job"&gt;The new job&lt;a class="headerlink" href="#the-new-job" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Eventually I found a new job. My first day is, officially, tomorrow. Today is my last day at Caterpillar. It is unfortunate that I have to leave. I really enjoyed the work
and the people. My managers have worked with me (and the rest of my team) to help us be as flexible as possible. But, I can't ignore that I'm missing out on family
things more and more. Caterpillar says things like "work-life balance", but I'm not sure they actually believe that any more.&lt;/p&gt;
&lt;p&gt;If they do, it's not a "work life balance" for families where both parents are employed - especially if they aren't both employed at Caterpillar. A week before I found
the new job, a new flexible work schedule was announced where employees could work 80 hours over the course of 9 days instead of the usual 10, giving you every other Friday
off. At first glance, that sounds appealing. But, after minute or so of figuring of how it works there is a fatal flaw: I'd be home even later over the course of 9 days and
then be home on a Friday - when the rest of the family is at work or school. That doesn't solve anything for me.&lt;/p&gt;
&lt;p&gt;The new job is a full time remote position. I'll be home every day. I can step out for an hour to go to a class room party or take a morning off to go on a field trip. The flexibility I've been told about is amazing. The official vacation policy is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Employees have the authority to use their judgment and discretion and take temporary periods of time away from work as vacation, without loss of pay, as their work permits.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Sold!&lt;/p&gt;
&lt;h2 id="goodbye-yellow"&gt;Goodbye Yellow!&lt;a class="headerlink" href="#goodbye-yellow" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Caterpillar has been my home for a decade. Despite my complaints about work life balance, above, I'm not leaving the company with malice or ill-intent. Caterpillar is a
large company and will continue long after I've left. The people that are there, especially my coworkers, are intelligent people who build amazing things. Unfortunately, 
in my case, Caterpillar seems to have forgotten that those intelligent people like to spend time doing things other than keeping their chairs warm.&lt;/p&gt;
&lt;p&gt;I am thankful for the decade of experiences, the professional relationships, and chances to work on interesting projects. Caterpillar, I wish you well in the future. If you
are going to listen to one piece of advice from a former employee, I recommend you take a look at those employees in your work force where the household is a dual career house.
Your work life balance initiatives do not appear to account for those employees and it is for that reason that you lost me.&lt;/p&gt;
&lt;p&gt;Goodbye Yellow. I'll always remember my time with you.&lt;/p&gt;</content><category term="job"></category></entry><entry><title>Review of Udemy's Python and Django Full Stack Web Developer Bootcamp course</title><link href="https://andrewwegner.com/django-fullstack-bootcamp-course-review.html" rel="alternate"></link><published>2017-06-28T06:16:00-05:00</published><updated>2017-06-28T06:16:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-06-28:/django-fullstack-bootcamp-course-review.html</id><summary type="html">&lt;p&gt;My review of the Python and Django Full Stack Web Developer Bootcamp course on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After ploughing through &lt;a href="https://andrewwegner.com/deep-learning-prereq-numpy.html"&gt;two machine learning&lt;/a&gt; &lt;a href="https://andrewwegner.com/deep-learning-prereq-linear-logistic-regression.html"&gt;prerequisite courses&lt;/a&gt;, I wanted to have a change in content for the next
course I took. I've used Django in the past to build &lt;a href="https://github.com/AWegnerGitHub/IRVING"&gt;IRVING&lt;/a&gt; - a dashboard that allows users to run queries against many
database types and display the results in one location. The majority of this was done almost 6 years ago though. It was built
to assist in a job I no longer hold. Since then, I've ignored it and haven't used Django for a major project. I have used it to
test a small snippet of code here or there, but never a complete application.&lt;/p&gt;
&lt;p&gt;I remember liking Django. To that end, I decided to take Jose Portilla's &lt;a href="https://www.udemy.com/python-and-django-full-stack-web-developer-bootcamp/learn/v4/overview"&gt;Python and Django Full Stack Web Developer Bootcamp&lt;/a&gt;
course on Udemy.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-course"&gt;Thoughts on the course&lt;a class="headerlink" href="#thoughts-on-the-course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am conflicted on how to rate this course. On the one hand, it covers a lot in the 30ish hours that the lectures take. Starting at
the very basics and moving through more advanced Django topics, it covers HTML and CSS then moves to Bootstrap, Javascript, the DOM,
jQuery, and Python before finally getting to Django. On the other hand, it moves through those basic lectures very slowly. Django isn't
even reached until two thirds of the way through the course.&lt;/p&gt;
&lt;p&gt;The lectures were a combination of hands on coding and an explanation of what the code is doing. The instructor types slightly
faster than me. This was a problem only at transitions between files, for example moving between an HTML file and a CSS file. I found myself
rewinding the video lectures many times around these transitions.&lt;/p&gt;
&lt;p&gt;One thing that I liked very early on in the lecture was the introduction of GitHub's &lt;a href="https://atom.io/"&gt;ATOM text editor&lt;/a&gt;. I've used this once before, for a job
interview that went very poorly (another story, for another time). I'd heard good things about it though. I used it throughout the course as a way to
force myself to use something other than PyCharm. Now that the course is complete, I have decided that I like ATOM, but not enough to switch from
PyCharm. It does have some nice features, especially with plugins, that I may utilize when building boiler plate code and templates though.&lt;/p&gt;
&lt;h2 id="foundation-vs-django-content"&gt;Foundation vs Django content&lt;a class="headerlink" href="#foundation-vs-django-content" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The foundational material - HTML, CSS, Bootstrap, Javascript, jQuery and even the Python - dragged on a little long for my taste. As I
mentioned above, this foundation took up the first two thirds of the course. I'd have preferred it if more time could be spent covering
other aspects of Django, especially some of the concepts that are thrown at the student in the last clone project.&lt;/p&gt;
&lt;p&gt;The Django content, itself, was great. It started at basics like setting up a project and single application within the project and
moved through URL routing, templates, views and briefly touched on the admin side. There were advanced topics on class based views and
the debug toolbar, both of which are important when developing.&lt;/p&gt;
&lt;p&gt;I can't help feeling that important things were missed though. For example, the admin side is barely touched. It is incredibly capable, yet the
most that is done in this course with the admin backend is registering a model to appear. Groups and permissions aren't touched at all. Customizing
views in the backend aren't mentioned, either. Another thing that I was hoping would be covered as part of the "and much,much more!" bullet in the
course description was both &lt;a href="https://docs.djangoproject.com/en/1.11/topics/signals/"&gt;signals&lt;/a&gt; and &lt;a href="https://www.djangoproject.com/weblog/2016/sep/09/channels-adopted-official-django-project/"&gt;channels&lt;/a&gt;, but they are not mentioned.&lt;/p&gt;
&lt;p&gt;Clone projects are useful in giving students a "real world" example that they are familiar with to bring everything they've learned together. There
are two such projects in this course, a blog and a message board/social media site. The blog one was a logical extension of the 5 parts that were
covered by Django. The message board, however, wasn't as useful. In an effort to be more "real world", the instructor missed a lot of steps in the
preceding foundational lectures. This project introduces multiple applications in the same project, but never introduced that concept previously
and doesn't expand on it much here. Instead, the project becomes a combination of speed coding to keep up with what's happening in the lecture and
copy and pasting code from the notes when the instructor does the same thing. I appreciate the more realistic project, but for all the time that was
spent building the foundation of Django knowledge, there is a big gap between the last lecture and this clone.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was worthwhile, once I made it through the foundational courses. It was a great refresher for what I'd done 6 years ago. Either I did
things very inefficiently then, or Django has had a &lt;em&gt;ton&lt;/em&gt; of improvements (or both), but looking back at IRVING, I see many things that could be
improved. I'm not sure if I actually will though, just due to not using the application any longer.&lt;/p&gt;
&lt;p&gt;The long foundational courses either should have been condensed. I would have rather had more focus on Django and covered more topics there. This
is especially true after completing the second clone project. New concepts were used in this project, but glossed over as "there is excellent
documentation on this", instead of the in depth explanations that were provided earlier in the course.&lt;/p&gt;
&lt;p&gt;I'd recommend this course for the Django topics. However, if you are coming into the course with any type of web development background (even the
relatively basic one I have), be prepared to be bored during the first half of the course.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-1VGWNREH"&gt;&lt;img alt="Python and Django Full Stack Web Developer Bootcamp Award" src="https://andrewwegner.com/images/udemy-django-full-stack-bootcamp.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Stack Overflow's Problem - Feedback from an experienced user</title><link href="https://andrewwegner.com/stack-overflows-problem-feedback-from-an-experienced-user.html" rel="alternate"></link><published>2017-05-22T23:45:00-05:00</published><updated>2017-05-22T23:45:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-05-22:/stack-overflows-problem-feedback-from-an-experienced-user.html</id><summary type="html">&lt;p&gt;Stack Overflow appears to have made several poor decisions in the past few years. This is feedback from an experienced community member on how those decisions are perceived&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Stack Overflow launched in 2008. As it nears it's 9th year of operation, I am afraid the resource that I depend on is losing it's way. Stack Overflow launched after I graduated college. I can't imagine how helpful it would have been during that time period, but it's been invaluable in my professional career. I &lt;a href="https://stackoverflow.com/users/189134/andy?tab=profile"&gt;joined&lt;/a&gt; the site about a year after it's public launch, in October 2009.&lt;/p&gt;
&lt;p&gt;In that time, I've gone from lurker to participant to moderator candidate (several times). I know Stack Overflow and Meta Stack Overflow. I am a moderator on another Stack Exchange site and have a good understanding of how the network operates. I also am one of the &lt;a href="https://andrewwegner.com/images/top_lqp_queue.png"&gt;most prolific reviewers&lt;/a&gt; in the Stack Overflow &lt;a href="https://stackoverflow.com/review/low-quality-posts/stats"&gt;Low Quality Posts review queue&lt;/a&gt; and have built several applications that work with the Stack Exchange API. I am a power user and know the network and the community.&lt;/p&gt;
&lt;p&gt;With those credentials out of the way, I want you to understand that I am active on the network. I am in good standing on Stack Overflow and am not a disgruntled user. I am a concerned user. I am getting more and more concerned that Stack Overflow - the company - is losing it's way.&lt;/p&gt;
&lt;p&gt;This post isn't another "Stack Overflow sucks" post (Google if you're curious). I'm going to present a few areas that I'm concerned about and hopefully provide either my suggestions for improvement or acknowledge that I don't know the solution but want the team to be aware of in the future. I still believe Stack Overflow is an incredible resource. I'd just like it to fix some of the perceived missteps that have occurred over the past two years.&lt;/p&gt;
&lt;h2 id="whats-going-wrong"&gt;What's going wrong?&lt;a class="headerlink" href="#whats-going-wrong" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the past two years, Stack Overflow has made several changes that the established community hasn't liked. Some of these changes still are not liked. These changes include the Teams feature, the new top bar, the Stack Overflow (versus existing Stack Exchange) mobile app, and Documentation. There have also been minor missteps that have caused a rift between portions of the community and the company. These areas include multiple political stances, and a number of post quality improvements that haven't been made.&lt;/p&gt;
&lt;p&gt;Each of these, separately, is a minor problem that could be worked through and moved on from. The problem I'm seeing is that taken together, all of these are causing a rift between users, power users and the community.&lt;/p&gt;
&lt;p&gt;Let's work through each of these items.&lt;/p&gt;
&lt;h3 id="teams"&gt;Teams&lt;a class="headerlink" href="#teams" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Teams was &lt;a href="https://meta.stackoverflow.com/questions/307513/189134"&gt;announced&lt;/a&gt; in October 2015 and &lt;a href="https://meta.stackoverflow.com/questions/308601/189134"&gt;clarified&lt;/a&gt; a week later. It was then &lt;a href="https://meta.stackoverflow.com/questions/330427/189134"&gt;shut down&lt;/a&gt; after nine months. The &lt;a href="https://stackoverflow.com/teams/"&gt;page&lt;/a&gt; it used to go to now has the following blurb (emphasis is mine):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Teams was in private beta for almost a year with 295 teams created and while we believe in its potential value, after a lot of consideration we’ve decided to un-ship the idea for the time being. We’ve realized that making a successful version of the Team page, as we originally proposed would ultimately take more time and resources than we want to devote to it. &lt;strong&gt;Our resources are currently allocated on projects to enhance and improve quality on Q&amp;amp;A, Documentation, and Jobs on Stack Overflow, as a result we don’t have the dedicated developers to get Teams to its fullest potential.&lt;/strong&gt; The intention was to add more features to Teams, but we never expanded it to anything beyond a team description.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The emphasized section sounds good, except that the one section that is taking up a majority of time (Documentation) has it's own major issues. The area that many power users want developers to focus on is Q&amp;amp;A.&lt;/p&gt;
&lt;p&gt;The problem with Teams, and many of the projects mentioned in this post, is that this was a feature that removed focus on areas the community wanted improved. Meta Stack Overflow has been asking for improvements to reduce the number of low quality posts for years. Moderators have been asking for better tooling. The review queues are overflowing with tasks and the number of users performing reviews isn't high enough to keep up. Teams was built without a true end goal and users weren't entirely sure what to do with it. This was the first in a series of mis-steps that continue to plague community interactions when new features are announced.&lt;/p&gt;
&lt;h3 id="top-bar"&gt;Top Bar&lt;a class="headerlink" href="#top-bar" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The new top bar was &lt;a href="https://meta.stackoverflow.com/questions/337745/189134"&gt;announced&lt;/a&gt; in November 2016. It went through a &lt;a href="https://meta.stackoverflow.com/questions/341806/189134"&gt;handful&lt;/a&gt; of &lt;a href="https://meta.stackoverflow.com/questions/343103/189134"&gt;iterations&lt;/a&gt; before being &lt;a href="https://meta.stackoverflow.com/questions/343653/189134"&gt;released&lt;/a&gt; in mid-February 2017. During the iterations users provided feedback. When initially released, though, much of this feedback felt ignored. Things like &lt;a href="https://meta.stackoverflow.com/a/343216/189134"&gt;notification overload&lt;/a&gt;, &lt;a href="https://meta.stackoverflow.com/q/343483/189134"&gt;stickiness of the top bar&lt;/a&gt;, and &lt;a href="https://meta.stackoverflow.com/a/346653/189134"&gt;hidden review counts&lt;/a&gt; were all mentioned during the three months of testing but not implemented until the change was live to millions of users.&lt;/p&gt;
&lt;p&gt;After three months of usage, a larger problem was noticed. One of the review queues was &lt;a href="https://meta.stackoverflow.com/q/349118/189134"&gt;constantly full&lt;/a&gt;. One of the changes that was made with this top bar was that the "Review" button no longer linked directly to the "Suggested Edits" review queue. Now it went to the page showing all review queues. Users that used to click once to get to a review queue were now presented with a list of queues to work in. Some of these queues are much more time consuming that others. It turns out the number of &lt;a href="https://meta.stackoverflow.com/a/349125/189134"&gt;reviews being done has decreased significantly&lt;/a&gt; since the top bar was implemented.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/stackoverflow_active_reviewers_per_week.png"&gt;&lt;img alt="Active Reviewer per week" src="https://andrewwegner.com/images/stackoverflow_active_reviewers_per_week.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The spike in reviews in February 2017 is when the new top by was released. Since that release, the number of reviewers has plummeted. This has been attributed to notification fatigue and not linking users directly to the Suggested Edits queue.&lt;/p&gt;
&lt;p&gt;Three months after implementation, it took the &lt;a href="https://meta.stackoverflow.com/q/349204/189134"&gt;community asking for results&lt;/a&gt; (&lt;em&gt;disclaimer: I asked the question&lt;/em&gt;), to find out how the top bar has been performing. It turns out that the top bar is &lt;a href="https://meta.stackoverflow.com/a/349386/189134"&gt;performing decently well&lt;/a&gt; compared to what the developers were expecting, with the exception of fewer review tasks being performed.&lt;/p&gt;
&lt;p&gt;The problem with this project, is that it's felt unneeded and has materially impacted one of the quality control features of the site. There is still a vocal group of users that don't like it because it doesn't match the rest of the network. Several are concerned about the review queue problem. Experienced users felt that they were ignored during the beta tests. Users provided feedback and examples of problems and it was only after implementation when millions of other users experienced the same thing that these changes were made.&lt;/p&gt;
&lt;h3 id="mobile-app"&gt;Mobile App&lt;a class="headerlink" href="#mobile-app" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A recent announcement (as in last week, at the time of this post) announced a new &lt;a href="https://meta.stackoverflow.com/q/349255/189134"&gt;Stack Overflow mobile application&lt;/a&gt;. The community response was not positive. Users asked why a new application was being built when one already existed (the response was "branding"). Users asked why the new app was less functional than the existing one (it's limited to Stack Overflow versus the entire Stack Exchange network). Users asked why it took a year to develop and why the existing application hasn't received bug fixes in that year.&lt;/p&gt;
&lt;p&gt;I think one of the most disappointing things about this is a &lt;a href="https://meta.stackoverflow.com/questions/349255/stack-overflow-now-has-its-own-app-on-ios-and-android#comment474055_349271"&gt;response&lt;/a&gt; I received in the comments from the VP of Engineering:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@Andy You're right, it wasn't worth a year. There's a long, sad story here, but it was originally expected to only take a few months and... well, here we are a year later. We decided to go ahead and launch and see what we can learn, and we'll reassess from here. – David Fullerton? May 17 at 16:26&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Another user expressed the dissatisfaction in a &lt;a href="https://meta.stackoverflow.com/a/349335/189134"&gt;very pointed way&lt;/a&gt;. They provided a list of features that the community has asked for over the years that many feel have been ignored. The VP's &lt;a href="https://meta.stackoverflow.com/questions/349255/stack-overflow-now-has-its-own-app-on-ios-and-android#comment474166_349335"&gt;response&lt;/a&gt; to this wasn't encouraging either:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I appreciate that there are a lot of issues on Stack Overflow that need to be addressed, and maybe we haven't been responding to them as quickly as we should. But Stack Overflow Q&amp;amp;A is a big, established product, most of the problems left are hard, and we can't let maintenance become the only thing we work on or we'll just slowly run out of money and go out of business. We are trying to both maintain Q&amp;amp;A and solve new problems for developers and reach new audiences. The latter is hard, and maybe we'll fail on a lot of our ideas, but we're not going to stop trying. – David Fullerton? May 17 at 21:10&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This sounds like work on the Q&amp;amp;A side is feature frozen at this point. They are done innovating in this area and instead are focused on drawing in users via other features - like Jobs or Documentation. Multiple times in the comments the new app was promoted as being able to use the Dev Story or Jobs features in the future. Perhaps it's just me, but I don't apply for jobs via my phone. That doesn't seem like a good way to really put the effort needed into a cover letter or application.&lt;/p&gt;
&lt;h3 id="documentation"&gt;Documentation&lt;a class="headerlink" href="#documentation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now we've reached Documentation. This is the project that's sucked up development time over the past two years. This is the project that Stack Overflow developers are defending tooth and nail and the community has all but given up on.&lt;/p&gt;
&lt;p&gt;Documentation was &lt;a href="https://meta.stackoverflow.com/q/303865/189134"&gt;announced&lt;/a&gt; back in August 2015. It's had a ton of &lt;a href="https://meta.stackoverflow.com/a/340826/189134"&gt;updates&lt;/a&gt; since then. It was met with initial enthusiasm but that quickly turned around. When the system launched for all users, one of the first complaints was that the reputation generated via documentation was doing back things to the main Q&amp;amp;A site. This resulted in a &lt;a href="https://meta.stackoverflow.com/q/328703/189134"&gt;massive recalculation of reputation&lt;/a&gt; and resulted in many users losing &lt;em&gt;a lot&lt;/em&gt; of their internet points.&lt;/p&gt;
&lt;p&gt;Another change that was announced with the introduction of a new &lt;a href="https://meta.stackoverflow.com/q/331663/189134"&gt;review queue for documentation&lt;/a&gt;. Initially, developers didn't expect the low quality to begin immediately, it seems. Long time users weren't surprised. Now we've reached the point where the company is realizing that the users knew what they were talking about. &lt;a href="https://meta.stackoverflow.com/q/349410/189134"&gt;Documentation is undergoing a massive change&lt;/a&gt;, to the point that much of it is being completely redone - not fixed - scraped and redone.&lt;/p&gt;
&lt;p&gt;This project has years worth of feedback from the community that has been ignored. It is the black sheep of Stack Overflow and many community users feel that quality of the content is lacking so badly that they don't participate any longer. This feeling isn't helped that many users have been explaining &lt;em&gt;why&lt;/em&gt; things aren't working for a while and it's only after two years the developers are starting to realize the private beta testers, public beta testers and experienced community users mentioned many of these problems. In this particular instance, the company took &lt;a href="https://blog.codinghorror.com/listen-to-your-community-but-dont-let-them-tell-you-what-to-do/"&gt;Jeff Atwood's advice&lt;/a&gt; (co-founder or Stack Overflow) to not let the community tell you what to do to heart. To the company's surprise, a community of developers that live in programming documentation had decent thoughts on what does and does not work in programming documentation.&lt;/p&gt;
&lt;h3 id="politics"&gt;Politics&lt;a class="headerlink" href="#politics" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For many users, the lack of true social features on Stack Overflow and across the Stack Exchange network has been a good thing. You can't easily follow a single user, you can't send private messages to a user, and you can't really do anything on the site that isn't public to everyone. The focus is on content, not opinions or social interactions.&lt;/p&gt;
&lt;p&gt;This breaks down once and a while though when a big political thing occurs. The two most frequently mentioned instances are the &lt;a href="https://meta.stackoverflow.com/a/297871/189134"&gt;response&lt;/a&gt; to the &lt;a href="http://s3.documentcloud.org/documents/2111821/obergefell-v-hodges.pdf"&gt;Obergefell v. Hodges&lt;/a&gt; Supreme Court decision and the response to President Trump's &lt;a href="https://meta.stackoverflow.com/q/342440/189134"&gt;initial immigration executive order&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Both of these caused huge uproars within the community when the company took a stand. These stands caused problems due to users holding opposite political views, users not wanting politics on their programming site, users not wanting to deal with the drama caused by the vocal members of the other groups. This led to an &lt;a href="https://meta.stackoverflow.com/q/342903/189134"&gt;apology&lt;/a&gt;. The community wasn't pleased with this apology. Users mentioned in multiple answers to this apology that they don't want the company to post such political agendas on the site. It's out of place for a programmer community. Both of these instances are still brought up on Meta when the community feels that the company is imposing on them.&lt;/p&gt;
&lt;p&gt;I don't really have advice or suggestions on this problem other than "I don't want to see this on Stack Overflow, because these hot button issues cause so much drama that nothing gets accomplished". These posts grind Meta and chatrooms to a halt while everyone expresses their opinion on the post, on the post's existance, on one another and on related issues.&lt;/p&gt;
&lt;h3 id="quality-improvements"&gt;Quality Improvements&lt;a class="headerlink" href="#quality-improvements" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Finally, the community has been asking for years about ways to improve the quality of posts on the site. Stack Exchange &lt;a href="https://meta.stackexchange.com/q/285889/186281"&gt;started a project to improve the quality&lt;/a&gt; back in October 2016. This generated 80 different suggestions on how the community sees "quality improvement" taking place. Since then there haven't been any updates on the status of this project or even subprojects.&lt;/p&gt;
&lt;p&gt;This was brought up during all of the projects listed above by long time users. The hope was that this quality project would help. Being ignored hasn't brought any good feelings. The lower quality has been measurable and seen less participation from experienced users.&lt;/p&gt;
&lt;h2 id="the-fix"&gt;The Fix&lt;a class="headerlink" href="#the-fix" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Above I've pointed out several issues that I've seen over the past two years. These issues are part of a bigger problem though. It seems that Stack Overflow doesn't know to how handle it's community size any longer. It's in the top 300 sites visited in the US and receives &lt;a href="https://www.quantcast.com/stackoverflow.com#trafficCard"&gt;half a billion views globally per month&lt;/a&gt;. Couple this with the fact that they &lt;a href="https://meta.stackoverflow.com/questions/349255/stack-overflow-now-has-its-own-app-on-ios-and-android#comment474175_349335"&gt;don't have a sustainable business model yet&lt;/a&gt; and have a &lt;a href="https://stackoverflow.com/company/team"&gt;sizable team&lt;/a&gt; with good benefits and they are getting concerned.&lt;/p&gt;
&lt;p&gt;Q&amp;amp;A is what built Stack Overflow, but it isn't enough to sustain them. Thus, the other projects are being created. Unfortunately, in this process, it seems the company is forgetting it's existing user base at the expense of expanding to new users. Existing users are getting frustrated with the lack of quality improvements, being ignored and not having changes that benefit their use cases.&lt;/p&gt;
&lt;p&gt;Documentation has taken up a giant chunk of time and developer effort and it's all been wasted. The &lt;a href="https://meta.stackoverflow.com/q/349410/189134"&gt;announcement&lt;/a&gt; that it is being redone has been met with "thanks" from the community, along with warnings to consider that "quality" problem. We'll see how it plays out, or if that quality issue is ignored like their own Quality Project.&lt;/p&gt;
&lt;p&gt;Which brings us to the final point I want to make. I think the feeling of Q&amp;amp;A being "done" is the biggest problem I've had with Stack Overflow over the last year. New features aren't being built in that space. Instead of focusing on some of the "hard" problems, the company is throwing stuff at the wall and hoping something will stick. Unfortunately, the four biggest projects in the last year have either failed completely (Teams, Documentation, Mobile App...perhaps) or have significant unintended consequences that isn't helping the quality issue users have been reporting for years.&lt;/p&gt;
&lt;p&gt;Power users, the underlying community that has put time and effort into growing Stack Overflow to that it is today, is feeling ignored. It is only after months or years long experiments fail that community opinions are finally validated or considered. Users have expressed concerns in each of the above projects repeatedly. Yet, those opinions were not addressed. The silos that the developers have built around themselves are causing the company to lose touch with it's community. This is being done at the expense of alienating the users that care and the cost of developer time.&lt;/p&gt;
&lt;p&gt;Users want a high quality site with answers to their questions. Even new or potentially new users want this. Stack Overflow continues to avoid dealing with that problem because "it's hard". The unfortunate thing is, this is costing the site &lt;a href="http://data.stackexchange.com/stackoverflow/query/674690#graph"&gt;users that return to provide more than one answer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/stackoverflow_return_users.png"&gt;&lt;img alt="Stack Overflow Return Answerers" src="https://andrewwegner.com/images/stackoverflow_return_users.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This chart is showing the number of answers provided per month by different types of users. Users that have provided more than 100 answers, between 11 and 100 answers, between 2 and 10 answers and only a single answer. The furthest data point on the right is an artifact of being an incomplete month. From this chart, we can see that the only group that has continued to rise are users that provide a single answer over time. The other groups took a steep drop in April 2014 and haven't recovered since then. The number of experienced users that are participating has dropped.&lt;/p&gt;
&lt;p&gt;What happened in April 2014? That's been &lt;a href="https://meta.stackoverflow.com/a/320234/189134"&gt;answered&lt;/a&gt; by a Stack Overflow community manager. The theory is that users aren't getting answers to their questions and due to being ignored they never return to participate further in the site. Another community manager also provided an &lt;a href="https://meta.stackoverflow.com/a/320440/189134"&gt;answer&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Starting around 2013 and peaking around March, 2014, people began asking fewer interesting questions. That lead to a decrease in voting on questions and fewer answers being given. Since the feedback on these uninteresting questions was discouraging, people began asking fewer questions on the whole. Meanwhile, truly poor questions continued being asked with little regard to negative feedback.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stack Overflow users began noticing increasing numbers of truly awful questions and decided, rightly, that downvoting and refusing to answer them is the best remedy. These questions fit broad categories of awful and users began withholding votes from questions that were not themselves awful, but bore some of the markers of awful. Fewer of these questions got answered and askers of mediocre questions did not see any point in trying to improve.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Thus began a slow spiral downward. Not all is lost though, because there are the upticks. I hope it's enough to break the cycle, but I really fear that something needs to be done about this quality issue. This is the issue that is brought up by the experienced community.  &lt;/p&gt;
&lt;h2 id="where-to-from-here"&gt;Where to from here?&lt;a class="headerlink" href="#where-to-from-here" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I continue to invest my time and effort into the community, but even as an active user who really wants the company and community to succeed, it's getting harder and harder to ignore that those of us that have been around for years are not being listened to any more. We're being treated as the grumpy old person that grumbles about the way things used to be. Our experiences on the site are brushed aside as being unhelpful to new users. That completely ignores that fact that we are still trying to reach the goal on which Stack Overflow was created: &lt;a href="https://stackoverflow.com/tour"&gt;"With your help, we're working together to build a library of detailed answers to every question about programming."&lt;/a&gt; To do this, we need high quality questions and answers so that we can actually provide help to all users. I think &lt;em&gt;this&lt;/em&gt; is the biggest challenge that Stack Overflow is going to face in the next 18 months.&lt;/p&gt;
&lt;p&gt;I want Stack Overflow to continue to grow. I also want Stack Overflow to have high quality content. I think my experience and the experience of others can help build the features to accomplish this. We just need Stack Overflow to refocus on the Q&amp;amp;A portion of their network again.&lt;/p&gt;</content><category term="Stack Exchange"></category></entry><entry><title>Review of Udemy's Deep Learning Prerequisites - Linear and Logistic Regression courses</title><link href="https://andrewwegner.com/deep-learning-prereq-linear-logistic-regression.html" rel="alternate"></link><published>2017-05-03T10:00:00-05:00</published><updated>2017-05-03T10:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-05-03:/deep-learning-prereq-linear-logistic-regression.html</id><summary type="html">&lt;p&gt;My review of the Deep Learning Prerequisites - Linear and Logistic Regression courses on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My &lt;a href="https://andrewwegner.com/deep-learning-prereq-numpy.html"&gt;last review&lt;/a&gt; covered &lt;a href="https://www.udemy.com/user/lazy-programmer/"&gt;Lazy Programmer's&lt;/a&gt; &lt;a href="https://www.udemy.com/deep-learning-prerequisites-the-numpy-stack-in-python/learn/v4/overview"&gt;Numpy prerequisites course&lt;/a&gt; on Udemy. In my goal to learn more about NLP,
I'm continuing through the courses this instructor has designed. To this end, that requires two additional prerequisites: &lt;a href="https://www.udemy.com/data-science-linear-regression-in-python/learn/v4/overview"&gt;Linear
Regression&lt;/a&gt; and &lt;a href="https://www.udemy.com/data-science-logistic-regression-in-python/learn/v4/overview"&gt;Logistic Regression&lt;/a&gt;. This review covers those two separate courses.  &lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;These two courses are each short three hour courses giving a crash course in how to perform linear regression analysis and logistic
regression analysis. The courses cover both the theoretical math needed and the more practical Python code needed. The instructor
states, several times, that simply copying the code isn't good enough in the later courses. The mathematical background is needed to
succeed later. With that in mind, I spent most of these lectures relearning much of the math. The instructor provides several detailed
"Theory" lectures and I found those helpful.&lt;/p&gt;
&lt;p&gt;After the theory is introduced, the next step is applying this in code. The instructor's code is short and to the point. It shows the
what was just taught and provides efficient &lt;code&gt;numpy&lt;/code&gt; code to convert the theory into something workable.&lt;/p&gt;
&lt;p&gt;Once again, I'm happy with the instructor and their teaching style. I think this will go well with the future courses I'm planning on taking
that are by the same person. I'm continuing to brush up on those math skills that haven't been used in a while, but at this point, I am happy
with how everything is heading for this series of courses.&lt;/p&gt;
&lt;p&gt;I've posted my &lt;a href="https://github.com/AWegnerGitHub/Deep-Learning-Prerequisites"&gt;IPython Notebooks&lt;/a&gt; on GitHub for all three of the courses related to the prerequisites.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am still looking forward to taking the &lt;a href="https://lazyprogrammer.me/data-science-courses/"&gt;courses designed by the Lazy Programmer&lt;/a&gt;. The series of prerequisites were very helpful in helping
me to catch up on the skills I'll need, but didn't know (or remember much of) ahead of time. With the actual content coming up, I am hoping
the lecture style and hands on coding sections continue be the same quality.&lt;/p&gt;
&lt;p&gt;The Linear and Logistic Regression courses didn't require much in terms of software - Python, numpy, pandas and matplotlib - but I still need to
decide how I'm going to proceed with the courses. I'm not sure whether or not I want to set up a Linux machine or a virtual machine. Windows doesn't
seem to play well with all the libraries I'll be needing. It may make my life easier too. So far, everyone seems to be using a Mac or Linux machine to
teach these courses and offer only basic "It may work on Windows" advice.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-OMSE1FD6"&gt;&lt;img alt="Linear Regression Completion Award" src="https://andrewwegner.com/images/udemy-deep-learning-prereq-linear-regression.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-XASAGYVJ"&gt;&lt;img alt="Linear Regression Completion Award" src="https://andrewwegner.com/images/udemy-deep-learning-prereq-logistic-regression.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Choosing an ORM library for a new project</title><link href="https://andrewwegner.com/choosing-orm-library.html" rel="alternate"></link><published>2017-04-26T14:30:00-05:00</published><updated>2017-04-26T14:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-04-26:/choosing-orm-library.html</id><summary type="html">&lt;p&gt;A discussion about how a team picked an ORM library for a new project.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="project-history"&gt;Project History&lt;a class="headerlink" href="#project-history" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt; project is over three years old at this point. It's grown from a small python script to a
decently sized application that integrates with another project. In that time, it's expanded what types of spam and
patterns it looks for, what chat rooms it posts to, what external services it integrates with and how permissions to
use the system are determined.&lt;/p&gt;
&lt;p&gt;A lot has changed under the hood. I was hoping to put a cool chart here showing code change over time, but some early
decisions with the project really throw off the chart. Using a &lt;a href="https://erikbern.com/2016/12/05/the-half-life-of-code.html"&gt;Ship of Theseus&lt;/a&gt; analogy for code, you can see how
much has changed. The basic idea is, if a ship leaves port and replaces every plank along it's journey, is it still the
same ship when it returns? With code, the idea is to apply this to lines of code in an application.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-all.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus" src="https://andrewwegner.com/images/smokey-git-theseus-all.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="what-happened-in-2014"&gt;What happened in 2014?!&lt;a class="headerlink" href="#what-happened-in-2014" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In late 2014, the project attempted their first machine learning method of detecting spam. In this time period, a
&lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/102aa9c64edafb7f5fef5ba16414f4cefad03d64"&gt;commit&lt;/a&gt; was added that added about 200,000 lines of code to the project. This was almost all training data for a
Bayesian algorithm. It wasn't needed and probably shouldn't have been added to the main repository. Unfortunately, it
stayed in the repository for over a year and was finally &lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/68d49ccc0b4981a4ebe91d993f42643542e44d80"&gt;removed&lt;/a&gt; in late 2015. This is the cause of the weird graph
above, and why almost everything added in 2014 looks like it's missing in later years.&lt;/p&gt;
&lt;h3 id="what-has-really-changed"&gt;What has really changed?&lt;a class="headerlink" href="#what-has-really-changed" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After eliminating that Bayesian directory from git history, you can get a much better idea of how much has changed. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-filtered.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus - Filtered" src="https://andrewwegner.com/images/smokey-git-theseus-filtered.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Very little of the original code, written in 2014, remains untouched. The explosion in code after that is due to
new detection patterns, chat commands (and a rewrite), integration with MetaSmoke and the introduction of blacklists.&lt;/p&gt;
&lt;p&gt;Even more dramatically, you can see how long a line of code is expected to survive in the code base.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-survival.png"&gt;&lt;img alt="SmokeDetector - Line Survival Rate" src="https://andrewwegner.com/images/smokey-git-theseus-survival.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within one year, the team is removing over 40% what's been committed to the repository. Looking at these commits,
it was determined that a vast majority aren't even &lt;em&gt;code&lt;/em&gt;. They are new items to blacklist or new patterns to detect.&lt;/p&gt;
&lt;h2 id="enter-the-database"&gt;Enter the database&lt;a class="headerlink" href="#enter-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of this type of data can be stored in a database and managed outside of code. In early 2017, those discussions
started taking place. Several team members come from a Ruby background and were familiar with it's &lt;a href="https://en.wikipedia.org/wiki/Object-relational_mapping"&gt;ORM&lt;/a&gt; method of
accessing databases. They wanted something similar when a database was brought into SmokeDetector.&lt;/p&gt;
&lt;p&gt;A bit of research was done and it was narrowed down to &lt;a href="http://docs.peewee-orm.com/en/latest/"&gt;peewee&lt;/a&gt; and &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="how-to-choose"&gt;How to choose?&lt;a class="headerlink" href="#how-to-choose" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Fortunately for the SmokeDetector team, there weren't any strong opinions either way. The biggest reason for choosing
one over the other came down to a &lt;a href="https://www.reddit.com/r/Python/comments/4tnqai/choosing_a_python_ormpeewee_vs_sqlalchemy/d5jyuug/"&gt;comment made by the peewee author&lt;/a&gt; on reddit. They state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[...] SQLAlchemy is the gold standard for ORM in the Python world. It has a very active community and a maintainer
who is committed to excellence. If you're a glass-half-empty guy, to put it another way, you can't go wrong if you
choose SQLAlchemy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The weaknesses they list for using their own package is the smaller ecosystem, support and number of developers.&lt;/p&gt;
&lt;h3 id="technical-differences"&gt;Technical differences&lt;a class="headerlink" href="#technical-differences" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;That's a boring story though. Not to be deterred from such a glowing review from a competitor, I wanted to see what the
technical differences were between the two solutions.&lt;/p&gt;
&lt;p&gt;To that end, I put together a small Python notebook showing the &lt;a href="https://gist.github.com/AWegnerGitHub/201dbaf09740f9ecd797c32ebfc15872"&gt;differences between peewee and SQLAlchemy&lt;/a&gt; in a
handful of tests. These tests included inserting two settings in an SQLite database, retrieving one, inserting a large
list of users and then retrieving a subset of those users.&lt;/p&gt;
&lt;p&gt;The results were...unremarkable.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/peewee-vs-sqlalcheme-results.png"&gt;&lt;img alt="peewee vs SQLAlchemy results" src="https://andrewwegner.com/images/peewee-vs-sqlalcheme-results.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The two libraries each took two tests (out of four) for being faster than the other. In both cases where SQLAlchemy was
faster, it was between two and six times faster. Where peewee was faster it was between a fraction faster and twice as
fast.&lt;/p&gt;
&lt;p&gt;The time scales are so small though, and SmokeDetector doesn't need to have thousands, hundreds or even tens of hits to
the database a second. A hundred extra milliseconds isn't going to cripple anything it handles.&lt;/p&gt;
&lt;p&gt;Thus, the choice was made based on the recommendation of the author of the peewee library. SQLAlchemy has a larger
community and better support.&lt;/p&gt;</content><category term="technical"></category><category term="programming"></category></entry><entry><title>Review of Udemy's 'Deep Learning Prerequisites: The Numpy Stack in Python' course</title><link href="https://andrewwegner.com/deep-learning-prereq-numpy.html" rel="alternate"></link><published>2017-04-20T22:30:00-05:00</published><updated>2017-04-20T22:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-04-20:/deep-learning-prereq-numpy.html</id><summary type="html">&lt;p&gt;My review of "Deep Learning Prerequisites: The Numpy Stack in Python" on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I found &lt;a href="https://www.udemy.com/user/lazy-programmer/"&gt;Lazy Programmer's&lt;/a&gt; Deep Learning courses on Udemy. A couple of those seem very interesting, specifically the ones
about Natural Language Processing. I'd love to be able to enhance either my &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;comment flagging&lt;/a&gt;, &lt;a href="https://andrewwegner.com/zephyr-the-bot-that-watches-for-low-quality-vote-requests.html"&gt;Zephyr&lt;/a&gt; or &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt;
with language processing capabilities. I also have tried, multiple times, to come up with a way to detect duplicate questions on
Stack Overflow, but my limited knowledge of true NLP concepts has proved to be unhelpful in that task.&lt;/p&gt;
&lt;p&gt;I have the goal of getting to the NLP courses and completing a few other data science and machine learning courses this year. I've
picked out a few that look interesting and useful in either personal or professional projects. That will be my main focus in the next
several months. When I need a break from these topics, I may find another soft skills course to look at. Or, I have a play through of
Witcher 3 waiting for me.&lt;/p&gt;
&lt;p&gt;To start this journey, I need to cover some prerequisites. Data Science and Machine learning utilize several important libraries and
I need to know them or brush up my skills when using them. I took the &lt;a href="https://andrewwegner.com/data-analysis-with-pandas-review.html"&gt;Data Analysis with Pandas&lt;/a&gt; last winter and found that helpful.
Lazy Programmer offers one covering the numpy stack. That's what I just finished.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.udemy.com/deep-learning-prerequisites-the-numpy-stack-in-python/learn/v4/overview"&gt;Deep Learning Prerequisites: The Numpy Stack in Python&lt;/a&gt; is a brief two hour course that gives a crash course in how to use numpy, pandas,
matplotlib and scipy. It touches each of these &lt;em&gt;very&lt;/em&gt; briefly. The goal of the course isn't to get you intimately familiar with the libraries.
The goal is to get you to know the libraries exist and a few of their most common tasks. In this regard, it was very useful.&lt;/p&gt;
&lt;p&gt;The course also served as a nice introduction to the instructor and their teaching style. It is all hands on though, which I like. I prefer
to do the coding (and add my own comments along the way) to watching someone present a huge chunk of code and walk through that line by
line. I've posted my &lt;a href="https://github.com/AWegnerGitHub/Deep-Learning-Prerequisites"&gt;IPython Notebooks&lt;/a&gt; on GitHub.&lt;/p&gt;
&lt;p&gt;One other thing this course does is introduce users to the assumptions the instructor makes about the students. Machine learning and data science,
in general, have a lot of math behind them. The instructor assumes that students have the theoretical background for this and teaches how to
implement this math in Numpy. Note to self: Brush up on those math skills. I haven't used some of this in a long time.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is an introduction course to the bigger &lt;a href="https://lazyprogrammer.me/data-science-courses/"&gt;"Deep Learning" courses&lt;/a&gt; that Lazy Programmer offers. It does it's job well and has increased my
confidence in the instructor. My last couple courses haven't been great and I'm happy that this quick two hour course was available. I'm looking
forward to taking some more of these courses.&lt;/p&gt;
&lt;p&gt;One thing I will need to consider as I go through this course: whether or not to either set up a Linux machine or a virtual machine. Windows doesn't
seem to play well with all the libraries I'll be needing. It may make my life easier too. So far, everyone seems to be using a Mac or Linux machine to
teach these courses and offer only basic "It may work on Windows" advice.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-9CGD0JX8"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-deep-learning-prereq-numpy.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Review of Udemy's 'Become a Product Manager | Learn the Skills &amp; Get the job' course</title><link href="https://andrewwegner.com/become-a-product-manager-review.html" rel="alternate"></link><published>2017-04-20T07:40:00-05:00</published><updated>2017-04-20T07:40:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-04-20:/become-a-product-manager-review.html</id><summary type="html">&lt;p&gt;My review of "Become a Product Manager  | Learn the Skills &amp;amp; Get the job" on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I recently finished the &lt;a href="https://www.udemy.com/become-a-product-manager-learn-the-skills-get-a-job/learn/v4/overview"&gt;"Become a Product Manager  | Learn the Skills &amp;amp; Get the job"&lt;/a&gt; course on Udemy. I had picked
this up in December during one of Udemy's frequent $15 dollars. I was looking to take something non-technical that covers
more of the "soft skills" I utilize in my job. I do a lot of software "product manager" work, without the title, at my job
and was hoping to brush up on those skills.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course is billed as a 13 hour course, with activities and interviews with product managers. The course is taught by
Cole Mercer (a Senior product manager at &lt;a href="https://soundcloud.com/"&gt;SoundCloud&lt;/a&gt;) and Evan Kimbrell (founder of &lt;a href="http://www.sprintkick.com/"&gt;Sprintkick&lt;/a&gt;). The course is
packed with useful content, resources and interviews. I learned a lot and reinforced a lot of what I already knew. That
information will be incredibly useful at work.&lt;/p&gt;
&lt;p&gt;That glowing review said, I had a hard time getting through the lessons. Despite the amount of useful information, I found
the lessons to be...boring, at best. At worst, the instructors attempted to throw jokes in that just didn't work for this format.
That type of distraction made it hard to stick with the lessons. Additionally, the quizzes that cropped up occasionally, were
treated as a joke by the course creators. There were joke answers, there were joke explanations for answers and their were
questions unrelated to the content but instead about the instructors.&lt;/p&gt;
&lt;p&gt;Finally, there are several points in the lessons that ask students to go the message board and provide feedback, do a quick activity,
and interact with one another. I did a couple of these. I stopped doing them when I didn't receive any responses from either other
students or the instructors. A closer look at the message board shows this is very common. I have to scroll back through a couple
"load more" clicks on the message board to find &lt;em&gt;any&lt;/em&gt; posts that even have a response. The interaction I was hoping for from the
instructors just doesn't exist with this course.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The content in this course is amazingly helpful. There are links to articles that I'll be able to use for years. The information
in the lectures is also helpful, if you can get through the bland presentation of the material. The frequent, distracting, jokes and
lack of interaction makes this course less stellar.&lt;/p&gt;
&lt;p&gt;Overall, I'd consider this a middle of the road course. The presentation is what drags down this information packed course.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-XK0L2MOQ"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-become-a-product-manager-completion.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Can a machine be taught to flag spam automatically</title><link href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html" rel="alternate"></link><published>2017-02-19T22:51:00-06:00</published><updated>2017-02-20T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-02-19:/can-a-machine-be-taught-to-flag-spam-automatically.html</id><summary type="html">&lt;p&gt;Description of how a group of people helped completely eliminate spam on the Stack Exchange network&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This post was originally &lt;a href="http://meta.stackexchange.com/q/291301/186281"&gt;published&lt;/a&gt; on Meta Stack Exchange on February 20, 2017. I've republished it here
so that I can easily update information related to recent developments. If you have questions or comments, I highly
encourage you to visit the &lt;a href="http://meta.stackexchange.com/q/291301/186281"&gt;question&lt;/a&gt; on Meta Stack Exchange and post there.&lt;/p&gt;
&lt;p&gt;The post was featured across the entire Stack Exchange network for a week, too. This drove a huge amount of traffic
to the question and resulted in some valuable feedback:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/spam-featured-announcement.png"&gt;&lt;img alt="Featured Announcement" src="https://andrewwegner.com/images/spam-featured-announcement.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;TL;DR: &lt;a href="http://charcoal-se.org/people.html"&gt;We&lt;/a&gt; did it, so... yes.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="what-is-this"&gt;What is this?&lt;a class="headerlink" href="#what-is-this" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Charcoal is the &lt;a href="http://charcoal-se.org/people.html"&gt;organization&lt;/a&gt; behind the &lt;a href="https://github.com/Charcoal-SE/SmokeDetector"&gt;SmokeDetector&lt;/a&gt; bot and other &lt;a href="https://github.com/Charcoal-SE"&gt;nice things&lt;/a&gt;. This bot scans new 
posts across the entire network for spam posts and reports them to &lt;a href="https://github.com/Charcoal-SE/SmokeDetector/wiki/Chat-Rooms"&gt;various chatrooms&lt;/a&gt; where people can act on them. 
If a post has been created or edited, anywhere on the network, we've probably seen it. The bot utilizes our knowledge 
of how spammers work and what they have previously posted to come up with common patterns and rules to detect spam in 
the new and updated posts. You've likely seen the SmokeDetector bot if you visit chatrooms such as 
&lt;a href="http://chat.meta.stackexchange.com/rooms/89/tavern-on-the-meta"&gt;Tavern on the Meta&lt;/a&gt;, &lt;a href="http://chat.stackexchange.com/rooms/11540/charcoal-hq"&gt;Charcoal HQ&lt;/a&gt;, &lt;a href="http://chat.stackoverflow.com/rooms/41570/so-close-vote-reviewers"&gt;SO Close Vote Reviewers&lt;/a&gt; and others across the network. Over time, the 
bot has become very accurate. &lt;/p&gt;
&lt;p&gt;Now we are leveraging the years of data and accuracy to automatically cast spam flags. With approximately 58,000 posts 
to draw from and over 46,000 true positives, we have a vast trove of data to utilize.&lt;/p&gt;
&lt;h2 id="what-problem-does-this-address"&gt;What problem does this address?&lt;a class="headerlink" href="#what-problem-does-this-address" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To put it simply, &lt;strong&gt;spam&lt;/strong&gt;. Stack Exchange is one of the most popular networks of websites on the Internet, and &lt;em&gt;all&lt;/em&gt; 
of it gets spammed at some point. Our statistics show that we see about 100 spam posts per day, on average over the 
last three months. &lt;/p&gt;
&lt;p&gt;A decent chunk of this isn't the type you'd want to see at work (or at all). The faster we can get this off the home 
page, the better for all involved. Unfortunately, it's not unheard of for spam to last several hours, even on the 
larger sites such as Graphic Design.&lt;/p&gt;
&lt;p&gt;Over the past three years, efforts with Smokey have significantly cut the time it takes for spam to be deleted. This 
project is an extension of that, and it's now well within reach to delete spam within seconds of it being posted.&lt;/p&gt;
&lt;h2 id="what-are-we-doing"&gt;What are we doing?&lt;a class="headerlink" href="#what-are-we-doing" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For over 3 years, SmokeDetector has reported potential spam across the Stack Exchange network so that users can flag 
the posts as appropriate. Users have provided feedback to inform the bot on whether the detection was correct or not 
(referred to as "feedback"). This feedback is stored in our web dashboard, &lt;a href="https://metasmoke.charcoal-se.org"&gt;metasmoke&lt;/a&gt; (&lt;a href="https://github.com/Charcoal-SE/metasmoke"&gt;code&lt;/a&gt;). Over time, we've 
used this feedback to evaluate our patterns ("reasons") and improve our accuracy. &lt;a href="https://metasmoke.erwaysoftware.com/reason/106"&gt;Several&lt;/a&gt; of our &lt;a href="https://metasmoke.erwaysoftware.com/reason/21"&gt;reasons&lt;/a&gt; 
are over 99.9% &lt;a href="https://metasmoke.erwaysoftware.com/reason/61"&gt;accurate&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Early last year, and after getting a baseline accuracy from &lt;a href="http://stackoverflow.com/users/1933347/jmac"&gt;jmac&lt;/a&gt; (thank you!), we realized we could use the 
system to automatically cast spam flags. On Stack Overflow the current accuracy of users flagging spam posts is 85.7%. 
Across the rest of the network users are 95.4% accurate. We determined we can beat those numbers and eliminate spam 
from Stack Overflow and the rest of the network even faster. &lt;/p&gt;
&lt;p&gt;Without going into too much detail (if you really want it, it's available on our &lt;a href="https://charcoal-se.org/flagging"&gt;website&lt;/a&gt;), we leverage the 
accuracy of each existing reason to come up with a weight indicating how certain the system is that a post is spam. If 
this value exceeds a specific threshold, the system will cast up to three spam flags on the post. We cast multiple 
flags utilizing a number of different users' accounts and the Stack Exchange API. Via metasmoke, users are given the 
opportunity to &lt;a href="https://metasmoke.erwaysoftware.com/flagging/ocs"&gt;enable their accounts to be used to flag spam&lt;/a&gt; (You can too, if you've made it this far). When a 
post is eligible for flagging because it exceeded the threshold set by each individual user, accounts are randomly 
selected from the pool of enabled users to cast a single flag each, up to a maximum of three per post so that we never 
unilaterally nuke something.&lt;/p&gt;
&lt;h2 id="what-are-our-safety-checks"&gt;What are our safety checks?&lt;a class="headerlink" href="#what-are-our-safety-checks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We designed the entire system with accuracy and sanity checks in mind. Our design collaborations are available for 
your browsing pleasure (&lt;a href="https://docs.google.com/document/d/1Bg0u4oY9W_skp79wSnyQWttUIBH8WV46JELDGJ7Bixo/edit"&gt;RFC 1&lt;/a&gt;, &lt;a href="https://docs.google.com/document/d/1voGyl3BUA1JHJ0pR2Mf9E5-wmIDUFC1G8HcThiS7B1k/edit"&gt;RFC 2&lt;/a&gt;, &lt;a href="https://docs.google.com/document/d/1Nu2U0uFbmHpb3v61WyBxjYNK34n5tFWAPYtvu13ZQCw/edit#heading=h.9nvcibv3gama"&gt;RFC 3&lt;/a&gt;). The major things that make this system safe and sane 
are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We give users a choice as to how accurate they want to be with their automatic flags. Before casting any flags, we 
 check that the preferences the user has set result in a spam detection accuracy of over 99.5% over a sample of at 
 least 1000 posts. Remember, the current accuracy of humans is 85.7% on SO and network wide it is 95.4%. &lt;/li&gt;
&lt;li&gt;We do not unilaterally spam nuke a post, regardless of how sure we are it is spam. This means that a human &lt;em&gt;must&lt;/em&gt; 
 be involved to finish off a post, even on the few sites with lower spam thresholds.&lt;/li&gt;
&lt;li&gt;We’ve designed the system to be tolerant of faults - if there’s a malfunction anywhere in the system, any user with 
 access to SmokeDetector can immediately halt all automatic flagging - this includes all network moderators. If this 
 happens, it needs a system administrator to step in to re-enable flags.&lt;/li&gt;
&lt;li&gt;We've discussed this with a community manager and have their &lt;a href="http://chat.stackexchange.com/transcript/message/35437121#35437121"&gt;blessing&lt;/a&gt; on the project.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We have been casting an average of 60-70 automatic flags per day for over two months, for a total of just over 4000 
flags network wide. These flags were cast by 22 different users. In that time, we've had &lt;a href="https://metasmoke.erwaysoftware.com/flagging/logs?filter=fps"&gt;four&lt;/a&gt; false positives. 
We would like to be able to automatically cancel these particular cases. This isn't possible though, so we've created 
a feature request to &lt;a href="http://meta.stackexchange.com/questions/288120/allow-retracting-flags-from-the-api"&gt;retract flags via the API&lt;/a&gt;. In the mean time, the flags are either manually retracted by the 
user or declined by a moderator.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/spam-weights-and-accuracies.png"&gt;&lt;img alt="Weights and Accuracy" src="https://andrewwegner.com/images/spam-weights-and-accuracies.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The above graph plots the weight of the reasons against its overall volume of reports and accuracy. As minimum weight 
increases, accuracy (yellow line and rightmost Y-axis) and total reports (blue line) on the left-hand scale increase. 
The green line represents the number of true positives, which are verified by SmokeDetector user feedback.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/spam-autoflags-per-day.png"&gt;&lt;img alt="Automatic Flags per day" src="https://andrewwegner.com/images/spam-autoflags-per-day.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This shows the number of posts we've automatically flagged per day over the last month. The jump on February 15th, is 
due to increasing the number of automatic flags from 1 per post to 3 per post. You can see a live version of this graph 
on &lt;a href="https://metasmoke.erwaysoftware.com/flagging"&gt;metasmoke's autoflagging page&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/spam-spam-hours.png"&gt;&lt;img alt="Spam Hours" src="https://andrewwegner.com/images/spam-spam-hours.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Spam arrives on Stack Exchange in waves. It is easy to see the time of day that many spam reports come in. The hours, 
above, are UTC time. The busiest spam times of day are the 8 hour block between 4am and Noon. We have affectionately 
named this "spam hour" in the chat room. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/spam-average-time-to-delete.png"&gt;&lt;img alt="Average Time to Deletion" src="https://andrewwegner.com/images/spam-average-time-to-delete.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Our goal is to delete spam quickly and accurately. The graph shows the time it takes for a reported spam post to be 
removed from the network. This section has three trend lines that show these averages. The first, red section is when 
we were simply reporting the posts to chatrooms and all flags had to come from users. You can see we are pretty constant 
in the time it takes to remove spam during this period. It took, on average, just over five minutes to get a post 
removed.&lt;/p&gt;
&lt;p&gt;The green trend line is when we were issuing a single automatic flag. At implementation, we eliminated a full minute 
from time to deletion and after a month we'd eliminated two full minutes compared to no automatic flags.&lt;/p&gt;
&lt;p&gt;The last section, the orange, is when we implemented three automatic flags to most sites. This was rolled out last 
week, but it's already had a dramatic improvement on the time to deletion. We are seeing between 1 and 2 minutes to 
time to deletion.&lt;/p&gt;
&lt;p&gt;As mentioned above, spam arrives in waves. The dashed and dotted lines on the graph show the average deletion time 
during these two different time periods. The dashed lines show deletion time during 4am and Noon UTC, the dotted lines 
show the rest of the 24 hour period. An interesting thing this graph shows is that time to deletion during spam hour 
was higher when we didn't cast any automatic flags. It was removed faster outside of spam hour. That reversed when we 
started issuing a single auto-flag. The spam hour time to deletion is slightly lower than the average. Comparing the 
two time periods though, time to deletion during non-spam hour at the end of the non-flagging time period and the end 
of the single flag period are roughly the same. &lt;/p&gt;
&lt;p&gt;We'll update these in a few weeks too, to better show the trend we are seeing with three automatic flags.  &lt;/p&gt;
&lt;h2 id="discussion"&gt;Discussion&lt;a class="headerlink" href="#discussion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;We are confident in SmokeDetector and the three years of history it has. We've had many talented developers assist us 
over the years and many more users have provided feedback to improve our detection rules. Let us know what you want us 
to elaborate on, features you're wondering about or would like to see added, or things we might have missed in the 
process or the tooling. Take a look at the &lt;a href="http://meta.stackexchange.com/questions/288120/allow-retracting-flags-from-the-api"&gt;feature&lt;/a&gt; we'd really like Stack Exchange to consider so that we can 
further improve this system (and some of the other community built systems). We'll have &lt;a href="http://charcoal-se.org/people.html"&gt;Charcoal members&lt;/a&gt; hanging 
around and answering your questions. Alternatively, feel free to drop into &lt;a href="http://chat.stackexchange.com/rooms/11540/charcoal-hq"&gt;Charcoal HQ&lt;/a&gt; and have a chat. &lt;/p&gt;</content><category term="Stack Exchange"></category><category term="machine learning"></category><category term="automation"></category><category term="programming"></category></entry><entry><title>Review of Udemy's 'From 0 to 1: Machine Learning, NLP and Python - Cut to the Chase' course</title><link href="https://andrewwegner.com/loony-corn-machine-learning-review.html" rel="alternate"></link><published>2016-12-28T20:10:00-06:00</published><updated>2017-04-24T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-12-28:/loony-corn-machine-learning-review.html</id><summary type="html">&lt;p&gt;My review of "From 0 to 1: Machine Learning, NLP and Python - Cut to the Chase" on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="course"&gt;Course&lt;a class="headerlink" href="#course" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I decided to squeeze one more course in before 2016 ended. This time I chose
&lt;a href="https://www.udemy.com/from-0-1-machine-learning/learn/v4/overview"&gt;"From 0 to 1: Machine Learning, NLP and Python - Cut to the Chase"&lt;/a&gt; by the LoonyCorn team on Udemy. This course was
a 20 hour overview of machine learning techniques. I've been interested in taking some more formal training on various
machine learning algorithms and this course sounded like it would be useful.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I was very disappointed in this course. The lessons had large portions of time that overlapped one another, the
background music was distracting, the instructor's speaking volume isn't consistent, the "coding" portions weren't
done in a way that allowed me to follow along, code was presented with bugs and the instructor glossed over
these with a simple "we'll fix those later". The theories were presented fairly well but really should have been
condensed into a handful of lessons instead of spread out so broadly.&lt;/p&gt;
&lt;p&gt;It took me a few lessons to realize it, but the course notes - effectively power point slides that are hand written
during the lecture - and the instructor's voice were recorded at different times. Multiple times through the lessons,
the &lt;em&gt;exact&lt;/em&gt; same portion is used repeatedly. Lecture notes are "rewritten" or explained again. This repetition is used
ineffectively, as the instructor's voice isn't consistent within a single lecture. The repeated parts are either much
louder or much softer than the surrounding lecture material.&lt;/p&gt;
&lt;p&gt;My biggest disappointment, though, was with the coding exercises. I was hoping for some hands on activities. Instead,
the instructor spoke while the code - with all comments - was coded "live". The code was done quickly and offered no time
for me to both code and listen to the explanation. Like the lecture notes, the code and the vocal explanation was
recorded at different times. This means when a bug is encountered in the code, it is simply glossed over in the
explanation as an area they will return to later to fix. This was incredibly frustrating.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course wasn't worth my time. The theory portions were &lt;em&gt;just&lt;/em&gt; good enough that I stuck with it hoping to pick out
something useful, but it never seemed to materialize. I did complete the course and don't feel I've learned anything
that I can apply elsewhere. In the new year, I'll be looking for another machine learning course that, hopefully, is
much better than this one.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-9WXL1L1V"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-machine-learning-nlp-python-completion.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Review of Udemy's 'Data Analysis with Pandas' course</title><link href="https://andrewwegner.com/data-analysis-with-pandas-review.html" rel="alternate"></link><published>2016-12-09T22:54:00-06:00</published><updated>2016-12-09T22:54:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-12-09:/data-analysis-with-pandas-review.html</id><summary type="html">&lt;p&gt;My review of "Data Analysis with Pandas" on Udemy.&lt;/p&gt;</summary><content type="html">
&lt;p&gt;It's been a few years since I finished my formal education. I've been getting the itch to take a few more structured
training courses, but don't have the desire to commit to another full university degree. Fortunately, there are a lot
of places online that now offer training and college courses (both free and paid). I'll be picking out a few and going
through them as my free time permits. I'll be sharing my thoughts on the courses in a series of posts with a review of
the course and, if available, a link to show what I produced during the course.&lt;/p&gt;
&lt;h2 id="data-analysis-with-pandas"&gt;Data Analysis with Pandas&lt;a class="headerlink" href="#data-analysis-with-pandas" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I recently completed &lt;a href="https://www.udemy.com/data-analysis-with-pandas/learn/v4/overview"&gt;Data Analysis with Pandas&lt;/a&gt; by Boris Paskhaver on Udemy. I use pandas both at work and in
personal projects and constantly find new things the library can do. This course is billed as a 19 hour course spanning
173 lectures. The curriculum looked like it covered both basics and topics I was less familiar with. It also helped
that the instructor was offering a coupon code on reddit to take the course for free. I decided to take the course.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Spoiler&lt;/em&gt;: Even if this wasn't free, this class was worth the price. It covered a large part of pandas and did so in a
way that didn't make me tune out the instructor, even after 19 hours.&lt;/p&gt;
&lt;h2 id="thoughts-on-the-lessons"&gt;Thoughts on the lessons&lt;a class="headerlink" href="#thoughts-on-the-lessons" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The course starts a bit slow with your basic "How to install" tutorials. The entire course is done in a series of
&lt;a href="https://github.com/AWegnerGitHub/Data-Analysis-with-Pandas"&gt;Jupyter Notebooks&lt;/a&gt; and, obviously, requires that you have Python (the instructor uses 3.5), pandas and a few
other modules installed before we get to the good stuff. The instructor uses OS X during all lectures, but that has
no effect on how things are communicated to the student. Everything is done in the Jupyter Notebooks or at a &lt;a href="https://www.continuum.io/downloads"&gt;conda&lt;/a&gt;
prompt. This works the same across all major operating systems. The only reason I felt this was slow was because I
already had all of the requirements installed due to using the library before. I understand the need for this lesson,
though, and can't hold it against the instructor for needing to include this.&lt;/p&gt;
&lt;p&gt;One thing that I liked about the introduction was that the instructor provided a series of CSV files we'd use
throughout the rest of the lessons. These CSVs were varied in size and composition. I thought this was a great way to
keep everyone on the same page. I've seen a lot of tutorials on pandas around the internet and most of them depend on
generating random data. By providing everyone with a set of CSVs it is much easier to focus on specific aspects of the
data and how certain functions work.&lt;/p&gt;
&lt;h3 id="series-and-dataframes"&gt;Series and DataFrames&lt;a class="headerlink" href="#series-and-dataframes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The course really begins in Section 2 which is on the pandas &lt;a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html"&gt;Series&lt;/a&gt; object. It covers what a series is, various
methods of creating one, and then goes over the various methods and attributes you can use on a series object. The
module covers 21 lessons and lays the foundation for the entire pandas library. Section 3, 4, and 5 cover
&lt;a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html"&gt;DataFrames&lt;/a&gt;. These sections cover 41 lessons. DataFrames are the heart of the pandas library. This is the object
you'll use most of the time, which explains the number of lessons that focus on DataFrames.&lt;/p&gt;
&lt;p&gt;These lessons cover everything from selecting a series (column) in a data frame, adding a new column, dropping null
values and sorting values. More advanced topics include various ways of filtering a dataframe to only the data you are
interested in, applying a function to all values and working with either index labels or index positions. These modules
are the heart of the entire course.&lt;/p&gt;
&lt;h3 id="text-data-and-datetime-data"&gt;Text data and DateTime data&lt;a class="headerlink" href="#text-data-and-datetime-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sections 6 and 10 deal with text data and datetime data. One complaint I had about these two sections was that they
were separated so much. Both types of data need to be operated on the same way in pandas. Namely, you have to add
either &lt;code&gt;.str&lt;/code&gt; or &lt;code&gt;.dt&lt;/code&gt; when calling a string or datetime function. I also think that datetimes are important enough
and used frequently enough that getting a lesson in on how to properly use them early would make more sense.&lt;/p&gt;
&lt;p&gt;That complaint aside, both sections cover their content well. There isn't anything ground breaking here, especially
if you've done any sort of work with either strings or dates in Python. The functions introduced all work as you'd
expect based on that experience.&lt;/p&gt;
&lt;p&gt;The DateTime section also provides information on how to work with date offsets and time deltas. Adding and
subtracting days/weeks/months is always important and the lessons cover how to do so pretty well.&lt;/p&gt;
&lt;h3 id="advanced-features"&gt;Advanced Features&lt;a class="headerlink" href="#advanced-features" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sections 7, 8 and 9 cover aspects of pandas that many will use as well. These cover ways to join and group multiple data
sets into a single data frame and the benefits of each method.&lt;/p&gt;
&lt;p&gt;MultiIndexes are not something I've used a lot, but after these 14 lessons I have already thought of ways I can
improve my code at work to utilize these.&lt;/p&gt;
&lt;h3 id="panels"&gt;Panels&lt;a class="headerlink" href="#panels" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Section 11 covers a topic that was brand new to me: Panels. I have never used them or heard of them. A series is a 1D
data set, a dataframe is a 2D data set and a panel is a 3D data set. It is a group of dataframes. The instructor explained
this concept very clearly and worked through multiple examples of how to build and use a panel.&lt;/p&gt;
&lt;p&gt;In this lesson, the panel we utilized was created by calling Google Finance for multiple companies. However, the panel
that was returned was not formatted the way I expected and it bothered me for several of the lessons. At first, this
was mentioned by the instructor in passing, and then seemed to be ignored. However, toward the end of the section, the
course covered ways of reforming the panel to be in a different format.&lt;/p&gt;
&lt;h3 id="inputoutput-and-visualization"&gt;Input/Output and Visualization&lt;a class="headerlink" href="#inputoutput-and-visualization" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Sections 12 and 13 covered the portions of pandas that my users see at work. The end result of data manipulation. I
produce visuals or excel documents and they are happy. The lessons cover how to export to CSVs and Excel (you need
an &lt;code&gt;ExcelWriter&lt;/code&gt;). It also covers the four most common visualizations I produce at my job - line charts, bar charts,
pie charts and histograms.&lt;/p&gt;
&lt;p&gt;Outside of the scope of this course, but something I'll look into, is what else &lt;code&gt;matplotlib&lt;/code&gt; can do. We did very
little to customize our plots and I know that the library can do so much more.&lt;/p&gt;
&lt;h3 id="options"&gt;Options&lt;a class="headerlink" href="#options" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final section covers a few of the miscellaneous options pandas has. There isn't anything exciting in this section
and these 4 lessons are short. Placing them at the end is a decent spot for them, as it reminds you to go look at the
documentation to see what other options are available (there are a ton).&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;While I used a coupon code to take this course for free, I feel it was worth the listed price. The course covers 19
hours and 172 lessons. The may seem overwhelming at first, but the lessons are short, with most falling in the 4-7
minute range. There are a couple that reach the 10+ minute point, but they still held my attention the entire lesson.&lt;/p&gt;
&lt;p&gt;The instructor has the lessons structured in a way that allows you to pause and return at the start of any lesson
without having to re-execute a long series of code. Most of the lessons are self contained, where a data set is either
re-imported at the start of each lesson or a new one is introduced.&lt;/p&gt;
&lt;p&gt;The only Section that didn't seem to follow this pattern was the visualization module. That module kept using code
from previous lessons. The section is less than an hour, but if you take a break you may need to rerun some of your
code in this section.&lt;/p&gt;
&lt;p&gt;There are 4 "quizzes" in this course. If you've worked through the lessons with the instructor, the questions are
very easy.&lt;/p&gt;
&lt;p&gt;I've now spent 19 hours (re)learning pandas and I feel that I've still just scratched the surface. I've learned a lot
that I'll be taking back to my code, but throughout the course I still got the impression there is much more to pandas.&lt;/p&gt;
&lt;h2 id="notebooks"&gt;Notebooks&lt;a class="headerlink" href="#notebooks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The notebooks that I created during this course are all available on &lt;a href="https://github.com/AWegnerGitHub/Data-Analysis-with-Pandas"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://ude.my/UC-FB6LLMB5"&gt;&lt;img alt="Completion Award" src="https://andrewwegner.com/images/udemy-data-analysis-pandas-completion.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;</content><category term="review"></category><category term="technical"></category><category term="learning"></category></entry><entry><title>Third time's the charm?</title><link href="https://andrewwegner.com/third-times-the-charm.html" rel="alternate"></link><published>2016-11-06T22:54:00-06:00</published><updated>2015-11-28T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-11-06:/third-times-the-charm.html</id><summary type="html">&lt;p&gt;It's been a year since Stack Overflow's last election. I'm running again. Will the third time be the charm, or third strike and I'm out?&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Last year, &lt;a href="https://andrewwegner.com/i'm-running-to-be-a-moderator-of-stack-overflow.html"&gt;I ran for moderator&lt;/a&gt; (&lt;a href="https://andrewwegner.com/i'm-running-for-moderator-on-stack-overflow-again.html"&gt;twice&lt;/a&gt;) on Stack Overflow and didn't make it through the primaries. I came 
close on that second run. Now, a year later, and a year more experienced, I'm going to try again. This post will 
document my progress through the election cycle.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Spoiler Alert&lt;/em&gt;: I didn't win. The rest of this post details my thoughts as the election occured though.&lt;/p&gt;
&lt;h2 id="nomination-phase"&gt;Nomination Phase&lt;a class="headerlink" href="#nomination-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The election this year took a slightly different route than last time. In previous years, the election was announced
at the same time as the call for nominations began. Users had a week to nominate themselves, then we answered a series
of community provided questions during the primaries, then the final election. &lt;/p&gt;
&lt;p&gt;This year, the election was announced a week in advance of nominations. During the week, a call was put out for 
&lt;a href="http://meta.stackoverflow.com/q/337191/189134"&gt;Community questions&lt;/a&gt;. When a nomination was posted, the answers would be posted as well. This change was made due
to how much the community needed to read during the primaries. The primaries were only a few days long and the Q&amp;amp;As 
were usually ten questions for each user. When a primary has 20-30 nominees, that is &lt;em&gt;a lot&lt;/em&gt; of reading that was 
expected in a short period of time. By bringing this phase forward, now the community has the &lt;em&gt;entire&lt;/em&gt; election cycle
to read and interact with the nominees. &lt;/p&gt;
&lt;p&gt;I provided &lt;a href="http://meta.stackoverflow.com/a/337238/189134"&gt;one question&lt;/a&gt; that was used in the final selection of questions. I mentioned &lt;a href="https://andrewwegner.com/i'm-running-for-moderator-on-stack-overflow-again.html"&gt;last time&lt;/a&gt; that I 
thought it was a great question, so I suggested it again:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do you have any Meta posts that you're particularly proud of, or that you feel best demonstrate your moderation style?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="my-nomination"&gt;My nomination&lt;a class="headerlink" href="#my-nomination" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My &lt;a href="http://stackoverflow.com/election/8?tab=nomination#post-40473869"&gt;platform&lt;/a&gt; isn't all the different than the last two times. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi Everyone, I'm &lt;strong&gt;Andy&lt;/strong&gt; and I'd like to be a moderator for you and Stack Overflow. I've answered the questions posted by the community &lt;a href="http://meta.stackoverflow.com/a/337574/189134"&gt;here&lt;/a&gt;. I encourage you to take a look.&lt;/p&gt;
&lt;h3 id="why-should-you-vote-for-me"&gt;Why should you vote for me?&lt;a class="headerlink" href="#why-should-you-vote-for-me" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I've been a moderator on &lt;a href="http://communitybuilding.stackexchange.com"&gt;Community Building&lt;/a&gt; for over two years. I know the moderator tools and have worked with many of the current moderators. This interaction will continue as a new moderator here. &lt;/li&gt;
&lt;li&gt;I have a lot of helpful flags. A decent percentage of these are on &lt;a href="http://meta.stackoverflow.com/questions/280546/"&gt;comments&lt;/a&gt;, but not all. I'd like to help keep the site clean without adding to the current moderators' work load. &lt;/li&gt;
&lt;li&gt;I'm active in the review queues (currently holding 5th in &lt;a href="http://stackoverflow.com/review/low-quality-posts/stats"&gt;Low Quality Post reviewers&lt;/a&gt; of all time), provide edits to posts, answers and enjoy the moderation aspect of Stack Exchange.&lt;/li&gt;
&lt;li&gt;I have a &lt;a href="http://meta.stackoverflow.com/users/189134/"&gt;history on Meta.SO&lt;/a&gt; that shows I'm involved in the meta aspect of the site as well.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I enjoy the moderation aspect on Stack Overflow (and Stack Exchange in general). I have a history of good community moderation, am here all the time and believe I can help the current team.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;During the first full day, I'm gotten positive responses to this post. My two favorite, so far, are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Andy's work around comment flags has been very impressive. I'm definitely curious to see what his thoughts on the mod 
queue are and if we could incorporate some of his work permanently on the site. Better identification of flags is 
something that would be very nice to have permanently.  - &lt;a href="http://stackoverflow.com/users/426671/bluefeet"&gt;bluefeet&lt;/a&gt; &lt;em&gt;Stack Overflow Community Manager&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;and &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are always some nominees for this position who are very active, some who have good judgment and cool heads, and 
some who innovate with their approach to community moderation. Andy is the rare candidate who very clearly checks all 
three boxes. As a user on SO for 3.5 years, a moderator pro tempore on Engineering SE for 1.7 years and an early 
participant in the Community Building SE beta, I strongly support this nomination. - &lt;a href="http://stackoverflow.com/users/2359271/air"&gt;Air&lt;/a&gt; &lt;a href="http://engineering.stackexchange.com/"&gt;&lt;em&gt;Moderator on Engineering.SE&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My candidate score this time is an impressive 39/40. This is up six from a year ago, and up ten from my first run. The 
one missing point is due to missing the &lt;a href="http://stackoverflow.com/help/badges/4369/refiner"&gt;Refiner&lt;/a&gt; badge. I believe the reason for this is because of my workflow. I,
generally, don't edit and answer questions at the same time. If I'm answering, I'm not in "edit" mode. If I'm editting, 
I'm usually in "moderation" mode. It's something I'll work on. I'm 38 out of 50 questions there, so I'll get it soon 
enough.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Candidate Score" src="https://andrewwegner.com/images/november_2016_candidate_score.png"/&gt;&lt;/p&gt;
&lt;h3 id="candidate-questions"&gt;Candidate questions&lt;a class="headerlink" href="#candidate-questions" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;None of the questions were that surprising. With the added benefit of a week to prepare answers prior to nominating,
I am very pleased with my &lt;a href="http://meta.stackoverflow.com/a/337574/189134"&gt;answers&lt;/a&gt;. Two answers have generated a bit of discussion though.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;A 10k+ user regularly has their comments flagged as "rude or offensive" or "not constructive", to the tune of 
4-5 flags a day. No comment by itself is particularly offensive, but their general tone causes them to be flagged 
by multiple users. You've contacted them privately about this, but they believe that they aren't doing anything wrong 
and that people are being too sensitive. The flags keep coming in on their comments. What, if anything, do you do 
next?&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;My response is: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;No one has an exemption from the Be Nice policy. I think the first step is to understand why nothing has already been 
done about the user. 4-5 a day seems like the user has moved beyond the "nuisance" stage. I think a temporary ban is 
appropriate, with another explanation as to what is expected when interacting with others. While some users are more 
sensitive than others, a stream of this many flags across an extended period of time doesn't lead me to believe the 
problem is with the community users.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The point raised in the comments was that I was rushing into banning the user without commuicating first. I disagree
with that, and explained that they've already been contacted privately and ignored those warnings. A ban is the next 
step in getting the user's attention. I was told this would be "humiliating" for a high rep user. Again, I disagree
and believe it's not humiliating, but &lt;a href="http://meta.stackoverflow.com/questions/337571/2016-stack-overflow-moderator-election-qa-questionnaire/337574#comment411104_337574"&gt;educating&lt;/a&gt; the user.&lt;/p&gt;
&lt;p&gt;The second question that generated some discussion was:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;You impose a temporary ban (say 1 week) on a user for what you judged as reasonable and valid reasons (the user 
gets notified by email of your action and the reason). The user replies to your email acknowledging the transgression,
says they won't do it again and asks for the ban to be lifted. The user sounds genuine. Do you remove the ban? Do you 
even reply at all? Explain your reasoning. The context of this question applies to longer bans too. If it helps get 
the juices flowing, consider the situation of a second offence for the same behaviour, which has a default ban 
period of 1 month.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;My response:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have two answers for this question, based on the user's history. If this is a first offense, up to this point the 
user hasn't been pushing limits and attempting to disrupt others, and the ban isn't related to voting fraud, then I'd 
be willing to remove the ban. Sometimes a ban is put in place to get the &lt;a href="http://meta.stackoverflow.com/questions/288229/why-was-balusc-temporarily-suspended-from-so"&gt;user's attention&lt;/a&gt;. Once the situation 
has been resolved, the ban is no longer appropriate and should be removed.&lt;/p&gt;
&lt;p&gt;On the other hand, if the user has a history of crossing the line and looking for a reaction, or if the ban is 
related to vote fraud, I'd simply not reply and the user will return in a week. Stack Overflow has enough "voting 
irregularity" bans that I imagine the responses to such bans are all similar (and invalid). I see no reason to 
change that policy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The push back I recieved on this was that I was letting a user off the hook by unbanning them. I argued that unbanning
has been done in the past. Sometimes the ban is needed simply to get the user's attention and start the conversation
and explain that why they are doing is wrong. If the user abuses the trust at that point and repeats the behavior, then
the longer ban is completely justified. A bit of compassion isn't a bad thing. &lt;/p&gt;
&lt;h2 id="primary-phase"&gt;Primary Phase&lt;a class="headerlink" href="#primary-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;There are 12 nominees, so a primary will occur. Once again, the primary phase will reduce the number of candidates in
the final phase to 10. With so few being eliminated this time around, it feels a little unneeded. The primary will last 
for a few days and during that time users can vote candidates up or down depending whether they believe the nominee
should be a moderator. I'll return in a few days...&lt;/p&gt;
&lt;h3 id="primary-results"&gt;Primary Results&lt;a class="headerlink" href="#primary-results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The Primary phase has ended and the final election has begun. I ended the primary in 5th place, securing a position 
in the final election. I have a sizable margin between my position and sixth place as well. One other stat that I'm
rather proud of: I received the fewest number of down votes of any candidate. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Primary Results" src="https://andrewwegner.com/images/2016-Fall-SO-Primary-Results.png"/&gt;&lt;/p&gt;
&lt;p&gt;On to the election! &lt;/p&gt;
&lt;h2 id="election-phase"&gt;Election Phase&lt;a class="headerlink" href="#election-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The election lasts for several days and covers a weekend. We'll see how it turns out in a few days. &lt;/p&gt;
&lt;h3 id="election-results"&gt;Election Results&lt;a class="headerlink" href="#election-results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Well, the election has concluded. I didn't secure on of the three positions for moderator. I finished in &lt;a href="http://www.opavote.com/results/6488198410665984/0"&gt;5th place&lt;/a&gt;,
with my elimination propelling second and third place to a victory. I was eliminated in the 10th round of the Meek STV
process. &lt;/p&gt;
&lt;p&gt;Good luck to the new moderators!&lt;/p&gt;
&lt;h2 id="post-election-thoughts"&gt;Post Election thoughts&lt;a class="headerlink" href="#post-election-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This election started differently than the previous two I've run in. This election was announced a week in advance
and solicited community input for questions for the candidates. I think this was a good change. The element of 
surprise in the previous two made it much more stressful. Additionally, by having the questions available at the start
of the election - instead of at the start of the primary phase - I was able to better answer the questions. Previously,
the questions would be available at the start of the primary phase. With the amount of reading needed to get through
one candidate's answers, let alone all of them, I imagine that many people didn't read all of the responses. &lt;/p&gt;
&lt;p&gt;The other nice thing about this lead time, is that I had time to get my answers read for when I posted my nomination. 
By posting the questions and answers at the same time, I was able to have my responses available the entire time. 
Score-wise, on the questionnaire, I did much better than my opponents. I think a big reason for this is that I have my
responses posted as soon as my nomination was posted.&lt;/p&gt;
&lt;p&gt;One question this time, though, seemed to split the candidates. I mentioned it previously, but it was regarding 
potentially removing a temporary ban. &lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;You impose a temporary ban (say 1 week) on a user for what you judged as reasonable and valid reasons (the user 
gets notified by email of your action and the reason). The user replies to your email acknowledging the transgression,
says they won't do it again and asks for the ban to be lifted. The user sounds genuine. Do you remove the ban? Do you 
even reply at all? Explain your reasoning. The context of this question applies to longer bans too. If it helps get 
the juices flowing, consider the situation of a second offence for the same behaviour, which has a default ban 
period of 1 month.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was one of two candidates that explicitly stated we'd consider removing the ban. A third user didn't state it 
explicitly, but did say they'd consider it. I was surprised by the harsh tone the others took, especially since there
is a lot of previous discussions on Meta where the outcome is the moderators or community managers removing the ban. I 
was happy to see that the other candidate who said they'd consider removing the ban get elected though.&lt;/p&gt;
&lt;p&gt;I still believe that removing the ban is a valid option. Especially because their &lt;em&gt;next&lt;/em&gt; ban would be much longer if 
they broke my trust. &lt;/p&gt;
&lt;p&gt;We'll see when the next election on Stack Overflow is, but with three new moderators and no resignations, I suspect
it'll be a while. I'll consider running again then. &lt;/p&gt;</content><category term="Stack Exchange"></category><category term="moderation"></category></entry><entry><title>My experiences releasing a package to PyPI</title><link href="https://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html" rel="alternate"></link><published>2016-03-15T12:26:00-05:00</published><updated>2016-03-15T12:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-03-15:/my-experiences-releasing-a-package-to-pypi.html</id><summary type="html">&lt;p&gt;I released StackAPI to PyPI. This post talks about my experiences.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In some of my &lt;a href="http://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;other projects&lt;/a&gt;, I've needed to make extensive use of the Stack Exchange API. I built a small library - StackAPI - to assist in this task and released it on Python's &lt;a href="https://pypi.python.org/pypi/StackAPI"&gt;PyPI repository&lt;/a&gt;. This post is going to cover some of the technical decisions and issues I ran into while going through this process. This was my first project being released to PyPI.&lt;/p&gt;
&lt;p&gt;My goals when releasing this were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clean up my own code so that it is usable by others&lt;/li&gt;
&lt;li&gt;Improve the documentation and host the documentation on &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automatically release it to PyPI, if it passes basic tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those goals sound simple. In the future, they probably will be, but for this first release it wasn't as simple as I was hoping.&lt;/p&gt;
&lt;h2 id="project-layout"&gt;Project Layout&lt;a class="headerlink" href="#project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before this project, I'd written modules and libraries that were used by myself (for personal projects) or as part of a larger application (for work). In both cases, though, I had a directory structure that looked something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;/project_root&lt;/span&gt;
&lt;span class="err"&gt;    /mymodule&lt;/span&gt;
&lt;span class="err"&gt;        __init__.py&lt;/span&gt;
&lt;span class="err"&gt;        mymodule.py&lt;/span&gt;
&lt;span class="err"&gt;    __init__.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This was close to the end goal, but lacked some files in the &lt;code&gt;project_root&lt;/code&gt; that were needed for a proper install via &lt;code&gt;pip&lt;/code&gt;. The important file that was missing was &lt;code&gt;setup.py&lt;/code&gt;. I needed this file to ensure that everything would install with a simple &lt;code&gt;pip install stackapi&lt;/code&gt; &lt;/p&gt;
&lt;h3 id="setuppy"&gt;setup.py&lt;a class="headerlink" href="#setuppy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.py"&gt;&lt;code&gt;setup.py&lt;/code&gt;&lt;/a&gt; is pretty basic and available on GitHub. There are a couple important things though.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt;: This is needed, but I didn't want to have to constantly remember to update this when pushing a version to PyPI. This was one of my first criteria when starting the project. I wanted to automate as much as I could, and versioning was at the top of that list. It's small, but easy to forget and keep syncronized across all the files in the project. I decided to utilize &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; and &lt;a href="http://www.fabfile.org/"&gt;Fabric&lt;/a&gt; to manage this specific field (both here and elsewhere in the project).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;install_requires&lt;/code&gt;: StackAPI is built in the fantastic &lt;a href="http://docs.python-requests.org/en/master/"&gt;Requests&lt;/a&gt; library. To ensure this was installed when StackAPI was install, it was needed in this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tests_require&lt;/code&gt;: The test suite I build utilizes the &lt;code&gt;mock&lt;/code&gt; library. I don't want that to be installed if the developer isn't running the tests, so it is added to this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_suite&lt;/code&gt;: I wanted developers to be able to run &lt;code&gt;python setup.py test&lt;/code&gt; to execute the test suite. To do so, I had to point to the where the tests were being executed from.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The rest of &lt;code&gt;setup.py&lt;/code&gt; seemed to be fairly standard when compared to other Python libraries.&lt;/p&gt;
&lt;h3 id="bumpversion-and-fabric"&gt;Bumpversion and Fabric&lt;a class="headerlink" href="#bumpversion-and-fabric" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned, I wanted to automate any versioning that was required. To do so, I used the &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; library and wrote a small &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/fabfile.py"&gt;Fabric&lt;/a&gt; script to handle it automatically. &lt;code&gt;bumpversion&lt;/code&gt; uses a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.cfg"&gt;config file&lt;/a&gt;, to determine what it is going to do. I configured it to automatically create a commit and a new git tag for each version. I then pointed to a couple files where the current version is listed. When &lt;code&gt;bumpversion&lt;/code&gt; is executed, it will change the version in each of those files to the new version. It will then create a single commit to the git repository with a commit message similar to&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bump version: 0.1.6 → 0.1.7&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is nice and clean. It tags the commit for me, which is useful later, when I want to push the change to PyPI.&lt;/p&gt;
&lt;p&gt;To make running &lt;code&gt;bumpversion&lt;/code&gt; a bit easier, I utilized a Fabric routine I found &lt;a href="https://gist.github.com/jbarratt/85c91d7b904462702892"&gt;online&lt;/a&gt; and adjusted it for my purposes. When I run &lt;code&gt;fab release&lt;/code&gt;, all of the &lt;code&gt;bumpversion&lt;/code&gt; 'stuff' occurs. Then I just have to push the commit (and new tag) to GitHub.&lt;/p&gt;
&lt;h3 id="final-project-layout"&gt;Final Project Layout&lt;a class="headerlink" href="#final-project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final project layout I settled on was this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;/stackapi&lt;/span&gt;
&lt;span class="err"&gt;    /docs&lt;/span&gt;
&lt;span class="err"&gt;        ...&lt;/span&gt;
&lt;span class="err"&gt;    /stackapi&lt;/span&gt;
&lt;span class="err"&gt;        __init__.py&lt;/span&gt;
&lt;span class="err"&gt;        stackapi.py&lt;/span&gt;
&lt;span class="err"&gt;    /tests&lt;/span&gt;
&lt;span class="err"&gt;    .gitignore&lt;/span&gt;
&lt;span class="err"&gt;    .travis.yml&lt;/span&gt;
&lt;span class="err"&gt;    fabfile.py&lt;/span&gt;
&lt;span class="err"&gt;    setup.cfg&lt;/span&gt;
&lt;span class="err"&gt;    setup.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="read-the-docs"&gt;Read the Docs&lt;a class="headerlink" href="#read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="configure-the-project"&gt;Configure the project&lt;a class="headerlink" href="#configure-the-project" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In the final project layout, you can see there is a &lt;code&gt;docs&lt;/code&gt; directory. One of my goals was to make this library usable and understandable by other developers. A good part of that means having decent documentation. I spent way more time than I expected cleaning the documentation in the code and creating documentation with examples. Most of that time was spent learning the sphinx documentation style and ReStructuredText, which Read the Docs utilizes.&lt;/p&gt;
&lt;p&gt;The first step in this process was installing and setting up the initial configuration for the documentation:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;pip install sphinx sphinx-autobuild&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, I created the &lt;code&gt;docs&lt;/code&gt; directory and switched to it and ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sphinx-quickstart&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This starts a short, interactive, wizard. Fill out the questions. At the end of this, it creates a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/docs/conf.py"&gt;&lt;code&gt;conf.py&lt;/code&gt;&lt;/a&gt; file in the &lt;code&gt;docs&lt;/code&gt; directory. The rest of the &lt;a href="https://github.com/AWegnerGitHub/stackapi/tree/master/docs"&gt;documentation&lt;/a&gt; is ReStructuredText files.&lt;/p&gt;
&lt;p&gt;To see how the documentation looks, from the &lt;code&gt;docs&lt;/code&gt; directory, run:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;make html&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates a &lt;code&gt;_build&lt;/code&gt; directory. If you open &lt;code&gt;_build/html/index.html&lt;/code&gt;, the documentation can be browsed locally. I do not commit this directory to git, though. It is ignored in &lt;code&gt;.gitignore&lt;/code&gt;, as a user can regenerate it at will.&lt;/p&gt;
&lt;h3 id="configure-read-the-docs"&gt;Configure Read the Docs&lt;a class="headerlink" href="#configure-read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I was satisfied with how the documentation looked, I had to configure Read the Docs to read my GitHub repository. To repeat those steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sign up (or log in) at &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt; (part of this will be associating the account to a GitHub account)&lt;/li&gt;
&lt;li&gt;Visit your &lt;a href="https://readthedocs.org/dashboard/"&gt;dashboard&lt;/a&gt; and click "Import a project"&lt;/li&gt;
&lt;li&gt;Fill out the form, but in my case the defaults were all appropriate. Do note that URLs are case sensitive.&lt;/li&gt;
&lt;li&gt;Click "Create". This is the first version of your documentation.&lt;/li&gt;
&lt;li&gt;To keep the code updating as you update GitHub, log into GitHub and go to the repository's "Settings" page.&lt;/li&gt;
&lt;li&gt;Click "Webhooks &amp;amp; Services"&lt;/li&gt;
&lt;li&gt;Click "Add Service"&lt;/li&gt;
&lt;li&gt;Select "ReadTheDocs" and add the service&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, each time you push a change to the repository, a new set of documents will be built. I then added the Read the Docs badge to my &lt;code&gt;README.rst&lt;/code&gt; for a simple link to the detailed documentation.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt; &lt;span class="ow"&gt;image&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt; https://readthedocs.org/projects/stackapi/badge/?version=latest
&lt;span class="nc"&gt;:target:&lt;/span&gt; http://stackapi.readthedocs.org/en/latest/?badge=latest
&lt;span class="nc"&gt;:alt:&lt;/span&gt; Documentation Status
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="force-rebuild-of-docs"&gt;Force rebuild of docs&lt;a class="headerlink" href="#force-rebuild-of-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Toward the very end of this project, Read the Docs had a minor hiccup and failed on building my documentation. I didn't want to force a build by making a fake commit. Instead, Read the Docs provides the information needed to force a rebuild. It requires a very simple &lt;code&gt;POST&lt;/code&gt; to the Post Commit Hook they provide. In my case, this was as simple as running this command (provided from the Dashboard):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;curl -X POST https://readthedocs.org/build/stackapi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="pypi"&gt;PyPI&lt;a class="headerlink" href="#pypi" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Nearing the end of the journey, it was time to see what exactly PyPI required. The first step was setting up an account on both the Test and Production instances of PyPI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PiPY Test: http://testpypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;li&gt;PyPI Live: https://pypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having one on both was important while testing. It meant that I didn't have to send broken versions to the live PyPI server, and I could adjust ReStructuredText formatting issues without requiring another release to PyPI. Each time a version is pushed to PyPI it &lt;strong&gt;must&lt;/strong&gt; have a new version number. By using the test instance, I could use as many of these fake versions as needed to fix things. Hooray for test environments!&lt;/p&gt;
&lt;p&gt;Before we perform this step automatically, we need to test that the PyPI accounts work. By following portions of a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;"First Time with PyPI"&lt;/a&gt; tutorial, I focused by steps down to these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a &lt;code&gt;.pypirc&lt;/code&gt; file in your home directory - not your project directory. This won't be required once Travis CI is set up and configured, so having the passwords in this, temporarily, wasn't an issue because I eventually deleted the file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The file looks like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[distutils]&lt;/span&gt;
&lt;span class="na"&gt;index-servers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&lt;/span&gt;
&lt;span class="s"&gt;  pypi&lt;/span&gt;
&lt;span class="s"&gt;  pypitest&lt;/span&gt;

&lt;span class="k"&gt;[pypi]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://pypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;

&lt;span class="k"&gt;[pypitest]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://testpypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Register the package on PyPI Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Register the package on PyPI Live: &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Live, &lt;em&gt;if&lt;/em&gt; you're ready for your first release. Remember, once a version is released to PyPI, it can't be used again (or overwritten): &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all of the above passed to your satisfaction, you can remove the &lt;code&gt;.pypirc&lt;/code&gt; file and move on to configuring Travis CI.&lt;/p&gt;
&lt;h2 id="travis"&gt;Travis&lt;a class="headerlink" href="#travis" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The last step in this process will be using Travis CI to perform some basic tests and, if this was a new release, push the changes to PyPI. The Travis config file is available on &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My goal is to support 'modern' Python with this library. I've configured Travis to test against multiple versions of Python, ranging from 2.7 to 3.5. StackAPI is installed using &lt;code&gt;python setup.py -q install&lt;/code&gt;. Then the test suite is run.&lt;/p&gt;
&lt;p&gt;The important bits are in the &lt;code&gt;deploy&lt;/code&gt; section.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="n"&gt;branch&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If there is a new git tag pushed to GitHub, and the tests pass, Travis CI will push the code to PyPI. Since &lt;code&gt;bumpversion&lt;/code&gt; makes a new git tag with each new version, this works perfectly.&lt;/p&gt;
&lt;p&gt;This does require that my password be included in the yml file. To keep this secure, I utilized the &lt;a href="https://blog.travis-ci.com/2013-01-14-new-client/"&gt;Travis Command Line Client&lt;/a&gt; (&lt;code&gt;gem install travis&lt;/code&gt;). In my local directory, I then ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;travis encrypt --add deploy.password&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This added the password to the YML file.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This was the first time I've released something to PyPI. It took a lot more set up than I expected it would take. However, now that I've gone through the process, gotten used to the ReStructuredText format that Sphinx and Read the Docs require, and set up PyPI for one project, I think it'll be fairly simple to do in the future. Most of the work is getting the other services to talk with GitHub and practicing good developer habits (documentation...).&lt;/p&gt;
&lt;h2 id="all-stackapi-links"&gt;All StackAPI Links&lt;a class="headerlink" href="#all-stackapi-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of these links are to the various places that StackAPI lives on the internet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: https://github.com/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;: http://stackapi.readthedocs.org/en/latest/&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TravisCI&lt;/strong&gt;: https://travis-ci.org/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPI&lt;/strong&gt;: https://pypi.python.org/pypi/StackAPI&lt;/li&gt;
&lt;/ul&gt;</content><category term="technical"></category></entry><entry><title>How I built a Flask application that integrates with Travis CI and OpenShift</title><link href="https://andrewwegner.com/how-i-set-up-openshift-travisci-and-flask.html" rel="alternate"></link><published>2015-12-11T09:15:00-06:00</published><updated>2015-12-12T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-12-11:/how-i-set-up-openshift-travisci-and-flask.html</id><summary type="html">&lt;p&gt;A walkthrough on how I set up a Flask application on OpenShift and used TravisCI to deploy it&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since I &lt;a href="https://andrewwegner.com/thanks-for-all-the-fish.html"&gt;shut down&lt;/a&gt; Vipers early this year, I've been itching to do &lt;em&gt;something&lt;/em&gt; web related. Web technologies aren't my best technical skill, but I like trying out new things and learning something in the process. I use Python at work. I like Python a lot. With Christmas and New Years coming up, I want to have a project during my down time. My goal is to get a &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; application built and then deployed to &lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt;. Part of this deployment is to utilize &lt;a href="https://travis-ci.org/"&gt;TravisCI&lt;/a&gt;. I'm planning on using &lt;a href="http://pytest.org/latest/"&gt;pytest&lt;/a&gt; and &lt;a href="https://hypothesis.readthedocs.org/en/latest/"&gt;hypothesis&lt;/a&gt; for my test suite. Finally, I want to use my own (sub)domain, instead of the provided &lt;code&gt;rhcloud&lt;/code&gt; one.&lt;/p&gt;
&lt;p&gt;Of these three technologies, I've used only Flask before. The &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;comment flagging bot&lt;/a&gt; I built has a dashboard built in Flask. I've never used OpenShift or TravisCI. I selected OpenShift because it has a couple &lt;a href="http://www.paasify.it/compare/heroku-vs-openshift%20online"&gt;features&lt;/a&gt; I want that Heroku doesn't. The biggest one, according to the previous link, was that OpenShift has support for MySQL and Heroku doesn't (surprisingly). I want to use TravisCI and automated testing, because one of my goals for next year at work is to introduce automated tested to our development. (I work with Engineers, not coders...that's my excuse and it's a bad excuse, so I'm going to try and fix it.) To get ready for that goal, I want to test out a system that does continuous integration/automated testing. Both OpenShift and Travis CI provide me with free services. Hypothesis and py.test provide me with a way to generate comprehensive test conditions. &lt;/p&gt;
&lt;h2 id="openshift-set-up"&gt;OpenShift set up&lt;a class="headerlink" href="#openshift-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Signing up for OpenShift was easy. Fill out the form, provide an email address - though they don't like email addresses with &lt;code&gt;+&lt;/code&gt; signs, which is disappointing - and then click the link they email back to you. &lt;/p&gt;
&lt;p&gt;Next, the &lt;code&gt;rhc&lt;/code&gt; OpenShift client tools are needed. This is a Ruby package. I have no experience with Ruby, so I needed to install Ruby as well. I ran into a problem almost immediately. The &lt;a href="https://developers.openshift.com/en/managing-client-tools.html"&gt;page&lt;/a&gt; for installing these tools says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenShift rhc can be run on any operating system with Ruby 1.8.7 or higher assuming you have the requisite user permissions to install programs. Instructions for specific operating systems are provided below. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Based on that, I figured I'd install the latest version of &lt;a href="http://rubyinstaller.org/downloads/"&gt;Ruby&lt;/a&gt;. At the time I tested this, that was 2.2.3. Unfortunately, when I ran the command to install the &lt;code&gt;rhc&lt;/code&gt; tools, I received an error. After a bit of Googling, I found that it doesn't like 2.2x. So, I installed 2.1.7 instead. Next, I ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gem install rhc&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This installs several gems and took a few minutes to complete. Next,&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;rhc setup&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This started the OpenShift setup wizard. It consisted of filling out the few prompts and letting it generate an SSH key and then connecting to my account. Remember the Namespace you select. Again, this took a few minutes.&lt;/p&gt;
&lt;h2 id="flask-setup"&gt;Flask setup&lt;a class="headerlink" href="#flask-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next step was to set up my first "Gear". This would be the Flask application. I'll work on the database next. First, I just want Python and Flask to function properly. Fortunately, this is very easy, as OpenShift has a Flask template.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;rhc app create testapp python-2.7 --from-code=https://github.com/openshift-quickstart/flask-base.git&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am utilizing Python 2.7, because that is the recommendation from the Flask team.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;testapp&lt;/code&gt; can be any alphanumeric string. This is the name that will appear in the Web Console. A specific note, &lt;code&gt;_&lt;/code&gt; is not alphanumeric. I'm getting the feeling that OpenShift doesn't like "special" characters.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--from-code&lt;/code&gt; parameter will download that repository and use it as the base of your application. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, Flask can be run locally using:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;python app.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The application can be pushed back to OpenShift at this point and there should be a functional page on your OpenShift domain. In your command line, from the directory of your project:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git add --all&lt;/span&gt;
&lt;span class="err"&gt;git commit -m "Adding Flask application"&lt;/span&gt;
&lt;span class="err"&gt;git push&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a moment. At the end, you should see these lines in your command prompt:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Git&lt;/span&gt; &lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Receive&lt;/span&gt; &lt;span class="n"&gt;Result&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Activation&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Deployment&lt;/span&gt; &lt;span class="n"&gt;completed&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If all three are a success, then you should be able to visit your URL. Your URL is a combination of your selected Namespace and the application name you created.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;http://&amp;lt;namespace&amp;gt;-&amp;lt;testapp&amp;gt;.rhcloud.com/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should show a "Welcome to Flask on OpenShift" page. If you append &lt;code&gt;/test&lt;/code&gt; to your URL, you'll get a message that says "It's Alive!"&lt;/p&gt;
&lt;p&gt;If it doesn't, you can check your error logs by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;rhc tail -a &amp;lt;testapp&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="mysql-setup"&gt;MySQL setup&lt;a class="headerlink" href="#mysql-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Next, I set up my application to utilize MySQL. It's the database I have the most experience with, so I decided to keep that aspect of this project simple for myself. The first step was to add a MySQL 5.5 cartridge to my test gear (OpenShift terminology). I did this in the OpenShift web console. The UI provided me with the option to install various databases and one of those was MySQL. Clicking the link caused a few second delay as it was set up, and then I was presented with login credentials to my database. Step one...done.&lt;/p&gt;
&lt;p&gt;The next step is installing the correct Python modules to utilize MySQL. I selected &lt;a href="http://www.pymysql.org/"&gt;PyMySQL&lt;/a&gt; (again, experience) and &lt;a href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. I added these to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;. The idea behind doing it in both places is to make life easy for myself in the future. Additionally, the quick tutorials I've looked at for TravisCI encourage the usage of &lt;code&gt;requirements.txt&lt;/code&gt;, while it seems OpenShift uses the &lt;code&gt;setup.py&lt;/code&gt;. I'll fix that eventually, but getting it set up initially, this will be fastest.&lt;/p&gt;
&lt;p&gt;Add these to &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;sqlalchemy==1.0.9&lt;/span&gt;
&lt;span class="err"&gt;pymysql==0.6.7&lt;/span&gt;
&lt;span class="err"&gt;Flask-SQLAlchemy==2.1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add this to the &lt;code&gt;install_requires&lt;/code&gt; list in &lt;code&gt;setup.py&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;'sqlalchemy==1.0.9','pymysql==0.6.7','Flask-SQLAlchemy==2.1'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The nice thing about OpenShift is that the credentials to the database are placed in &lt;a href="https://developers.openshift.com/en/managing-environment-variables.html#database-variables"&gt;environment variables&lt;/a&gt;, so I don't need to embed the passwords, connections strings, or anything potentially sensitive in my code. For MySQL these are available as:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;Variable Name               |   Purpose&lt;/span&gt;
&lt;span class="err"&gt;------------------------------------------------&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_HOST     |   The host name or IP address used to connect to the database.&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_PORT     |   The port the database server is listening on.&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_USERNAME |   The database administrative user name.&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_PASSWORD |   The database administrative user’s password.&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_SOCKET   |   An AF socket for connecting to the database (for non-scaled apps only).&lt;/span&gt;
&lt;span class="err"&gt;OPENSHIFT_MYSQL_DB_URL      |   Database connection URL.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="utilizing-the-database"&gt;Utilizing the database&lt;a class="headerlink" href="#utilizing-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Setting up SQLAlchemy and MySQL is fairly easy. I tested this with a simple table and ensured that it appeared in the database as expected.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;class User(db.Model):&lt;/span&gt;
&lt;span class="err"&gt;    __tablename__ = 'users'&lt;/span&gt;
&lt;span class="err"&gt;    id = db.Column('user_id', db.Integer, primary_key=True)&lt;/span&gt;
&lt;span class="err"&gt;    name = db.Column(db.String(60))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few adjustments were made to the import statements of the Flask application:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask_sqlalchemy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SQLAlchemy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A couple variables were created and loaded:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;app.config.from_pyfile('flaskapp.cfg')&lt;/span&gt;
&lt;span class="err"&gt;db = SQLAlchemy(app)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the &lt;code&gt;flaskapp.cfg&lt;/code&gt; file was modified to include these two lines:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;SQLALCHEMY_DATABASE_URI = os.environ['OPENSHIFT_MYSQL_DB_URL'] + os.environ['OPENSHIFT_APP_NAME]&lt;/span&gt;
&lt;span class="err"&gt;SQLALCHEMY_ECHO = False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="remote-mysql-access"&gt;Remote MySQL Access&lt;a class="headerlink" href="#remote-mysql-access" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I like to use &lt;a href="https://www.mysql.com/products/workbench/"&gt;MySQL Workbench&lt;/a&gt; while building and testing to watch what's happening in the database. To use that with OpenShift, I had to jump through a few small hoops. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open MySQL Workbench and create a new connection&lt;/li&gt;
&lt;li&gt;Give the connection a name&lt;/li&gt;
&lt;li&gt;In "Connection Method", select "Standard TCP/IP over SSH"&lt;/li&gt;
&lt;li&gt;The SSH Hostname is the full name of your OpenShift gear where MySQL is installed. It should look like &lt;code&gt;namespace-appname.rhcloud.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The SSH Username is the gear's Unique Identifier. This can be found by looking at the &lt;code&gt;OPENSHIFT_GEAR_UUID&lt;/code&gt; environment variable. It can also be found in the web console, but looking at the "remote access" section. It shows a connection string. You need the username portion. This is the part that appears before the &lt;code&gt;@&lt;/code&gt; in the &lt;code&gt;ssh longuniquestring@namespace-appname.rhcloud.com&lt;/code&gt; command. &lt;/li&gt;
&lt;li&gt;Set the SSH key file. On Windows this is in &lt;code&gt;\Users\&amp;lt;username&amp;gt;\.ssh\id_rsa&lt;/code&gt; by default&lt;/li&gt;
&lt;li&gt;Set MySQL Hostname equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_HOST&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set Username equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_USERNAME&lt;/code&gt; (this was also provided to you when you installed MySQL)&lt;/li&gt;
&lt;li&gt;See Password equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_PASSWORD&lt;/code&gt; (again, this was provided to you when MySQL was installed)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="travisci-setup"&gt;TravisCI setup&lt;a class="headerlink" href="#travisci-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I want to play with automated testing. The idea behind this is to get a jump start on a goal for next year at work and to learn something new. I'd like to utilize Travis CI to perform the tests and if they pass, deploy to OpenShift. If the tests fail, I don't want to push a broken build to OpenShift. That's the goal...we'll see how it turns out. But, the first step is getting Travis CI and OpenShift talking to one another.&lt;/p&gt;
&lt;p&gt;Travis CI integrates with GitHub, so what I'm going to do in reality is push to GitHub and let Travis CI pick up the changes. From there, it will perform it's tests. If the tests pass, it will push the commit to OpenShift.&lt;/p&gt;
&lt;p&gt;On GitHub, create a new repository for your source. This is where you will be pushing your code for Travis CI to pick up.&lt;/p&gt;
&lt;p&gt;From your OpenShift directory (which is already a git repository):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git remote rename origin openshift&lt;/span&gt;
&lt;span class="err"&gt;git remote add origin https://github.com/&amp;lt;USER&amp;gt;/&amp;lt;repositoryname&amp;gt;.git&lt;/span&gt;
&lt;span class="err"&gt;git push -u origin master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This resets the origin to point to your new GitHub repository and sets up a new remote. Then it pushes the changes to GitHub.&lt;/p&gt;
&lt;p&gt;Log into your &lt;a href="https://travis-ci.org/profile"&gt;Travis CI profile page&lt;/a&gt;. Make sure you are logged into GitHub first, as this will create the profile automatically. Press the "Sync now" button at the top of the page to pull a list of all of your repositories. Once that is done, find the repository you just set up, and enable integration with that repository.&lt;/p&gt;
&lt;p&gt;Next you need to set up Travis CI and the &lt;code&gt;.travis.yml&lt;/code&gt; file. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;gem install travis&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install a Ruby script that assists in this process. If you get an error when running this, you need to create an empty &lt;code&gt;.travis.yml&lt;/code&gt; file first and then run the command again.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;travis setup openshift&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fill out the prompts. Defaults should be fine in most cases, but do pay attention to "OpenShift application name". If your GitHub repository is named differently than your OpenShift application name, the default for this prompt will be incorrect.&lt;/p&gt;
&lt;p&gt;One last note, for a quick test you can change the &lt;code&gt;script&lt;/code&gt; section to &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This forces the tests to pass. Once you've written tests, you can do something like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;script:&lt;/span&gt;
&lt;span class="c"&gt;    - py.test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run your test scripts, utilizing &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Deploy these changes to GitHub:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git add .travis.yml&lt;/span&gt;
&lt;span class="err"&gt;git commit -m "Deploying Travis"&lt;/span&gt;
&lt;span class="err"&gt;git push origin master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will commit and push the changes to GitHub. A few seconds later, if you are watching Travis CI, you'll see it notices the new commit and starts running tests. If you tests complete with a status code of &lt;code&gt;0&lt;/code&gt; (successful), it will deploy the changes to OpenShift. If the tests fail (any other status code), it will not deploy to OpenShift.&lt;/p&gt;
&lt;h2 id="pytest-setup"&gt;py.test setup&lt;a class="headerlink" href="#pytest-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Setting up the testing frame work involves a few Python modules. These need to be added to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;pytest&amp;gt;=2.8.0&lt;/span&gt;
&lt;span class="err"&gt;hypothesis==1.16.0&lt;/span&gt;
&lt;span class="err"&gt;pytest-runner==2.6.2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The next step is setting up some quick integration with &lt;code&gt;setup.py&lt;/code&gt;, so that users can run &lt;code&gt;python setup.py test&lt;/code&gt; and execute your tests.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;setup.py&lt;/code&gt;, add (or edit) the &lt;code&gt;setup_requires&lt;/code&gt; list to include &lt;code&gt;pytest-runner&lt;/code&gt;. Add (or edit) the &lt;code&gt;tests_require&lt;/code&gt; list to include &lt;code&gt;pytest&lt;/code&gt;. I also added the following to my &lt;code&gt;setup.cfg&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[aliases]&lt;/span&gt;
&lt;span class="na"&gt;test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;pytest&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I modified my &lt;code&gt;setup_requires&lt;/code&gt; list a bit, so that it's conditional. Since this would install the &lt;code&gt;pytest-runner&lt;/code&gt; on every call to &lt;code&gt;setup.py&lt;/code&gt;, even when the module wouldn't be called, I wanted the runner to only be required when &lt;code&gt;pytest&lt;/code&gt; is utilized.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'pytest'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ptr'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intersection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pytest_runner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pytest-runner'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;setup_requires&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="c1"&gt;#... Other requirements here&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pytest_runner&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I wanted to test that my tests were working correctly. I created a &lt;code&gt;tests&lt;/code&gt; directory, which is where I plan on storing all of my test cases. &lt;code&gt;pytest&lt;/code&gt; will find any files that start or end with &lt;code&gt;test&lt;/code&gt; and execute them. I created a very simple &lt;code&gt;test_tests.py&lt;/code&gt; file with the following simple test (taken from the &lt;a href="https://hypothesis.readthedocs.org/en/latest/quickstart.html#writing-tests"&gt;Hypothesis Quickstart&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;@given(st.integers(), st.integers())&lt;/span&gt;
&lt;span class="err"&gt;def test_ints_are_commutative(x, y):&lt;/span&gt;
&lt;span class="err"&gt;    assert x + y == y + x&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, Travis CI needs to be told what to do. Modify the &lt;code&gt;script&lt;/code&gt; key to include &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;script:&lt;/span&gt;
&lt;span class="c"&gt;   - py.test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After a successful run through Travis, you'll see something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;tests/test_tests.py .&lt;/span&gt;
&lt;span class="err"&gt;=========================== 1 passed in 0.26 seconds ===========================&lt;/span&gt;
&lt;span class="err"&gt;The command "py.test" exited with 0.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="custom-domain"&gt;Custom Domain&lt;a class="headerlink" href="#custom-domain" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have my own domain name. I want to utilize OpenShift with one of those domains, instead of the default one provided. Since I've using the free tier, that will rule out using the SSL certificate that is wildcarded to the whole &lt;code&gt;rhcloud.com&lt;/code&gt; domain. I can live with this. If I need SSL on my domain, I'll upgrade.&lt;/p&gt;
&lt;p&gt;To set up OpenShift to use your domain, log into the web console. Go to the gear you are configuring. At the top, where the full domain is displayed, is the option to "Change". Select that option. Input the full domain (and subdomain) you want to utilize and click "Save". After a few seconds, you'll get a notification that the alias was created.&lt;/p&gt;
&lt;p&gt;The next step is to configure the DNS records. I &lt;a href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;utilize&lt;/a&gt; CloudFlare for my domains, so the instructs will be specific to that, but should apply to any DNS system. Login to your management system and go to the area where you can specify DNS records.&lt;/p&gt;
&lt;p&gt;For my test, I set up a subdomain of one of my domains as the alias I wanted to use. In your DNS system, set up a CNAME that points to the original hostname on OpenShift. The CNAME should be the subdomain you told OpenShift about. Save the record. &lt;/p&gt;
&lt;p&gt;CloudFlare recognized this immediately and redirected me to my Flask application. Hooray!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this, the set up is complete. You have a Flask application, connected to MySQL, that is integrated with a CI system which automatically deploys to OpenShift when all tests pass and uses CloudFlare (because I already was doing so), to provide a CDN. &lt;/p&gt;
&lt;p&gt;On to building something!&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>I'm running for moderator on Stack Overflow again</title><link href="https://andrewwegner.com/i'm-running-for-moderator-on-stack-overflow-again.html" rel="alternate"></link><published>2015-11-18T09:38:00-06:00</published><updated>2015-12-08T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-11-18:/i'm-running-for-moderator-on-stack-overflow-again.html</id><summary type="html">&lt;p&gt;Stack Overflow is having a second election this year. I'm throwing my hat in the ring again. This entry follows the process.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In April, &lt;a href="https://andrewwegner.com/i'm-running-to-be-a-moderator-of-stack-overflow.html"&gt;I ran for moderator&lt;/a&gt; on Stack Overflow and didn't make it through the primaries. That's ok though, there were several very good users that did get &lt;a href="http://stackoverflow.com/election/6"&gt;elected&lt;/a&gt;. In a surprise announcement, though, Stack Overflow is running a second election this year. This is the first time this has happened since 2011. I'm still interested in a position and I'm still active in the community, so I'm going to run again. This post will follow the process.&lt;/p&gt;
&lt;h2 id="nomination-phase"&gt;Nomination Phase&lt;a class="headerlink" href="#nomination-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Like last time, the nomination phase began with users throwing their hat into the ring. Nominations were slower and fewer this time. Only 19 nominees, so no one was eliminated due to low reputation. Several users from the last election are rerunning too. &lt;/p&gt;
&lt;h3 id="my-platform"&gt;My Platform&lt;a class="headerlink" href="#my-platform" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My &lt;a href="http://stackoverflow.com/election/7#post-33617646"&gt;platform&lt;/a&gt; hasn't changed much since the previous run. Below is my nomination post. This time, I tried to pull emphasis off the automated script by putting it lower on the list of things I've done and instead focused on the moderation tasks I do on Stack Overflow and the work I've done on &lt;a href="http://communitybuilding.stackexchange.com"&gt;Community Building&lt;/a&gt;. We'll see if it works.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hi Everyone, I'm &lt;strong&gt;Andy&lt;/strong&gt; and I'd make a great moderator for Stack Overflow.&lt;/p&gt;
&lt;h3 id="why-vote-for-me"&gt;Why vote for me?&lt;a class="headerlink" href="#why-vote-for-me" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I'm active in the review queues (currently holding 10th in &lt;a href="http://stackoverflow.com/review/low-quality-posts/stats"&gt;Low Quality Post reviewers&lt;/a&gt; of all time), provide edits to posts, &lt;a href="http://stackoverflow.com/users/189134/andy?tab=answers"&gt;answers&lt;/a&gt; and enjoy the moderation aspect of Stack Exchange&lt;/li&gt;
&lt;li&gt;I've been a moderator on &lt;a href="http://communitybuilding.stackexchange.com"&gt;CommunityBuilding&lt;/a&gt; for nearly a year and a half. I know the moderator tools and have worked with several of the current moderators. This interaction will continue as a new moderator here. &lt;/li&gt;
&lt;li&gt;I've built an automated script that continues to handle &lt;a href="http://meta.stackoverflow.com/q/280546/189134"&gt;noisy comments&lt;/a&gt; very &lt;a href="http://i.stack.imgur.com/GK32p.png"&gt;accurately&lt;/a&gt;. &lt;/li&gt;
&lt;li&gt;I have a &lt;a href="http://meta.stackoverflow.com/users/189134/andy"&gt;history&lt;/a&gt; on Meta.SO that shows I'm involved in the meta aspect of the site as well.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have a history of good community moderation already. I enjoy the moderation aspect on Stack Overflow (and Stack Exchange in general). I deal with users with respect, even if our opinions on an issue differ. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this, I received my "candidate score". It was 33/40. Not the highest, but better than last time. The score wasn't mentioned in April. I am not expecting it to be an issue this time either.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Candidate Score" src="https://andrewwegner.com/images/november_2015_candidate_score.png"/&gt;&lt;/p&gt;
&lt;h2 id="primary-phase"&gt;Primary Phase&lt;a class="headerlink" href="#primary-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated November 21, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The primary phase is in the third day. In day 1, I was hovering around 9th/10th place. Overnight, between days 1 and 2 though, I dropped down to 11th. I've been sitting here consistantly for a full day now and, while still gaining votes, I'm not gaining as fast as 10th position. It appears I may not make the cutoff by Friday's deadline. While disappointing, there are a few things that I came away with that I'm very happy about.&lt;/p&gt;
&lt;p&gt;In the last primary, I revieved 1,492 positive votes. I've surpassed that already. I've over 2,100 currently. I'm pleased with that upswing. I was also more prepared for the questionnaire portion of the primaries this time. I've gotten the second highest number of upvotes on my &lt;a href="http://meta.stackoverflow.com/a/310357/189134"&gt;responses&lt;/a&gt;. Several of the questions were similar to last time, but there are a few that I think should be included in the future elections.&lt;/p&gt;
&lt;h3 id="questionnaire"&gt;Questionnaire&lt;a class="headerlink" href="#questionnaire" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This first question is a &lt;em&gt;great&lt;/em&gt; post for candidates. It allows them to show off their involvement in Meta and show their best work. For users, it gives them a sense of how a candidate interacts with the community. I am very surprised that several candidates list only one or two posts. This seems to be doing a disservice to themselves.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do you have any Meta posts that you're particularly proud of, or that you feel best demonstrate your moderation style?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My response to this question:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I'm proud of several of my posts both here on Meta.SO and on other network sites I participate in. Here on MSO, I have two questions that I am proud of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://meta.stackoverflow.com/questions/280546/can-a-machine-be-taught-to-flag-comments-automatically"&gt;Can a machine be taught to flag comments automatically?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://meta.stackoverflow.com/questions/300916/i-estimate-10-of-the-links-posted-here-are-dead-how-do-we-deal-with-them"&gt;I estimate 10% of the links posted here are dead. How do we deal with them?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In both of these, you can see that I care about quality on Stack Overflow. I've spent time analyzing the problem, as I see it, and present my findings to the community. I participated in the discussions that both posts generated and &lt;a href="http://i.stack.imgur.com/XQoP5.png"&gt;continue to run&lt;/a&gt; the bot to this day. &lt;/p&gt;
&lt;p&gt;Elsewhere on the network, my participation in meta has helped to shape communities. For example, on &lt;a href="http://hardwarerecs.stackexchange.com"&gt;Hardware Recommendations&lt;/a&gt;, my meta post about &lt;a href="http://meta.hardwarerecs.stackexchange.com/a/81/57"&gt;"What type of hardware is allowed"&lt;/a&gt; helped to set the scope of what the community accepts as on topic hardware. I've also helped to set up the &lt;a href="http://meta.hardwarerecs.stackexchange.com/a/206/57"&gt;high quality guidelines for questions&lt;/a&gt; and &lt;a href="http://meta.hardwarerecs.stackexchange.com/a/274/57"&gt;argued against certain types of tags&lt;/a&gt; and &lt;a href="http://meta.hardwarerecs.stackexchange.com/a/257/57"&gt;hardware&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;With all of these, I've presented my arguments and logic and strived to remain professional. I believe the community on HardwareRecs has seen that as well.&lt;/p&gt;
&lt;p&gt;As a moderator on &lt;a href="http://communitybuilding.stackexchange.com"&gt;Community Building&lt;/a&gt;, I've been involved in many &lt;a href="http://meta.communitybuilding.stackexchange.com/users/78/andy?tab=summary"&gt;discussions&lt;/a&gt;. I was involved in the discussions to &lt;a href="http://meta.communitybuilding.stackexchange.com/q/175/78"&gt;rename&lt;/a&gt; the community from Moderators.SE to CommunityBuilding.SE. I've been involved in discussions about slow &lt;a href="http://meta.communitybuilding.stackexchange.com/q/151/78"&gt;growth of the community&lt;/a&gt;. I've also presented &lt;a href="http://meta.communitybuilding.stackexchange.com/a/1274/78"&gt;arguments&lt;/a&gt; that go against other moderators, and walked away still feeling like a moderation team. (Go communication!)&lt;/p&gt;
&lt;p&gt;Finally, on OpenSource, I made a &lt;a href="http://meta.opensource.stackexchange.com/q/642/22"&gt;post&lt;/a&gt; about how moderators had implemented a policy to watch the reviewers. It was similar to the long removed "flag weight" option that used to exist. I believe the post was presented in a way that questioned the decisions of the moderators, yet remained professional. &lt;/p&gt;
&lt;p&gt;With all of these meta posts, across the network, I think you can pick up on my moderation style and personality. I like data and I try to present my thoughts in a way that is understandable to all. I'm also willing to speak my mind.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;
&lt;p&gt;This second question I struggled with for a bit. I've had ideas on how Stack Overflow/Stack Exchange could improve, but what did I want to present in this response. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you could add/revise one Stack Overflow policy/guideline, what would you change? Why would you change it, and what would it mean for the community?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My response to this question: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;At the risk of talking myself out of a position, I think more community moderation would help the problem that Stack Overflow has with scaling moderators. There are a couple areas that I think would work well in opening this to the higher reputation users&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Comment flagging: Comments can be removed if enough users flag a comment. If not, a moderator needs to handle the flag. Instead, opening this as a review queue can remove a lot of this burden from the moderators. Users could handle all but the "Other..." flag. There may be guidance needed on the "Obsolete" one due to the difference between "obsolete comment" and "obsolete code block" differences. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Audit Review reviews: On Stack Overflow, we get a decent number of &lt;a href="http://meta.stackoverflow.com/questions/tagged/disputed-review-audits"&gt;disputed audit review&lt;/a&gt; posts on meta. There may be a way to get users with a history of passing both audits and good reviews involved in dealing with these disputed audits. The idea would be to say whether an audit is good or not. &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These changes, and other areas where the community could be leveraged for moderation tasks, helps to remove the burden on moderators. Handling 2,000 (and growing) flags a day means that something needs to change. Moderators are exception handlers. They should be handling the cases that are exceptional - not comments that are no longer relevant. &lt;/p&gt;
&lt;p&gt;For the community, this would be more &lt;a href="http://meta.stackexchange.com/questions/252844/make-comment-flags-less-stupid"&gt;involvement&lt;/a&gt; with the moderation aspect. Users would be able to more quickly clean up a comment thread. Flag it and it appears in the review queue. From here, the moderators don't need to be involved. The downside of this is that it adds another queue for users to be involved with. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="primary-results"&gt;Primary Results&lt;a class="headerlink" href="#primary-results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the primaries over, I ended with &lt;strong&gt;2483&lt;/strong&gt; positive votes. This put me in 11th place. Sadly, this was not enough to get into the election. I was 185 votes shy of over taking 10th. Good luck to the candidates that made it.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Live Vote Counter at the end of the Primary" src="https://andrewwegner.com/images/2015-11-21_22_43_25-SO_2015_Election_Vote_Monitor.png"/&gt;&lt;/p&gt;
&lt;p&gt;One of the tools that came out of this election was a way to &lt;a href="http://meta.stackoverflow.com/q/310694/189134"&gt;visualize&lt;/a&gt; various data points to compare candidates. I provided a &lt;a href="http://meta.stackoverflow.com/a/310736/189134"&gt;couple notes about outliers&lt;/a&gt; various candidates show regarding aspects on the site. I found it interesting to see what each user had "specialized" in. &lt;/p&gt;
&lt;h2 id="election"&gt;Election&lt;a class="headerlink" href="#election" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated December 8, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The election is over and the new moderators have settled in. We've had our first bout of public drama over one of these moderators actually moderating a chat room too. &lt;em&gt;gasp&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I was closer to the top 10 this time, but still missed it. Even more surprising was that the user that ended up in 3rd in the primaries didn't even come close to getting elected. He was eliminated in the 5th round of final STV votes. I still think I'd make a great moderator for Stack Overflow, but I need to figure out the best way to promote myself in the next election.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="moderation"></category></entry><entry><title>How not to recruit me</title><link href="https://andrewwegner.com/how-not-to-recruit-me.html" rel="alternate"></link><published>2015-10-10T14:20:00-05:00</published><updated>2015-10-10T14:20:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-10-10:/how-not-to-recruit-me.html</id><summary type="html">&lt;p&gt;In which I discuss ways not to send me a recruitment message if you are interested in me working for you&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A few days ago, on Meta.StackOverflow, a product manager &lt;a href="http://meta.stackoverflow.com/q/307674/189134"&gt;asked&lt;/a&gt; for feedback on how they could make first contact between employers and potential employees more valuable to the potential employee. I provided my &lt;a href="http://meta.stackoverflow.com/a/307687/189134"&gt;feedback&lt;/a&gt;. I've reposted it below, with some minor changes to further explain my ideals. &lt;/p&gt;
&lt;p&gt;The summary of this entire post is: If I have to spend time to make my resume jump out and catch &lt;em&gt;your&lt;/em&gt; attention, I expect you to spend just a little bit of time telling me about your company and the position you are recruiting for. I don't think a few sentences with these details is that much ask.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="what-i-want-to-see"&gt;What I want to see&lt;a class="headerlink" href="#what-i-want-to-see" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I want to know what the company does and I want to know who you are. I also want to know what positions you are looking to fill and a few details about the position are also important.&lt;/p&gt;
&lt;h2 id="messages-ive-recieved"&gt;Messages I've recieved&lt;a class="headerlink" href="#messages-ive-recieved" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="message-1"&gt;Message 1&lt;a class="headerlink" href="#message-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is the start of a good message:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Message 1" src="https://andrewwegner.com/images/message1.png"/&gt;&lt;/p&gt;
&lt;p&gt;It has the following good elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who the recruiter is&lt;/li&gt;
&lt;li&gt;Position they are recruiting for &lt;/li&gt;
&lt;li&gt;A company name&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It does not offer the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What the company does (other than "build great software").&lt;/li&gt;
&lt;li&gt;Explanation which of my skills or experiences they are interested in. Are you interested in my Python answers on Stack Overflow? My projects on Github? My PHP experience from years ago? This is &lt;em&gt;important&lt;/em&gt; to know. If the company is looking to recruit me for knowledge I shared years ago (ie. PHP in my case), I'd probably be less useful right now because I haven't used PHP in years. I have not kept up with recent changes to the language or various frameworks.&lt;/li&gt;
&lt;li&gt;Explanation of what the position will do, projects I'll be involved in, or challenges they are facing now that I'll help solve.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I did not respond to this position. &lt;/p&gt;
&lt;h3 id="message-2"&gt;Message 2&lt;a class="headerlink" href="#message-2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Message 2" src="https://andrewwegner.com/images/message2.png"/&gt;&lt;/p&gt;
&lt;p&gt;This has the following useful elements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I know your name, position and company. &lt;/li&gt;
&lt;li&gt;Due to who the company was in this particular message, I am even vaguely aware of what the company does. Name recognition helps, but is not very high on my list of &lt;em&gt;"important things"&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What this does not have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A description of the position. "Looking for top talent...to make a significant impact on our systems". Ok. How? What will I be doing?&lt;/li&gt;
&lt;li&gt;How did you find me?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I actually talked to this recruiter and I have to say that I'm both disappointed in the company and myself for not noticing some red flags in this message. This wasn't an interview for a specific position. This was a general recruiting email and I suspect it was sent to multiple users. Flags that I missed in the message:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lack of any details at all and use of buzzwords ("top technical talent", "fast paced", "start-up like", "eCommerce industry").&lt;/li&gt;
&lt;li&gt;Discussion about personal career goals and technical background. Some of my back ground should be obvious from my Careers profile, SO profile and links on both. More importantly, I missed the "personal career goals" flag. The details they wanted were to see if my goals aligned with any open positions they had at the time. &lt;/li&gt;
&lt;li&gt;When the discussion took place, the recruiter knew little more than my name. There were no questions about my careers profile (at the very least) or other projects I mentioned on my profile. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shame on me.&lt;/p&gt;
&lt;h3 id="message-3"&gt;Message 3&lt;a class="headerlink" href="#message-3" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Message 3" src="https://andrewwegner.com/images/message3.png"/&gt;&lt;/p&gt;
&lt;p&gt;This message isn't useful to me at all.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Who is this company and what do they do? &lt;/li&gt;
&lt;li&gt;I have no experience in mobile apps. How did they find me?&lt;/li&gt;
&lt;li&gt;What is Chad's relationship to the company?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I suspect this message showed up because I work for one of their largest clients, live 10 miles from their office and work, literally, right across the street from them. I didn't know that at the time though. I had to ask a co-worker if they'd ever heard of the company. They pointed out their office at lunch.&lt;/p&gt;
&lt;p&gt;I did not respond this this message.&lt;/p&gt;
&lt;h3 id="message-4"&gt;Message 4&lt;a class="headerlink" href="#message-4" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Message 4" src="https://andrewwegner.com/images/message4.png"/&gt;&lt;/p&gt;
&lt;p&gt;This message is worthless. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You are seeking employees who are willing to relocate. Great. Good for you. Are you interested in my skills or just a warm body to keep your chairs warm?&lt;/li&gt;
&lt;li&gt;No details about the company, other than a link to a web site&lt;/li&gt;
&lt;li&gt;No name at all. Who am I talking to? &lt;/li&gt;
&lt;li&gt;No details about the job. I hope they found someone to hold their seats to the floor 8 hours a day. If not, I recommend large rocks. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="summary-of-the-messages"&gt;Summary of the messages&lt;a class="headerlink" href="#summary-of-the-messages" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I need &lt;em&gt;details&lt;/em&gt; and I need details more than what the salary is going to be. Obviously, I need to do some research about your company, if I've never heard of you. But, throw me a bone. Tell me a bit about your self. I had to make a fancy resume to get you to reach out to me. I did something that caught your eye. Now, do something that will catch mine. &lt;/p&gt;
&lt;p&gt;I don't need to work at a company that is the next Google or Apple or start up flush with cash. But, I do want to know about the company before I talk to you. If you can't spend a few seconds explaining a bit about the company, I don't want to talk with you. I don't think a few sentences is that much to offer:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Here at COMPANY NAME, we are looking for a POSITION with skills in LANGUAGE or experience in INDUSTRY. I see you have both and think you'd be able to help TEAM NAME with their on going project of MAKING THE WORLD BETTER. Your PROJECT ON GITHUB looks like you've dealt with aspects of this problem before. We've gotten some press recently about our innovations in this area (check them out HERE)."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;
&lt;h2 id="how-to-get-my-attention"&gt;How to get my attention&lt;a class="headerlink" href="#how-to-get-my-attention" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I think the post above makes it clear what &lt;em&gt;doesn't&lt;/em&gt; work. The companies that I've responded to (other than message 2, above) have all done the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Indicate they've at least looked at my resume by commenting on some aspect of it. I've had recruiters mention projects I've done, jobs I've held, or individual bullet points that caught their attention. This is great. It means you aren't reaching out to me because I happened to hit all of your keywords when the resume passed through your Human Resources department.&lt;/li&gt;
&lt;li&gt;Provide a short description of the job they want to fill. I don't need a full job posting. A link to such a posting is sufficient. However, if you could summarize it in a sentence or two, that'd make both of our lives easier. Reading full job descriptions isn't the most fun thing in the world and often have industry (or even company) specific acronyms. That isn't helpful to either of us, because I may not know them. Just tell me what your team does within the company. That's good enough to get my attention.&lt;/li&gt;
&lt;li&gt;Talk to me like a person, not some number that a database search returned. As a hint, if you can figure out that I like to go by "Andy", instead of "Andrew", you've already done a far better job than most recruiters I've spoken with. &lt;/li&gt;
&lt;/ul&gt;</content><category term="meta"></category><category term="job"></category></entry><entry><title>Link Analysis - Technical Explanation</title><link href="https://andrewwegner.com/link-analysis---technical-explanation.html" rel="alternate"></link><published>2015-08-10T23:41:00-05:00</published><updated>2015-08-10T23:41:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-08-10:/link-analysis---technical-explanation.html</id><summary type="html">&lt;p&gt;In my last two posts, I've discussed the number of rotten links on Stack Overflow and a proposal to fix said links. In this post, I'm going to discuss how I performed this analysis.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In my last two posts, I've discussed the number of &lt;a href="http://andrewwegner.com/analysis-of-links-posted-to-stack-overflow.html"&gt;rotten links&lt;/a&gt; on Stack Overflow and a &lt;a href="http://andrewwegner.com/a-proposal-to-fix-broken-links-on-stack-overflow.html"&gt;proposal to fix said links&lt;/a&gt;. In this post, I'm going to discuss how I performed this analysis. &lt;/p&gt;
&lt;h2 id="set-up"&gt;Set up&lt;a class="headerlink" href="#set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="the-database"&gt;The database&lt;a class="headerlink" href="#the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The process began by downloading the March 2013 &lt;a href="https://archive.org/details/stackexchange"&gt;data dump&lt;/a&gt;. I loaded the &lt;code&gt;posts&lt;/code&gt; into a [MariaDB] instance on my local machine. This was accomplished with a very simple script and patience, as the script took a while to run.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;load xml local infile '/path/to/posts.xml'&lt;/span&gt;
&lt;span class="err"&gt;into table posts&lt;/span&gt;
&lt;span class="err"&gt;rows identified by '&amp;lt;row&amp;gt;';&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="the-data"&gt;The data&lt;a class="headerlink" href="#the-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once this was done, the next step was selecting my random sample of data. I did this by randomly selecting 25% of the days in a year and then pulling all posts for those days across all years of Stack Overflow's existence. The Python script I used to do this was fairly simple:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;randint&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ceil&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;random_date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;total_seconds&lt;/span&gt;&lt;span class="p"&gt;())))&lt;/span&gt;

&lt;span class="n"&gt;percentage&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.25&lt;/span&gt;
&lt;span class="n"&gt;days&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;366&lt;/span&gt;

&lt;span class="n"&gt;dayslist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;days&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;percentage&lt;/span&gt;&lt;span class="p"&gt;))):&lt;/span&gt;
    &lt;span class="n"&gt;dayslist&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_date&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2008&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2008&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At the end of this run, the days that I cared about are in the &lt;code&gt;dayslist&lt;/code&gt; variable. I used that to pull questions and answers from the database that were created on that month/day combination. In the end, this resulted in just over 25% of the total posts being selected. To ensure that I could replicate the results, I also saved the dates that were selected.&lt;/p&gt;
&lt;h2 id="parsing-the-data"&gt;Parsing the data&lt;a class="headerlink" href="#parsing-the-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next step was to parse out links from the data. I used the following script to extract anchor text and links from a post. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def links_in_post(post):
    """
    Returns a list of all links found
    :param posts: A list of dictionaries with a 'body' key containing HTML strings
     [
        {
            'body': "&lt;span class="nt"&gt;&amp;lt;b&amp;gt;&lt;/span&gt;This is HTML&lt;span class="nt"&gt;&amp;lt;/b&amp;gt;&lt;/span&gt;"
        },
    ]
    :return: A list of tuples containing anchor text and URL
        [
            ('Display Text', 'http://example.com')
        ]
    """
    logging.debug("Extracting links...")
    links = []
    images = []
    regexp = "&lt;span class="ni"&gt;&amp;amp;.+?;&lt;/span&gt;"
    list_of_html = re.findall(regexp, post)
    for e in list_of_html:
        if e in invalid_entities:
            h = HTMLParser.HTMLParser()
            unescaped = h.unescape(e) 
            post = post.replace(e, unescaped)

    doc = html.fromstring(post)
    for link in doc.xpath('//a'):
        links.append(Link(text=link.text_content(), link=link.get('href')))
    for image in doc.xpath('//img'):
        images.append(Link(text=image.get('alt'), link=image.get('src')))
    all_items = links + images
    seen = set()
    unique_items = [item for item in all_items if item[1] not in seen and not seen.add(item[1])]
    return unique_items
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The regular expression being utilized, is to strip out HTML entities. This was needed due to weird parsing issues with non-ASCII characters. Fortunately, I wasn't the &lt;a href="http://stackoverflow.com/a/13939198/189134"&gt;first to encounter oddities like this&lt;/a&gt;. The list comprehension at the end of the function is returning only unique tuples of anchor text/link. I was surprised how often I'd end up with tuples such as &lt;code&gt;('this', 'http://google.com')&lt;/code&gt; in the same post. This uniqueness saved a lot of processing time later.&lt;/p&gt;
&lt;p&gt;After all links in a post had been extracted, this information and information about the post itself, was saved to the database. If a post had no links, it was not saved. The database consisted of three tables. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Links - This table contains the base URLs seen in all posts. URLs are distinct. It also contains an ID that will be utilized for linking to the other tables.&lt;/li&gt;
&lt;li&gt;Post Links - This table contains information about links in a post. This includes the specific anchor text/link combinations&lt;/li&gt;
&lt;li&gt;Link Results - This table contains the results of link status checks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Processing the posts was fairly time consuming, but was able to be parallelized easily. That significantly cut down on processing time.&lt;/p&gt;
&lt;h2 id="checking-the-links"&gt;Checking the links&lt;a class="headerlink" href="#checking-the-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The most time consuming portion of this entire project was actually checking link status. Each link that appeared in the &lt;code&gt;Links&lt;/code&gt; table was checked. As I mentioned in my first post, the original idea was to simply send a &lt;code&gt;HEAD&lt;/code&gt; request to each URL. The idea was to save myself and the end point a tiny amount of bandwidth. I had over a million links to process. I figured a little saved bandwidth wouldn't hurt.&lt;/p&gt;
&lt;p&gt;I turns out this isn't a good idea. When I started seeing larger sites as not being accessible, I go suspicious that something was wrong. These sites were returning status 405 errors. This indicates that the method is not allowed. So, I switched to &lt;code&gt;GET&lt;/code&gt; for every link. The next problem I ran into was that many sites didn't like the default user agent of the spider. They rejected requests with 404 and 401 errors. In the end, I got around this by mimicking Firefox on every request. &lt;/p&gt;
&lt;p&gt;With those kinks worked out, every link was sent a &lt;code&gt;GET&lt;/code&gt; request that looked to be from a Firefox browser. The process would allow 20 seconds per link. If the link didn't respond in that time limit, it was declared inaccessible. &lt;/p&gt;
&lt;p&gt;A week later, I repeated the process with anything that hadn't returned a status code less than 400. Once more, on the third week, I repeated this with the failed links. At the end of three weeks, I had a list of sites that were inaccessible to me - on a residential connection - three times over a period of three weeks.&lt;/p&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://andrewwegner.com/images/status_codes.svg"&gt;SVG image&lt;/a&gt; that I created for the write up was generated with Pygal. The tables were the result of various break downs of the data via queries to the status results. &lt;/p&gt;
&lt;h2 id="wrap-up"&gt;Wrap up&lt;a class="headerlink" href="#wrap-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I am rather proud of how the results turned out for this project. I went into it expecting about 15% of links to be broken, but I didn't really realize what the meant. Fifteen percent of 21 million total posts is over 3 million. That's a large number. BUT, it also ignored that a large percentage of posts don't contain links. I failed to consider that in my original hypothesis. &lt;/p&gt;
&lt;p&gt;Less than half of my sample had links (2.3M out of 5.6M). Of the 2.3M with links, only 1.5M were unique links. The final result of 10% failed links makes much more sense in this context. Ten percent of 1.5M links means that there are 150K links that are bad. &lt;/p&gt;</content><category term="Stack Exchange"></category><category term="programming"></category></entry><entry><title>A proposal to fix broken links on Stack Overflow</title><link href="https://andrewwegner.com/a-proposal-to-fix-broken-links-on-stack-overflow.html" rel="alternate"></link><published>2015-08-07T07:34:00-05:00</published><updated>2015-08-07T07:34:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-08-07:/a-proposal-to-fix-broken-links-on-stack-overflow.html</id><summary type="html">&lt;p&gt;My proposal to decrease the number of broken links on Stack Overflow&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This post was &lt;a href="http://meta.stackoverflow.com/q/300916/189134"&gt;published&lt;/a&gt; by &lt;a href="http://meta.stackoverflow.com/users/189134/andy?tab=profile"&gt;me&lt;/a&gt; on Meta Stack Overflow on August 7th, 2015. I've republished it here
so that I can easily update information related to recent developments. If you have questions or comments, I highly
encourage you to visit the &lt;a href="http://meta.stackoverflow.com/q/300916/189134"&gt;question&lt;/a&gt; on Meta Stack Overflow and post there.&lt;/p&gt;
&lt;p&gt;This is a follow up to &lt;a href="https://andrewwegner.com/analysis-of-links-posted-to-stack-overflow.html"&gt;yesterday's post&lt;/a&gt; about how many links on Stack Overflow are starting to rot.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="the-proposal"&gt;The proposal&lt;a class="headerlink" href="#the-proposal" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I propose &lt;a href="http://meta.stackoverflow.com/a/301002/189134"&gt;another hybrid&lt;/a&gt; of the previous &lt;a href="http://meta.stackexchange.com/questions/224895/what-happened-to-the-broken-link-review-queue"&gt;broken link&lt;/a&gt; queue (as was mentioned &lt;a href="http://meta.stackoverflow.com/questions/300916/i-estimate-10-of-the-links-posted-here-are-dead-how-do-we-deal-with-them#comment229798_300916"&gt;above&lt;/a&gt; in &lt;a href="http://meta.stackoverflow.com/questions/300916/i-estimate-10-of-the-links-posted-here-are-dead-how-do-we-deal-with-them#comment229795_300916"&gt;comments&lt;/a&gt; and &lt;a href="http://meta.stackoverflow.com/a/300998/189134"&gt;other&lt;/a&gt; &lt;a href="http://meta.stackoverflow.com/a/300996/189134"&gt;answers&lt;/a&gt;) and an automated process to fix broken links with an archived version (which has also been &lt;a href="http://meta.stackoverflow.com/a/301001/189134"&gt;suggested&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The broken link queue should focus on editing and fixing the links in a post (as opposed to closing it). It'd be similar to the suggested edits queue, but with the focus intended to correct &lt;em&gt;links&lt;/em&gt; not spelling and grammar. This could be done by only allowing a user to edit the links.&lt;/p&gt;
&lt;p&gt;One possibility, I envision is presenting the user with the links in the post and a status on whether or not the link is available. If it's not available, give the user a way to change that specific link. Utilizing &lt;a href="http://stackoverflow.com/a/2054063/189134"&gt;this&lt;/a&gt; post, I have a quick mock up of what I propose such a review task looks like:&lt;/p&gt;
&lt;h2 id="the-queue"&gt;The Queue&lt;a class="headerlink" href="#the-queue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/brokenlinkqueue.png"&gt;&lt;img alt="Broken Link Mock up" src="https://andrewwegner.com/images/brokenlinkqueue.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All the links that appear in the post are on the right hand side of the screen. The links that are accessible have a green check mark. The ones that are broken (and the reason for being in this queue) have a red X. When a user elects to fix a post, they are presented with a modal showing only the broken URLs.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="the-automation"&gt;The Automation&lt;a class="headerlink" href="#the-automation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this queue, though, I think an automated process would be helpful as well. The idea is that this would operate similarly to the Low Quality queue, where the system can automatically add a post to the queue if certain criteria are met &lt;em&gt;or&lt;/em&gt; a user can flag a post as having broken links. I've based my idea on what Tim Post outlined in the &lt;a href="http://meta.stackexchange.com/questions/130398/does-stack-exchange-crawl-websites/198357#comment741544_198357"&gt;comments to a previous post&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automated process performs a "Today in History" type check. This keeps the fixes limited to a small subset of posts per day. It also focuses on older posts, which were more likely to have a broken link than something posted recently. Example: On July 31, 2015, the only posts being checked for bad links would be anything posted on July 31 in any year 2008 through current year - 1.&lt;/li&gt;
&lt;li&gt;Utilizing the &lt;a href="http://archive.org/about/wayback_api.php"&gt;Wayback Machine API&lt;/a&gt;, or similar service, the system attempts to change broken links into an archived version of the URL. This archived version should probably be from "close" to the time the post was originally made. If the automated process isn't able to find an archived version of the link, the post should be tossed into the Broken Link queue&lt;/li&gt;
&lt;li&gt;When the Community edits a post to fix a link, a new Post History event is utilized to show that a link was changed. This would allow anyone looking at revision history to easily see that a specific change was only to fix links.&lt;/li&gt;
&lt;li&gt;Actions performed in the previous bullets are exposed to 10K users in the moderator tools. Much like recent close/delete posts show up, these do as well. This allows higher rep users to spot check (if they so desire). I think this portion is important when the automated process fixes a link. For community edits in the queue, the history tab in &lt;code&gt;/review&lt;/code&gt; seems sufficient.&lt;/li&gt;
&lt;li&gt;If a post consists of a large percentage of a link (or links) and these links were changed by Community, the post should have further action taken on it in some queue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example:
     - A post where X+% of the text is hyperlinks is very dependent on the links being active. If one or more of the links are broken, the post may no longer be relevant (or may be a link only post). One example I found while doing this was &lt;a href="http://stackoverflow.com/posts/4906230/revisions"&gt;this&lt;/a&gt; answer.&lt;/p&gt;
&lt;p&gt;I don't think that this type of edit from the Community user should bump a post to the front page. Edits done in the broken link queue, though, &lt;em&gt;should&lt;/em&gt; bump the post just like a suggested edit does today. By preventing the automated Community posts from being bumped, we prevent the the front page from being flooded, daily, with old posts and these edits. I think that the exposure in the 10K tools and the broken link queue will provide the visibility needed to check the process is working correctly. &lt;/p&gt;
&lt;h2 id="process-flows"&gt;Process flows&lt;a class="headerlink" href="#process-flows" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Queue Flow:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/brokenqueueflow.png"&gt;&lt;img alt="Queue Flow" src="https://andrewwegner.com/images/brokenqueueflow.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Automated process flow:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/automatedlinkflow.png"&gt;&lt;img alt="Automated Link check flow" src="https://andrewwegner.com/images/automatedlinkflow.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="potential-pitfalls"&gt;Potential pitfalls&lt;a class="headerlink" href="#potential-pitfalls" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The automated link checking will likely run into several of the problems I did. Mainly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sites modify the &lt;code&gt;HEAD&lt;/code&gt; request to send a 404 instead of a 405. My solution to this was to issue &lt;code&gt;GET&lt;/code&gt; requests for everything.&lt;/li&gt;
&lt;li&gt;Sites don't like certain user agents. My solution to this was to mimic the Firefox user agent. To be a good internet citizen, Stack Exchange probably shouldn't go that far, but providing a unique user agent that is easily identifiable as "StackExchangeBot" (think "GoogleBot"), should be helpful in identifying where traffic is coming from.&lt;/li&gt;
&lt;li&gt;Sites that are down one week and up another. I solved this by spreading my tests over a period of 3 weeks. With the queue and automatic linking to an archived version of the site, this may not be necessary. However, immediately converting a link to an archived copy should be discussed by the community. Do we convert the broken link immediately? Or do we try again in X days. If it's still down then convert it? It was suggested in &lt;a href="http://meta.stackoverflow.com/a/301002/189134"&gt;another answer&lt;/a&gt; that we first offer the poster the chance to make changes before an automatic process takes place.&lt;/li&gt;
&lt;li&gt;The need to throttle requests so that you don't flood a site with requests. I solved this by only querying unique URLs. This still issues a lot of requests to certain, popular, domains. This could be solved by staggering the checks over a period of minutes/hours versus spewing 100s - 1000s of &lt;code&gt;GET&lt;/code&gt; requests at midnight daily.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With the broken link queue, I feel the first two would be acceptable. Much like posts in the Low Quality queue appear because of a heuristic, despite not being low quality, links will be the same way. The system will flag them as broken and the queue will determine if that is true (if an archived version of the site can't be found by the automated process). The bullet about throttling requests is an implementation detail that I'm sure the developers would be able to figure out.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="programming"></category></entry><entry><title>Analysis of links posted to Stack Overflow</title><link href="https://andrewwegner.com/analysis-of-links-posted-to-stack-overflow.html" rel="alternate"></link><published>2015-08-06T07:35:00-05:00</published><updated>2015-08-07T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-08-06:/analysis-of-links-posted-to-stack-overflow.html</id><summary type="html">&lt;p&gt;Approximately 10% of 1.5M randomly selected unique links in the Stack Overflow March 2015 data dump are unavailable. This is an analysis of how that was determined and a request for discussion on how to improve it&lt;/p&gt;</summary><content type="html">
&lt;p&gt;This post was &lt;a href="http://meta.stackoverflow.com/q/300916/189134"&gt;published&lt;/a&gt; by &lt;a href="http://meta.stackoverflow.com/users/189134/andy?tab=profile"&gt;me&lt;/a&gt; on Meta Stack Overflow on August 6th, 2015. I've republished it here
so that I can easily update information related to recent developments. If you have questions or comments, I highly
encourage you to visit the &lt;a href="http://meta.stackoverflow.com/q/300916/189134"&gt;question&lt;/a&gt; on Meta Stack Overflow and post there. &lt;/p&gt;
&lt;p&gt;TL;DR: Approximately 10% of 1.5M randomly selected unique links in the March 2015 &lt;a href="https://archive.org/details/stackexchange"&gt;data dump&lt;/a&gt; are unavailable. To be more precise, that is approximately 150K dead links.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been running into more and more links that are dead on Stack Overflow and it's bothering me. In some cases, I've spent the time hunting down a replacement, in others I've notified the owner of the post that a link is dead, and (more shamefully), in others I've simply ignored it and left just a &lt;a href="http://meta.stackoverflow.com/a/262040/189134"&gt;down vote&lt;/a&gt;. Obviously that's not good.&lt;/p&gt;
&lt;p&gt;Before making sweeping generalizations that there are dead links everywhere, though, I wanted to make sure I wasn't just finding bad posts because I was wandering through the review queues. Utilizing the March 2015 data dump, I randomly selected about 25% of the posts (both questions and answers) and then parsed out the links. This works out to 5.6M posts out of 21.7M total.&lt;/p&gt;
&lt;p&gt;Of these 5.6M posts, 2.3M contained links and 1.5M of these were unique links. I sent each unique URL a &lt;a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods"&gt;&lt;code&gt;HEAD&lt;/code&gt;&lt;/a&gt; request, with a user agent mimicking Firefox&lt;sup&gt;1&lt;/sup&gt;. I then retested everything that didn't return a successful response a week later. Finally, anything that failed from &lt;em&gt;that&lt;/em&gt; batch, I resent a final test a week later. If a site was down in all three tests, I considered it down for this test.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="results2"&gt;Results&lt;sup&gt;2&lt;/sup&gt;&lt;a class="headerlink" href="#results2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="by-status-code"&gt;By status code&lt;a class="headerlink" href="#by-status-code" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Good news/Bad News: A majority of the links returned a valid response, but there are still roughly 10% that failed.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/status_codes.svg"&gt;&lt;img alt="PIE CHART IMAGE" src="https://andrewwegner.com/images/status_codes.svg"/&gt;&lt;/a&gt;
&lt;em&gt;(This image is showing the top status codes returned)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The three largest slices of the pie are the status 200s (site working!), status 404 (page not found, but server responded saying the page isn't found) and Connection Errors. Connection errors are sites that had no proper server response. The request to access the page timed out. I was generous in the time out and allowed a request to live for 20 seconds before failing a link with this status. The &lt;code&gt;4xx&lt;/code&gt; and &lt;code&gt;5xx&lt;/code&gt; errors are status codes that fall in the 400 and 500 range of HTTP responses. These are client and server error ranges, thus counted as a failure. &lt;code&gt;2xx&lt;/code&gt; errors (of which was are in the low triple) are pages that responded with a success message in the 200 range, but it wasn't a &lt;code&gt;200&lt;/code&gt; code. Finally, there were just over a hundred sites that hit a redirect loop that didn't seem to end. These are the &lt;code&gt;3xx&lt;/code&gt; errors. I failed a site with this range if it redirected more than 30 times. There are a negligible number of sites that returned status codes in the 600 and &lt;a href="https://github.com/joho/7XX-rfc"&gt;700&lt;/a&gt; range&lt;sup&gt;4&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id="by-most-common"&gt;By most common&lt;a class="headerlink" href="#by-most-common" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are, expectedly, many URLs that failed that appeared frequently in the sample set. Below is a list of the top 50&lt;sup&gt;3&lt;/sup&gt; URLs that are in posts most often, but failed three times over the course of three weeks.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;http://docs.jquery.com/Plugins/validation&lt;/span&gt;
&lt;span class="c"&gt;http://www.eclipse.org/eclipselink/moxy.php&lt;/span&gt;
&lt;span class="c"&gt;http://jackson.codehaus.org/&lt;/span&gt;
&lt;span class="c"&gt;http://xstream.codehaus.org/&lt;/span&gt;
&lt;span class="c"&gt;http://opencv.willowgarage.com/wiki/&lt;/span&gt;
&lt;span class="c"&gt;http://developer.android.com/resources/articles/painless-threading.html&lt;/span&gt;
&lt;span class="c"&gt;http://valums.com/ajax-upload/&lt;/span&gt;
&lt;span class="c"&gt;http://sqlite.phxsoftware.com/&lt;/span&gt;
&lt;span class="c"&gt;http://qt.nokia.com/&lt;/span&gt;
&lt;span class="c"&gt;http://www.oracle.com/technetwork/java/codeconv-138413.html&lt;/span&gt;
&lt;span class="c"&gt;http://download.java.net/jdk8/docs/api/java/time/package-summary.html&lt;/span&gt;
&lt;span class="c"&gt;http://docs.oracle.com/javase/1.4.2/docs/api/java/text/SimpleDateFormat.html&lt;/span&gt;
&lt;span class="c"&gt;http://watin.sourceforge.net/&lt;/span&gt;
&lt;span class="c"&gt;http://leandrovieira.com/projects/jquery/lightbox/&lt;/span&gt;
&lt;span class="c"&gt;https://graph.facebook.com/&lt;/span&gt;
&lt;span class="c"&gt;https://ccrma.stanford.edu/courses/422/projects/WaveFormat/&lt;/span&gt;
&lt;span class="c"&gt;http://www.postsharp.org/&lt;/span&gt;
&lt;span class="c"&gt;http://www.erichynds.com/jquery/jquery-ui-multiselect-widget/&lt;/span&gt;
&lt;span class="c"&gt;http://ha.ckers.org/xss.html&lt;/span&gt;
&lt;span class="c"&gt;http://jetty.codehaus.org/jetty/&lt;/span&gt;
&lt;span class="c"&gt;http://cpp-next.com/archive/2009/08/want-speed-pass-by-value/&lt;/span&gt;
&lt;span class="c"&gt;http://codespeak.net/lxml/&lt;/span&gt;
&lt;span class="c"&gt;http://www.hpl.hp.com/personal/Hans_Boehm/gc/&lt;/span&gt;
&lt;span class="c"&gt;http://jquery.com/demo/thickbox/&lt;/span&gt;
&lt;span class="c"&gt;http://book.git-scm.com/5_submodules.html&lt;/span&gt;
&lt;span class="c"&gt;http://monotouch.net/&lt;/span&gt;
&lt;span class="c"&gt;http://developer.android.com/resources/articles/timed-ui-updates.html&lt;/span&gt;
&lt;span class="c"&gt;http://jquery.bassistance.de/validate/demo/&lt;/span&gt;
&lt;span class="c"&gt;http://codeigniter.com/user_guide/database/active_record.html&lt;/span&gt;
&lt;span class="c"&gt;http://www.phantomjs.org/&lt;/span&gt;
&lt;span class="c"&gt;http://watin.org/&lt;/span&gt;
&lt;span class="c"&gt;http://www.db4o.com/&lt;/span&gt;
&lt;span class="c"&gt;http://qt.nokia.com/products/&lt;/span&gt;
&lt;span class="c"&gt;http://referencesource.microsoft.com/netframework.aspx&lt;/span&gt;
&lt;span class="c"&gt;https://github.com/facebook/php-sdk/&lt;/span&gt;
&lt;span class="c"&gt;http://java.decompiler.free.fr/&lt;/span&gt;
&lt;span class="c"&gt;http://pivotal.github.com/jasmine/&lt;/span&gt;
&lt;span class="c"&gt;http://api.jquery.com/category/plugins/templates/&lt;/span&gt;
&lt;span class="c"&gt;http://code.google.com/closure/library&lt;/span&gt;
&lt;span class="c"&gt;http://www.w3schools.com/tags/ref_entities.asp&lt;/span&gt;
&lt;span class="c"&gt;http://xstream.codehaus.org/tutorial.html&lt;/span&gt;
&lt;span class="c"&gt;https://github.com/facebook/php-sdk&lt;/span&gt;
&lt;span class="c"&gt;http://download.java.net/maven/1/jstl/jars/jstl-1.2.jar&lt;/span&gt;
&lt;span class="c"&gt;https://developers.facebook.com/docs/offline-access-deprecation/&lt;/span&gt;
&lt;span class="c"&gt;http://www.parashift.com/c++-faq-lite/pointers-to-members.html&lt;/span&gt;
&lt;span class="c"&gt;https://developers.facebook.com/docs/mobile/ios/build/&lt;/span&gt;
&lt;span class="c"&gt;http://downloads.php.net/pierre/&lt;/span&gt;
&lt;span class="c"&gt;http://fluentnhibernate.org/&lt;/span&gt;
&lt;span class="c"&gt;http://net.tutsplus.com/tutorials/javascript-ajax/5-ways-to-make-ajax-calls-with-jquery/&lt;/span&gt;
&lt;span class="c"&gt;http://dev.iceburg.net/jquery/jqModal/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="by-post-score"&gt;By post score&lt;a class="headerlink" href="#by-post-score" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Count of posts by score (top 10)  (Covers 94% of all broken links):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;| Score | Percentage of Total Broken |&lt;/span&gt;
&lt;span class="err"&gt;|-------|----------------------------|&lt;/span&gt;
&lt;span class="err"&gt;| 0     | 36.4087%                   |&lt;/span&gt;
&lt;span class="err"&gt;| 1     | 25.1674%                   |&lt;/span&gt;
&lt;span class="err"&gt;| 2     | 13.4089%                   |&lt;/span&gt;
&lt;span class="err"&gt;| 3     | 7.2806%                    | &lt;/span&gt;
&lt;span class="err"&gt;| 4     | 4.2971%                    |&lt;/span&gt;
&lt;span class="err"&gt;| 5     | 2.7065%                    |&lt;/span&gt;
&lt;span class="err"&gt;| 6     | 1.8068%                    |&lt;/span&gt;
&lt;span class="err"&gt;| 7     | 1.2854%                    |&lt;/span&gt;
&lt;span class="err"&gt;| -1    | 1.1935%                    |&lt;/span&gt;
&lt;span class="err"&gt;| 8     | 0.9415%                    |&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="by-number-of-views"&gt;By number of views&lt;a class="headerlink" href="#by-number-of-views" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Note, this is number of views at the time the data dump was created, not as of today&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Count of posts by number of views (top 10):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;| Views        | Total Views |&lt;/span&gt;
&lt;span class="err"&gt;|--------------|-------------|&lt;/span&gt;
&lt;span class="err"&gt;| (0, 200]     | 24.4709%    |&lt;/span&gt;
&lt;span class="err"&gt;| (200, 400]   | 14.2186%    |&lt;/span&gt;
&lt;span class="err"&gt;| (400, 600]   | 9.5045%     |&lt;/span&gt;
&lt;span class="err"&gt;| (600, 800]   | 6.9793%     | &lt;/span&gt;
&lt;span class="err"&gt;| (800, 1000]  | 5.2574%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1000, 1200] | 4.1864%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1200, 1400] | 3.3699%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1400, 1600] | 2.7766%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1600, 1800] | 2.3477%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1800, 2000] | 1.9550%     |&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="by-days-since-post-created"&gt;By days since post created&lt;a class="headerlink" href="#by-days-since-post-created" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Note: This is number of days since creation at the time the data dump was created, not from today&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Count of posts by days since creation (top 10) (Covers 64% of broken links):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;| Days since Creation | Percentage of Total Broken |&lt;/span&gt;
&lt;span class="err"&gt;|---------------------|----------------------------|&lt;/span&gt;
&lt;span class="err"&gt;| (1110, 1140]        | 7.2938%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (1140, 1170]        | 6.7648%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (1470, 1500]        | 6.6579%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (1080, 1110]        | 6.6535%                    | &lt;/span&gt;
&lt;span class="err"&gt;| (750, 780]          | 6.5535%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (720, 750]          | 6.5516%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (1500, 1530]        | 6.3978%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (390, 420]          | 5.8508%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (360, 390]          | 5.8258%                    |&lt;/span&gt;
&lt;span class="err"&gt;| (780, 810]          | 5.5175%                    |&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="by-ratio-of-viewsdays"&gt;By Ratio of Views:Days&lt;a class="headerlink" href="#by-ratio-of-viewsdays" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Ratio Views:Days (top 20) (Covers 90% of broken links):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;| Views:Days Ratio | Percentage of Total Broken |&lt;/span&gt;
&lt;span class="err"&gt;|------------------|-------------|&lt;/span&gt;
&lt;span class="err"&gt;| (0, 0.25]        | 27.2369%    |&lt;/span&gt;
&lt;span class="err"&gt;| (0.25, 0.5]      | 18.8496%    |&lt;/span&gt;
&lt;span class="err"&gt;| (0.5, 0.75]      | 11.4321%    |&lt;/span&gt;
&lt;span class="err"&gt;| (0.75, 1]        | 7.2481%     | &lt;/span&gt;
&lt;span class="err"&gt;| (1, 1.25]        | 5.1668%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1.25, 1.5]      | 3.7907%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1.5, 1.75]      | 2.9310%     |&lt;/span&gt;
&lt;span class="err"&gt;| (1.75, 2]        | 2.4033%     |&lt;/span&gt;
&lt;span class="err"&gt;| (2, 2.25]        | 1.9788%     |&lt;/span&gt;
&lt;span class="err"&gt;| (2.25, 2.5]      | 1.6850%     |&lt;/span&gt;
&lt;span class="err"&gt;| (2.5, 2.75]      | 1.4080%     |&lt;/span&gt;
&lt;span class="err"&gt;| (2.75, 3]        | 1.1879%     |&lt;/span&gt;
&lt;span class="err"&gt;| (3, 3.25]        | 1.0654%     |&lt;/span&gt;
&lt;span class="err"&gt;| (3.25, 3.5]      | 0.9391%     |&lt;/span&gt;
&lt;span class="err"&gt;| (3.5, 3.75]      | 0.8334%     |&lt;/span&gt;
&lt;span class="err"&gt;| (3.75, 4]        | 0.7165%     |&lt;/span&gt;
&lt;span class="err"&gt;| (4, 4.25]        | 0.6634%     |&lt;/span&gt;
&lt;span class="err"&gt;| (4.25, 4.5]      | 0.5789%     |&lt;/span&gt;
&lt;span class="err"&gt;| (4.5, 4.75]      | 0.5508%     |&lt;/span&gt;
&lt;span class="err"&gt;| (4.75, 5]        | 0.4833%     |&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;h2 id="discussion"&gt;Discussion&lt;a class="headerlink" href="#discussion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;What can we do with all of this? How do we, as a community, solve the issue of 10% of our outbound links pointing to places on the internet that no longer exist? Assuming that my sample was indicative of the entire data dump, there are close to 600K (150K broken unique links x 4, because I took 1/4 of the data dump as a sample) broken links posted in questions and answers on Stack Overflow. I assume a large number of links posted in comments would be broken as well, but that's an activity for another month.&lt;/p&gt;
&lt;p&gt;We encourage posters to provide snippets from their links just in case a link dies. That definitely helps, but the resources behind the links and the (presumably) expanded explanation behind the links are still gone. How can we properly deal with this? &lt;/p&gt;
&lt;p&gt;It looks like there have been a few previous discussions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://meta.stackexchange.com/a/198357/186281"&gt;Utilize the Wayback API to automatically fix broken links.&lt;/a&gt; Development appeared to stall on this due to the large number of edits the Community user would be making. This would also hide posts that depended on said link from being surfaced for the community to fix it.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://meta.stackexchange.com/questions/224895/what-happened-to-the-broken-link-review-queue"&gt;Link review queue&lt;/a&gt;. It was in &lt;a href="http://meta.stackexchange.com/questions/212023/where-can-i-access-the-link-validation-review-queue"&gt;alpha&lt;/a&gt;, but disappeared in early 2014. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://meta.stackexchange.com/questions/174347/badge-request-for-fixing-dead-links-pipefitter"&gt;Badge proposal for fixing broken links&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id="footnotes"&gt;Footnotes&lt;a class="headerlink" href="#footnotes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;This is how it ultimately played out. Originally I sent &lt;code&gt;HEAD&lt;/code&gt; requests, in an effort to save bandwidth. This turned out to waste a whole bunch of time because there are a whole bunch of sites around the internet that return a &lt;a href="https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#4xx_Client_Error"&gt;&lt;code&gt;405 Method Not Allowed&lt;/code&gt;&lt;/a&gt; when sending a &lt;code&gt;HEAD&lt;/code&gt; request. The next step was to sent &lt;code&gt;GET&lt;/code&gt; requests, but utilize the default Python &lt;a href="http://docs.python-requests.org/en/latest/"&gt;requests&lt;/a&gt; user-agent. A lot of sites were returning &lt;code&gt;401&lt;/code&gt; or &lt;code&gt;404&lt;/code&gt; responses to this user agent. &lt;/li&gt;
&lt;li&gt;Links to Stack Exchange sites were not counted in the above results. The failures seen are almost 100% due to a question/answer/comment being deleted. The process ran as an anonymous user, thus didn't have any reputation and was served a 404. A user with appropriate permissions &lt;em&gt;can&lt;/em&gt; still visit the link. I verified a number of 404'd links to Stack Overflow posts and this was the case.&lt;/li&gt;
&lt;li&gt;The 4th most common failure was to &lt;code&gt;localhost&lt;/code&gt;. The 16th and 17th most common were &lt;code&gt;localhost&lt;/code&gt; on ports other than 80. I removed these from the result table with the knowledge that these shouldn't be accessible from the internet.&lt;/li&gt;
&lt;li&gt;There where 7 total URLs that returned status codes in the &lt;code&gt;600&lt;/code&gt; and &lt;a href="https://github.com/joho/7XX-rfc"&gt;&lt;code&gt;700&lt;/code&gt;&lt;/a&gt; range. One such site was &lt;a href="http://learn.code.org/hoc/1"&gt;code.org&lt;/a&gt; with a status code of 752. Sadly, this is not even defined the joke RFC. &lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="follow-up"&gt;Follow up&lt;a class="headerlink" href="#follow-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I &lt;a href="https://andrewwegner.com/a-proposal-to-fix-broken-links-on-stack-overflow.html"&gt;posted&lt;/a&gt; a proposal on how I think this could be fixed.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="programming"></category></entry><entry><title>How I set up this site with GitHub Pages and CloudFlare</title><link href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html" rel="alternate"></link><published>2015-07-09T11:26:00-05:00</published><updated>2015-07-09T11:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-07-09:/how-i-set-up-this-site-with-github-pages-and-cloudflare.html</id><summary type="html">&lt;p&gt;This post provides a brief description of how I set up the web site to utilize GitHub Pages and CloudFlare and eliminated my self hosting&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In a &lt;a href="https://andrewwegner.com/why-i-moved-from-wordpress-to-pelican.html"&gt;previous post&lt;/a&gt;, I described why I moved from Wordpress to Pelican for my blog. This one goes a step further and describes how I eliminated the
need for the dedicated server I'd been utilizing as a part of &lt;a href="https://andrewwegner.com/thanks-for-all-the-fish.html"&gt;Team Vipers&lt;/a&gt;. By eliminating that server, I reduced my costs to zero but kept control
over the DNS of my domain (thanks to &lt;a href="https://www.cloudflare.com/"&gt;CloudFlare&lt;/a&gt;) and had an easier method of updating the site using &lt;a href="https://pages.github.com/"&gt;GitHub Pages&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="github-pages-setup"&gt;GitHub Pages Setup&lt;a class="headerlink" href="#github-pages-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;To utilize GitHub Pages, I needed to create a new &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io"&gt;repository&lt;/a&gt; that followed the format &lt;code&gt;GitHubUsername.github.io&lt;/code&gt;. This repository would house the
content that is this site. I also set up a second &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source"&gt;repository&lt;/a&gt; which contains the source for the blog. This repository includes the templates, plugins
and markdown version of the pages. The first repository was set up as submodule.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;git submodule add https://github.com/AWegnerGitHub/awegnergithub.github.io.git output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I ignored the &lt;code&gt;output&lt;/code&gt; directory in &lt;code&gt;.gitignore&lt;/code&gt; on the source repository. Finally, I had to adjust &lt;code&gt;publishconf.py&lt;/code&gt; slightly to  &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;DELETE_OUTPUT_DIRECTORY = False&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Without this, I was constantly destroying the output repository and had to reinitialize it. This prevents that from occuring.&lt;/p&gt;
&lt;p&gt;Now, a new post consists of writing up the &lt;a href="https://raw.githubusercontent.com/AWegnerGitHub/awegnergithub.github.io-source/master/content/2015_07_09_how-i-set-up-this-site-with-github-pages-and-cloudflare.md"&gt;Markdown page&lt;/a&gt;, generating the page with the command below (or the &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source/blob/master/generate_content_production.bat"&gt;batch script&lt;/a&gt;) and then committing and
pushing the changes to the submodule to GitHub.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;# Generates HTML files without debugging information&lt;/span&gt;
&lt;span class="err"&gt;pelican content --output output --settings publishconf.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The new content is available immediately.&lt;/p&gt;
&lt;h3 id="custom-domain"&gt;Custom Domain&lt;a class="headerlink" href="#custom-domain" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You may notice that the URL for this site isn't &lt;code&gt;awegnergithub.github.io&lt;/code&gt;, but instead &lt;code&gt;andrewwegner.com&lt;/code&gt;. To accomplish this, I added a directory to the &lt;code&gt;content&lt;/code&gt;
named &lt;code&gt;extra&lt;/code&gt;. In this directory is a single file named &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source/blob/master/content/extra/CNAME"&gt;&lt;code&gt;CNAME&lt;/code&gt;&lt;/a&gt; (no extension). In the file is my domain name.&lt;/p&gt;
&lt;p&gt;Next, I had to modify &lt;a href="https://github.com/AWegnerGitHub/awegnergithub.github.io-source/blob/master/pelicanconf.py"&gt;&lt;code&gt;pelicanconf.py&lt;/code&gt;&lt;/a&gt; to add the &lt;code&gt;extra/CNAME&lt;/code&gt; to the static path and then on generation move the &lt;code&gt;CNAME&lt;/code&gt; file from this subdirectory to the root.
I could have put it in the root of &lt;code&gt;content&lt;/code&gt; by default, but Pelican provides a way to do this and it keeps &lt;code&gt;content&lt;/code&gt; clean. &lt;strong&gt;One very important note&lt;/strong&gt;, the &lt;code&gt;EXTRA_PATH_METADATA&lt;/code&gt; is
operating system sensitive. Since I am generating the content on a Windows machine, I had to use a backslash instead of the forward slash the documentation shows. I found this
after posing a &lt;a href="http://stackoverflow.com/a/30512242/189134"&gt;question&lt;/a&gt; on Stack Overflow on why it wasn't working as the documentation suggested.&lt;/p&gt;
&lt;p&gt;The two important fields to add or edit are:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;...&lt;/span&gt;
&lt;span class="err"&gt;STATIC_PATHS = ['images', 'extra/CNAME']&lt;/span&gt;
&lt;span class="err"&gt;...&lt;/span&gt;
&lt;span class="err"&gt;EXTRA_PATH_METADATA = {'extra\CNAME': {'path': 'CNAME'},}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="cloudflare-setup"&gt;Cloudflare Setup&lt;a class="headerlink" href="#cloudflare-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The final thing I needed in order to get rid of my server was control over DNS. I could revert back to GoDaddy, but after a little research found that CloudFlare's additional CDN and
security was a "good thing" (because, you know, I'm such a highly traffic'd blog these days). Step one was signing up to CloudFlare. This was a 3-5 minute thing.&lt;/p&gt;
&lt;p&gt;Once signed up and signed in, I went to set up DNS. This was as simple as adding my domain name and waiting for CloudFlare to import my existing DNS records. With this, I kept by Google Apps
email intact (which is what I was most concerned with). Next, I went and removed the &lt;code&gt;A&lt;/code&gt; records. I replaced these with &lt;code&gt;CNAME&lt;/code&gt; records pointing to my GitHub Pages URL. I also added a &lt;code&gt;www&lt;/code&gt; CNAME
pointing to the same location. Since I have Pelican configured to strip it with the setting below, it doesn't matter other than people expect to enter &lt;code&gt;www dot domain dot com&lt;/code&gt; in their URL bar.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;SITEURL = 'http://andrewwegner.com'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Last, I had to point by name servers to CloudFlare instead of my dedicated server. They provide a list of registrars to choose from. Select your registrar and follow the instructions. My biggest
issue here was remembering my GoDaddy password. After I made it into my account, the steps to change name servers were very simple. Once those are saved, you wait for the changes to propagate and
enjoy your new GitHub Pages / CloudFlare web page for free.&lt;/p&gt;</content><category term="Meta"></category><category term="technical"></category><category term="Pelican"></category></entry><entry><title>Why I moved from Wordpress to Pelican</title><link href="https://andrewwegner.com/why-i-moved-from-wordpress-to-pelican.html" rel="alternate"></link><published>2015-05-03T22:41:00-05:00</published><updated>2015-05-03T22:41:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-05-03:/why-i-moved-from-wordpress-to-pelican.html</id><summary type="html">&lt;p&gt;A brief summary of why I dropped Wordpress and moved to Pelican&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;For years, I maintained a Wordpress blog covering various things I've done or created. Most of these revolved around
things I created to make administering Team Vipers easier for me and for the rest of the admin team. It was my way
of documenting what I'd done (in case I ever needed to do it again) and providing a way to update the Team Vipers community
about new plugins or applications that would be deployed to the community. &lt;/p&gt;
&lt;h2 id="my-issues-with-wordpress"&gt;My Issues with Wordpress&lt;a class="headerlink" href="#my-issues-with-wordpress" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The problem I had with Wordpress was that it was just to bulky for the simple posts I was making. I needed a database, a full web
server (or a hosting provider), and either time to hunt for the "perfect" plugin(s) or PHP knowledge to do it myself. Early in my
development career, I used PHP a lot. That was part of the reason I chose Wordpress. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Oh! I know that language. If I ever need something, I can just whip it up myself. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;-Me, before the real world ambushed me and beat me with a stick&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="spam"&gt;Spam&lt;a class="headerlink" href="#spam" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I spent time setting up Wordpress. I picked out a theme, plugins, and started saving future me with documentation. Then life happened. For whatever
reason, I stopped updating Wordpress. My blog sat out there for weeks or months unvisited by anyone. Then, one morning, my phone vibrated
and told me that I had a new comment on my site. Woo! &lt;/p&gt;
&lt;p&gt;Except it was spam. Boo!&lt;/p&gt;
&lt;p&gt;I marked it spam and moved on with my day. Later that morning, I glanced at my phone again. 32 emails. I am just not that popular. Something
was wrong. Turns out, a spam bot found me. I sighed and then removed all the comments and checked the box indicating that users had to
be registered to post. That solved my problem for a few months.&lt;/p&gt;
&lt;p&gt;Then the bots got smarter. They started registering. They started posting legitimate looking messages, except for that associated URL their name
would link to in the comments. They pulled keywords out of the post and formulated a somewhat passable English question using those words. The spam
prevention plugins I installed would slow the tide for a few weeks. The bots would adapt and then I'd be awash with spam posts again. Eventually,
the solution was to completely disable comments. I'd spent way to much time dealing with spam on a blog that received very little legitimate traffic.&lt;/p&gt;
&lt;p&gt;Since I don't utilize the comments, Pelican provides a nice simple page that I can post my thoughts and not worry about getting hit by a spam bot. It also
provides plugins so that I &lt;em&gt;can&lt;/em&gt; include comments should I ever choose to do so in the future. For the time being, though, I have a nice simple page 
with no comments. That's exactly what I was looking for.&lt;/p&gt;
&lt;h3 id="security"&gt;Security&lt;a class="headerlink" href="#security" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you watch any technology web sites, you'll notice that there are vulnerabilities found in Wordpress frequently. These require patches,
which requires me to do something. It may be as simple as logging in and clicking a button to update, but it is still something I need to 
remember to do for a relatively minor site. When I'd log in to clear the spam backlog, I'd frequently also install updates for 10-20 plugins, themes or
Wordpress itself. It was mostly painless, but I didn't like the idea of the site sitting there vulnerable for weeks at a time because I didn't
visit and login.&lt;/p&gt;
&lt;p&gt;The dynamic nature of Wordpress and the underlying database exposed a fairly sizable target for a web page so small. Pelican generates static
HTML pages. I don't have to worry about SQL injections, unauthorized logins, or anything else. I host a basic set of HTML, CSS and JavaScript files. 
That's it.&lt;/p&gt;
&lt;h2 id="php-vs-python"&gt;PHP vs Python&lt;a class="headerlink" href="#php-vs-python" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As I mentioned before, I used to use PHP frequently. It was my go to language. I picked Wordpress with the idea that I'd be able to hack together features I needed.
The reality, it turns out, was that I wasn't actually interested in doing that. Instead, I picked out plugins that were close enough to the
exact functionality I wanted. &lt;/p&gt;
&lt;p&gt;I transferred to a job where I used Python. Instead of having a language I used on the side (PHP) and a job where I was a glorified project manager, without the 
actual title of "Project Manager", I now had a job where I used a language (Python) for 8 hours a day. My usage of PHP plummeted. I found I could get what I wanted
done in my side projects faster and easier with Python. At work I used Python to build tools for engineering problems. At home, I started using it for every day
tasks. &lt;/p&gt;
&lt;p&gt;Soon, I realized I hadn't used PHP for several versions of the language. My knowledge of the language was outdated. The biggest reason I'd chosen Wordpress was no longer
relevant, because I couldn't write anything complicated in PHP without glancing at documentation to do even simple things. It's sad that I lost the intimate knowledge of
a language, but I feel that I've been more productive with Python anyway.&lt;/p&gt;
&lt;p&gt;Pelican is written in Python. Even more importantly though, it generates HTML files which are hosted. I don't need to run a Python environment on a server. I just
need to host HTML files. &lt;/p&gt;
&lt;h2 id="markdown"&gt;Markdown&lt;a class="headerlink" href="#markdown" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Finally, I've fought with Wordpress's text editor countless times. This happened most often when attempting to add code blocks. It was a pain to do. It was a pain
to fix when the blocks broke. Pelican supports Markdown. Markdown is supported by large organizations like GitHub, reddit and Stack Exchange. I use all three of those.
I know how to utilize Markdown to create code blocks, headers, insert images, create bulleted lists. All without needing to fight how the text editor is going to actually
save the data.&lt;/p&gt;</content><category term="Meta"></category><category term="Pelican"></category></entry><entry><title>I'm running to be a moderator of Stack Overflow</title><link href="https://andrewwegner.com/i'm-running-to-be-a-moderator-of-stack-overflow.html" rel="alternate"></link><published>2015-04-06T22:00:00-05:00</published><updated>2015-04-21T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-04-06:/i'm-running-to-be-a-moderator-of-stack-overflow.html</id><summary type="html">&lt;p&gt;I'm running for a Stack Overflow moderator position in April 2015. This entry follows the election process.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://stackexchange.com/sites#"&gt;Stack Exchange&lt;/a&gt; has over 130 sites in its network. Each of those sites has at least 3 moderators that are glorified &lt;a href="http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/"&gt;janitors&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A lot of the moderation work is extremely mundane, almost janitorial. It’s deleting obvious spam, closing blatantly off-topic questions, and culling some of the worst rated posts in various dimensions.&lt;/p&gt;
&lt;p&gt;The ideal moderator does as little as possible. But those little actions may be powerful and highly concentrated. Judiciously limiting your use of moderator powers to selectively prune and guide the community — now that’s the true art of moderation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This works so well in the Stack Exchange network because the users are able to handle most moderation tasks. As users gain reputation, they gain privileges. With these privileges, they are better able to maintain and cultivate the content on the site.&lt;/p&gt;
&lt;p&gt;Not all activity can be performed by users though. This is where moderators come in.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://communitybuilding.stackexchange.com/users/78/andy?tab=profile"&gt;&lt;img alt="Andy on Community Building" src="https://andrewwegner.com/images/community_building_andy_flair.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I already have a diamond (♦) on the &lt;a href="http://communitybuilding.stackexchange.com/"&gt;Community Building&lt;/a&gt; site. I was &lt;a href="http://meta.communitybuilding.stackexchange.com/q/138/78"&gt;appointed&lt;/a&gt; one of the Pro Tempore moderators during the beta phase of the site. This is my first experience moderating on Stack Exchange, beyond what my reputation on Stack Overflow
gets me. &lt;a href="http://meta.communitybuilding.stackexchange.com/a/77/78"&gt;It is not, however, my first time moderating&lt;/a&gt;. &lt;em&gt;Community Building&lt;/em&gt; is focused on various aspects of building communities - both online and off. It caters to users from all aspects of a site (owners, moderators, users, advertisers and any thing else).
My experience here led me to pursuing a moderator position on Stack Overflow. This site is orders of magnitude larger than &lt;em&gt;Community Building&lt;/em&gt;. It has millions of users and millions of questions. With all this traffic, there are still only 18 diamond moderators. The
idea of community moderation shows that it scales well.&lt;/p&gt;
&lt;h2 id="nomination-phase"&gt;Nomination Phase&lt;a class="headerlink" href="#nomination-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The election cycle begins with the nomination phase. Users nominate themselves for the position. In 1200 characters or less, you lay out your platform. In this phase, nearly anyone can nominate themselves. However, there are only 30 positions available. If more than 30 people
nominate themselves, then the users with the lowest reputation get bumped. With only 11K reputation, I am at the lower end of the spectrum of other nominees, but I am well above the lowest. I have the 8th lowest reputation. I've looked at previous election cycles. It seems unlikely
that there will be 30 or more nominees. I think that I am safe.&lt;/p&gt;
&lt;h3 id="my-platform"&gt;My Platform&lt;a class="headerlink" href="#my-platform" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I posted my &lt;a href="http://stackoverflow.com/election/6#post-29480018"&gt;platform&lt;/a&gt; shortly after the nomination phase opened. I stressed the work that I've already done on Stack Overflow and previous moderation experience on another Stack Exchange site (Community Building).&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I'm Andy and I want to be one of your moderators.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why vote for me?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I've built an automated script to handle &lt;a href="http://meta.stackoverflow.com/questions/280546/can-a-machine-be-taught-to-flag-comments-automatically"&gt;noisy comments&lt;/a&gt;. It runs daily, probably to the chagrin of the current moderators, but it helps keep the comments noise down and it is incredibly accurate.&lt;/li&gt;
&lt;li&gt;In addition to the automated flagging, I participate in the review queues, provide edits and post &lt;a href="http://stackoverflow.com/users/189134/andy?tab=answers"&gt;answers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;As a moderator of &lt;a href="http://communitybuilding.stackexchange.com/"&gt;"Community Building"&lt;/a&gt;, I know the tools used by the Stack Exchange sites. I've used this position to interact with the existing moderators for advise and questions. This interaction will not only continue but be helpful as a new moderator to SO.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I have the flagging history and experience to make the appropriate judgment calls. I feel that is a positive attribute that will help me in helping you to have the best experience you can on Stack Overflow.&lt;/p&gt;
&lt;p&gt;I'll continue to help improve the site regardless of whether I am elected or not. I will be able to do a much better job at that, though, as one of your moderators.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;With this, I received my "candidate score". It was 29/40. Not the highest, but not the lowest either. I expect, if any one is concerned about this score, it will be mentioned it in the comments.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Candidate Score" src="https://andrewwegner.com/images/april_2015_candidate_score.png"/&gt;&lt;/p&gt;
&lt;h3 id="nomination-phase-comments"&gt;Nomination Phase Comments&lt;a class="headerlink" href="#nomination-phase-comments" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Updated April 11, 2014&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The comments on my nomination post have focused mostly on the pros and cons of the automated script I built to flag comments. I was expecting this discussion. I'd classify most of the comments about the script as
"cautious". Users seem concerned about something completely automated used to moderate or that I focus on low priority content. My response to this concern was:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[...] by automating the removal of this lower priority content it is easier to focus on the actively harmful stuff.&lt;/p&gt;
&lt;p&gt;I'd like to point out that I have done more than "build a script". I've actively participated in review queues on Stack Overflow for years. I've flagged appropriate content
(with a high percentage marked as accepted). I have also been moderator on Community Building. All of this, in combination with the automation, makes up my "platform".
I have the experience of moderation, the knowledge of how the system works and the drive to improve the community.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It was also mentioned a few times that I'd be unlikely to utilize such an automated tool as a moderator. I promised to bring this concern up when I moved further into the election process.&lt;/p&gt;
&lt;p&gt;Finally, I received a few comments supporting either me or the work that I've done.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The automation is very impressive - thanks for that, it's a real contribution to the quality of the site. That said - as a privileged user I suspect you won't be able to run these sort of scripts on your account for obvious reasons.  –  Benjamin Gruenbaum Apr 6 at 21:34&lt;/p&gt;
&lt;p&gt;I can vouch for Andy's track record as a pro tem mod on Community Building. I want to note as well for the record that many of the main site questions and answers on Community Building are explicitly about moderation, and his contributions there also provide insight into his approach to the job. –  Air Apr 7 at 16:54&lt;/p&gt;
&lt;p&gt;Huh. I have to say I'm impressed. Putting you on my list of candidates to watch. –  Qix Apr 7 at 19:23&lt;/p&gt;
&lt;p&gt;I'd just like to point out that your response to my concerns is fair and reasonable, as well as polite, even if it isn't quite exactly how I see things. It certainly alleviates my concerns of misusing moderator power. I will be seriously considering voting for you. –  jpmc26 Apr 8 at 6:41&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Overall, I'm pleased with how the discussion has gone. It has been a few days since there were comments left though. Hopefully a little interest picks up during the primary phase.&lt;/p&gt;
&lt;p&gt;I am also very impressed by the other candidates. There are many very good candidates that I'd be happy to work with (or be unashamed to lose to).&lt;/p&gt;
&lt;h2 id="primary-phase"&gt;Primary Phase&lt;a class="headerlink" href="#primary-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated April 17, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The nomination phases has ended. I have advanced to the primary phase. The purpose of this phase is to narrow the list of 30 candidates to 10. Those 10 will be the ones that can be voted on to be the next moderators. In the primary phase, users can vote nominees up or down.&lt;/p&gt;
&lt;p&gt;As part of the election process, one of the other &lt;a href="http://stackoverflow.com/users/616460/jason-c"&gt;candidates&lt;/a&gt; created several tools to help users see nominee activity. He also created a &lt;a href="http://meta.stackoverflow.com/questions/290346/2015-election-live-vote-monitor"&gt;live vote monitor&lt;/a&gt;. It was exciting to hang out in the Election Chat room and watch votes roll in. The position of 10th was highly contested
toward the end of the primary. I was very pleased to see that everyone remained civil in the chat room too.&lt;/p&gt;
&lt;p&gt;I ended this phase with &lt;strong&gt;1492&lt;/strong&gt; positive votes. This put me in 15th. Sadly, not enough to advance to the election phase. However, there are several excellent candidates that did advance. Good luck to them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Live Vote Counter at the end of the Primary" src="https://andrewwegner.com/images/april_2015_primary_live_vote.png"/&gt;&lt;/p&gt;
&lt;h3 id="other-primary-data"&gt;Other Primary Data&lt;a class="headerlink" href="#other-primary-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Part of the primary phase involves answering questions that users have posed during the nomination phase. These questions were voted upon and the highest were included in the questionnaire. My &lt;a href="http://meta.stackoverflow.com/questions/290096/2015-moderator-election-qa-questionnaire/290122#290122"&gt;response&lt;/a&gt; was removed at the end of this phase because I did not advance. I was
prepared with answers about my moderation style and my expectations for the position.&lt;/p&gt;
&lt;p&gt;One of the other tools that was created during this cycle showed &lt;a href="http://meta.stackoverflow.com/questions/289995/2015-moderator-candidate-activity-profiles"&gt;nominee activity&lt;/a&gt; on the site over time. This was a quick way to compare nominees based on the number of activities they have performed on undeleted posts (because data related to deleted posts is removed from public view). It
provided, at a glance, a way to see who is and is not active.&lt;/p&gt;
&lt;p&gt;Below are the charts of my activity that the tool created. The green vertical bar is account creation date. The orange/brown vertical bars are previous election windows.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Stack Overflow Activity Chart" src="https://andrewwegner.com/images/april_2015_so_activity_chart.png"/&gt;
This is my activity chart for Stack Overflow itself. It shows that I've had an account since 2009, but didn't really start utilizing the site, more than occassionally, until 2013. Since then, it shows that a large majority of my
activity onsite is in the review queues. There are posts, revisions, comments and more along the bottom, but most of my activity is in the review queues.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Meta Stack Overflow Activity Chart" src="https://andrewwegner.com/images/april_2015_mso_activity_chart.png"/&gt;
&lt;img alt="Meta Stack Exchange Activity Chart" src="https://andrewwegner.com/images/april_2015_mse_activity_chart.png"/&gt;
My Meta Stack Overflow and Meta Stack Exchange charts show a fairly low activity level. Unfortunately, I think this is obscuring the posts that I do make simply because of the large scale on the y-axis.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Combined Activity Chart" src="https://andrewwegner.com/images/april_2015_combined_activity_chart.png"/&gt;
Finally, the last chart shows the combined activity across all three areas (SO, MSO, and MSE). It looks very similar to the Stack Overflow one because of the lower activity levels on the two Meta sites.&lt;/p&gt;
&lt;h2 id="election-phase"&gt;Election Phase&lt;a class="headerlink" href="#election-phase" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated April 21, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The election is over. Three great candidates were elected. One thing I am like about Stack Exchange's elections is their &lt;a href="http://meta.stackexchange.com/a/77560/186281"&gt;usage of OpenSTV and the Meek STV method&lt;/a&gt;. The results of each round of the
election cycle are available at &lt;a href="http://www.opavote.org/results/4962933813542912/0"&gt;opavote.org&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="final-thoughts"&gt;Final Thoughts&lt;a class="headerlink" href="#final-thoughts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Like most elections, there are known and unknown winners before the election even begins. The response that &lt;a href="http://stackoverflow.com/users/100297/martijn-pieters"&gt;Martijn Pieters&lt;/a&gt; received from the time he nominated through the final moments of the election all but guarenteed a victory for him. It is a
well deserved victory. I hope that he is able to keep up his frequent, high quality, answers in the &lt;a href="http://stackoverflow.com/questions/tagged/python"&gt;python&lt;/a&gt; tag. If not, his drop in activity will be felt. The surprise, to me, was &lt;a href="http://stackoverflow.com/users/1114/jeremy-banks"&gt;Jeremy Banks&lt;/a&gt;. He ended in 9th place in the primaries. That doesn't mean he can't do the job.&lt;/p&gt;
&lt;p&gt;I've interacted with all three moderators on site and in chat prior to their victory. I've been very happy with those interactions. With their promotion, I look forward to working with them as a moderator on the Stack Exchange network in the future.&lt;/p&gt;
&lt;p&gt;Congratulations to the winners!&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="moderation"></category></entry><entry><title>Zephyr - The bot that watches for low quality vote requests</title><link href="https://andrewwegner.com/zephyr-the-bot-that-watches-for-low-quality-vote-requests.html" rel="alternate"></link><published>2015-03-12T23:34:00-05:00</published><updated>2015-05-08T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-03-12:/zephyr-the-bot-that-watches-for-low-quality-vote-requests.html</id><summary type="html">&lt;p&gt;Find out about the bot that watches Stack Exchange chat rooms for requests to close low quality content&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Stack Exchange receives thousands of questions per day across all of their sites. Not all of these are high quality
posts. Fortunately, users of the Stack Exchange network are given &lt;a href="http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/"&gt;tools&lt;/a&gt; to help keep that low quality stuff to a 
minimum. One of these tools is the chat network that spans the Stack Exchange sites. &lt;/p&gt;
&lt;p&gt;In the chat rooms, a convention has arisen to tag a message as &lt;kbd class="light"&gt;cv-pls&lt;/kbd&gt; for questions that need to be closed for one reason 
or another. Over time, this evolved to include other tags such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;kbd class="light"&gt;del-pls&lt;/kbd&gt; for a deletion request&lt;/li&gt;
&lt;li&gt;&lt;kbd class="light"&gt;spam&lt;/kbd&gt; for notification that spam made it through the already &lt;a href="http://meta.stackexchange.com/questions/228043/"&gt;impressive&lt;/a&gt; spam &lt;a href="http://meta.stackexchange.com/a/237882/186281"&gt;filters&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;kbd class="light"&gt;reopen&lt;/kbd&gt; for a reopen request&lt;/li&gt;
&lt;li&gt;a few others to cover specific flag types (eg. Not an answer, Very Low Quality or Offensive)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="introducing-zephyr"&gt;Introducing Zephyr&lt;a class="headerlink" href="#introducing-zephyr" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The problem with these is that the requests are only seen by users active in the specific room where it was posted. 
Other users across the network miss the request. &lt;strong&gt;&lt;a href="https://github.com/AWegnerGitHub/SE_Zephyr_VoteRequest_bot"&gt;Zephyr&lt;/a&gt;&lt;/strong&gt; was built to resolve this problem. Zephyr monitors
several rooms where these types of requests are frequent. These requests all all posted into a single &lt;a href="http://chat.meta.stackexchange.com/rooms/773/low-quality-posts-hq"&gt;chat room&lt;/a&gt;. 
This provides users with a single room to monitor to see requests for multiple questions and sites across the network.&lt;/p&gt;
&lt;p&gt;Here is an example of what Zephyr's chat activity looks like during a spam wave:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Zephyr's chat activity during a spam wave" src="https://andrewwegner.com/images/zephyr-spam-wave.png"/&gt;&lt;/p&gt;
&lt;h3 id="how-it-works"&gt;How it works&lt;a class="headerlink" href="#how-it-works" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Zephyr utilizes the &lt;a href="https://github.com/Manishearth/ChatExchange"&gt;ChatExchange&lt;/a&gt; package to join and read the chat rooms. To do this, Zephyr required a dedicated
account. I decided to run Zephyr with a dedicated account to completely separate the bot that would sit and watch multiple chat
rooms 24/7 from my account. Zephyr maintains a small SQLite database of all the posts that it records. The idea behind this, 
is that eventually this data will be utilized to train other systems on unwanted content. This information is pulled via
the &lt;a href="http://api.stackexchange.com/"&gt;API&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Zephyr watches the chat rooms for specific string &lt;a href="https://github.com/AWegnerGitHub/SE_Zephyr_VoteRequest_bot/blob/master/create_config_files.py"&gt;patterns&lt;/a&gt;. If these patterns are matched, a message is posted if &lt;code&gt;should_post&lt;/code&gt; 
is &lt;code&gt;True&lt;/code&gt; for the matched pattern. &lt;/p&gt;
&lt;p&gt;Overall, a nice simple application. It performs some pattern matching and a couple API calls. &lt;/p&gt;
&lt;h3 id="other-bots"&gt;Other bots&lt;a class="headerlink" href="#other-bots" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In addition to watching user activity, Zephyr also watches two other quality bots that patrol Stack Exchange for low
quality content: &lt;a href="https://github.com/Charcoal-SE/SmokeDetector"&gt;SmokeDetector&lt;/a&gt; and &lt;a href="https://github.com/ArcticEcho/Phamhilator/wiki"&gt;Phamhilator&lt;/a&gt;. If either of these bots detect spam, Zephyr takes note of the information by
recording it to the database, but not reposting. Since both of those bots post their reports, it didn't make sense for Zephyr
to add a second (or third, if both of the others detected spam) message to the chat room. The information is recorded, though,
to help future training for other systems.&lt;/p&gt;
&lt;h2 id="updates"&gt;Updates&lt;a class="headerlink" href="#updates" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated May 8, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Over time Zephyr has been updated to include new rooms to monitor or new patterns to match. Those changes are small (and simple).
There are, however, a few larger changes that I'd like to note below.&lt;/p&gt;
&lt;h3 id="commands"&gt;Commands&lt;a class="headerlink" href="#commands" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The other bots that Zephyr monitors respond to user input. Zephyr has very little that requires user interaction since all of it's
posts are generated &lt;em&gt;by&lt;/em&gt; user input. However, there have been times where I, as the bot owner, would like to be able to issue
certain commands to it. My most common desire is to see a report of how many spam posts Zephyr has seen. Thus, Zephyr now responds
to the command &lt;code&gt;spamreport&lt;/code&gt; from me. It then prints out a nice summary of information. This information has been utilized in 
SmokeDetector to watch for commonly spammed domains.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Zephyr spam report for April 2015" src="https://andrewwegner.com/images/zephyr-spam-report.png"/&gt;&lt;/p&gt;
&lt;h3 id="upgrade-from-sqlite-to-mariadb"&gt;Upgrade from SQLite to MariaDB&lt;a class="headerlink" href="#upgrade-from-sqlite-to-mariadb" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Zephyr was originally built against an SQLite database. This worked, but was getting slower as more data was being added. This slow down
was beginning to affect performance. I started seeing this error more and more frequently:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;Traceback (most recent call last):&lt;/span&gt;
&lt;span class="err"&gt;  File "H:\python-virtualenvs\zephyr-se-voterequests\lib\site-packages\sqlalchemy\pool.py", line 255, in _close_connection&lt;/span&gt;
&lt;span class="err"&gt;    self._dialect.do_close(connection)&lt;/span&gt;
&lt;span class="err"&gt;  File "H:\python-virtualenvs\zephyr-se-voterequests\lib\site-packages\sqlalchemy\engine\default.py", line 418, in do_close&lt;/span&gt;
&lt;span class="err"&gt;    dbapi_connection.close()&lt;/span&gt;
&lt;span class="c"&gt;ProgrammingError: SQLite objects created in a thread can only be used in that same thread.The object was created in thread id 4824 and this is thread id 4660&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After spending a lot of time troubleshooting and not resolving it to my satisfaction, I decided to upgrade to a more robust database. I'd used
MySQL/MariaDB before and I happened to have another application utilizing MariaDB at the moment so that is the solution I picked. &lt;/p&gt;
&lt;p&gt;The first step was transferring data. I learned that there isn't a decent utility to do a straight migration. So, I took these steps to transfer the data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Export table structures and data from SQLite&lt;/li&gt;
&lt;li&gt;Convert the SQLite dump to MySQL format. Though both systems use SQL, there are slight differences in dialect. I utilized
 &lt;a href="http://stackoverflow.com/a/1067365/189134"&gt;this Python script&lt;/a&gt; as a starting point. It got me most of the way there, but not completely.&lt;/li&gt;
&lt;li&gt;Data clean up. Ugh. The dreaded part of the job for anyone who handles data. Fortunately, the script above did most of the work.
 I ended up fixing a couple stray back ticks that didn't convert properly, escaping a very extra quotation marks, and replacing
 a few "smart quotes" (of both the &lt;a href="http://www.fileformat.info/info/unicode/char/201c/index.htm"&gt;left&lt;/a&gt; and &lt;a href="http://www.fileformat.info/info/unicode/char/201d/index.htm"&gt;right&lt;/a&gt; variety). I wish data at the office job was this easy to clean...&lt;/li&gt;
&lt;li&gt;Import into MariaDB&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since the transfer to MariaDB, I've noticed no performance degradation. The error about threads has been eliminated as well.&lt;/p&gt;
&lt;h3 id="upgrade-to-utilize-web-sockets"&gt;Upgrade to utilize web sockets&lt;a class="headerlink" href="#upgrade-to-utilize-web-sockets" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Originally, Zephyr used the &lt;a href="https://github.com/Manishearth/ChatExchange/blob/master/chatexchange/rooms.py#L68"&gt;&lt;code&gt;watch&lt;/code&gt;&lt;/a&gt; method when monitoring a room. This method would long poll the room. It turns out that this is 
pretty unreliable. I'd get multiple errors through out the week, ranging from &lt;code&gt;Connection Aborted&lt;/code&gt; errors to random &lt;code&gt;404&lt;/code&gt; messages. The 
solution has been to switch to &lt;a href="https://github.com/Manishearth/ChatExchange/blob/master/chatexchange/rooms.py#L78"&gt;&lt;code&gt;watch_socket&lt;/code&gt;&lt;/a&gt;. The only time I've had problems since this switch is when the Stack Exchange 
web sockets go down. This saves a lot of restarts to get everything up and running again.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="automation"></category><category term="programming"></category></entry><entry><title>Thanks for all the fish</title><link href="https://andrewwegner.com/thanks-for-all-the-fish.html" rel="alternate"></link><published>2015-01-08T15:38:00-06:00</published><updated>2015-04-28T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-01-08:/thanks-for-all-the-fish.html</id><summary type="html">&lt;p&gt;Good bye, Team Vipers, it's been a great 6 years&lt;/p&gt;</summary><content type="html">
&lt;h2 id="goodbye-team-vipers"&gt;Goodbye Team Vipers&lt;a class="headerlink" href="#goodbye-team-vipers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A few days ago Team Vipers shut down. Exactly 6 years after I join the community and 5 years after taking
over as owner, I decided to step aside. I announced my decision to my admin team in November and asked if anyone wanted to
take over. A week later I made the announcement public. I copied that below. My hope was that someone would be willing to
take over day to day operations and management.&lt;/p&gt;
&lt;p&gt;Unfortunately, no one was able to take on the responsibilities. I had to make the hard choice of shutting down the community.
I am unable to provide the time or monetary commitment this community requires any longer. Team Vipers was a home and
community for 6 years. I've met a lot of people playing games with members of the community. Several other sites were
created by members of Team Vipers. They have indicated they'd be willing to absorb and welcome members from Vipers.&lt;/p&gt;
&lt;p&gt;It's been a great run. So long Vipers, and thanks for all the fish.&lt;/p&gt;
&lt;p&gt;
&lt;iframe allowfullscreen="true" frameborder="0" height="315" src="//www.youtube.com/embed/BL-5OdZc3zw" width="560"&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;p&gt;&lt;img alt="Thanks for the fish" src="https://andrewwegner.com/images/thanks-for-the-fish.jpg"/&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="original-announcement"&gt;Original Announcement&lt;a class="headerlink" href="#original-announcement" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On January 5th, 2015, I am stepping away from Vipers as the owner and administrator. Unfortunately, I no longer have time
to maintain the servers in a way that benefits the community. I announced this to the admin team earlier this week.&lt;/p&gt;
&lt;h3 id="what-do-we-do-before-january-5th"&gt;What do we do before January 5th?&lt;a class="headerlink" href="#what-do-we-do-before-january-5th" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I am giving you this heads up to discuss the future of Vipers. If someone wants to step up and take everything on, I'll
gladly offer help during the transition. If you have questions about what happens behind the scenes, I'll answer those
as well. In fact, I'll start with a few questions that I think may help lead this discussion.&lt;/p&gt;
&lt;h3 id="do-we-need-multiple-game-servers"&gt;Do we need multiple game servers?&lt;a class="headerlink" href="#do-we-need-multiple-game-servers" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Short answer - No. If the community wants to focus on a specific server mode, then a single server is all that is needed.
When I joined Vipers there were two servers: An Orange server and a vanilla server. For the first year-ish, the
servers base grew and contracted around different mods. Orange turned to Crit Orange, a Randomizer appeared and then
splintered into it's own community, the Nest grew and then shrank. Zombie popped up. Prophunt and Dodgeball came around
multiple times. In all of this, there has been between one or two popular servers, with the rest being very niche. Those
are for fun. Those are also frustrating to fix when updates break them.&lt;/p&gt;
&lt;h3 id="do-we-need-a-dedicated-server"&gt;Do we need a dedicated server?&lt;a class="headerlink" href="#do-we-need-a-dedicated-server" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Again, no. The benefit the dedicated server provided is IP address stability. Before the dedicated server, the game servers
jumped around IPs every few months. With each move players were lost. Some found us months or years later when they
randomly stumbled upon us. Others are just gone. More importantly though, is dealing with performance. If there is a
hosting company that can provide high quality, low ping, servers at a cheap price - that is worth it. A word of advice,
avoid EscapedTurkey. It is a one man operation and that person doesn't know what they are doing. If an issue crops up,
it takes hours to days to resolve it. It is because of them that we purchased a dedicated server.&lt;/p&gt;
&lt;p&gt;One other note. I can not transfer the dedicated server to anyone. It's rented in my name and the hosting company doesn't
allow transfers. So, no matter what happens, the IP addresses would have to change anyway. The upside of this long
transition period is that you have plenty of time to advertise and set up the new servers. We could have in game announcements
AND we can lock the existing servers with the new IP in the titles. It won't be an immediate cut over. It provides
notification to the players.&lt;/p&gt;
&lt;h3 id="do-we-need-the-forums"&gt;Do we need the forums?&lt;a class="headerlink" href="#do-we-need-the-forums" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Yes. The forums are what kept me in Vipers before I ended up in the position I'm in now. Without the forums, there is no
community. There are people that you see frequently on the servers, but rarely any meaningful interaction. With the forums
we get stories of our members' lives. If, however, you are going to stick to playing Valve games, I highly recommend a
change in forum software. Find something that supports integration with Steam (either natively or via plugin) and start
over. With that integration, you can do so many more (and non-hackish) things. You can pull information from Steam or
any other TF2 community that exposes an API. Banning a player on the servers and the forums is easy as both are based
on the same thing. Additionally, requiring the Steam login should eliminate the spam (no random Chinese, Russian,
Californian spam bots). In any case, I will provide a full database dump for you. If you stick with PHPBB, I think a
fresh install of PHPBB would be a good thing, but you'll have all of the data and should be able to simply import it
into the database. If you go with something else, you'll have the database and can attempt to use that software's
conversion script. Results will vary on how that works.&lt;/p&gt;
&lt;h3 id="does-we-make-money-on-donations"&gt;Does we make money on donations?&lt;a class="headerlink" href="#does-we-make-money-on-donations" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;No. Since July of [2014 to November 2014], the community has donated $20. Total. It has been 14 months since we reached our monthly
goal. In the last year, we have broken $50 only 4 times. To prevent someone from misconstruing this as a plea for
money, I've disabled donations. I don't want someone to start a misguided "Save the Vipers" campaign that you believe
can succeed with donations. The way to "save the vipers" is to come together as a team and discuss your options.&lt;/p&gt;
&lt;h3 id="what-happens-if-no-one-steps-up"&gt;What happens if no one steps up?&lt;a class="headerlink" href="#what-happens-if-no-one-steps-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Someone in the community may step up, but if no one steps up by January, then Vipers has one last New Years hoo-rah
and fades to the internet. If someone does step up, I am still available to help with initial set up. I'm still available
to play games and to talk to. I'm not dropping off the face of the earth and I'm not rage quitting. This is very
much a case of real life happens.&lt;/p&gt;
&lt;p&gt;I think that is going to cover your initial questions. If you have more, post them here and I'll answer them.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;It has been a great 6 years with everyone here. While I may be stepping down as owner, if someone keeps Vipers around,
you'll keep me around as a regular. I've had fun talking to all of you and playing with (and against) all of you.&lt;/em&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="updated-steam-group-ownership"&gt;Updated Steam Group Ownership&lt;a class="headerlink" href="#updated-steam-group-ownership" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated April 28, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Ownership of the Steam Group for Team Vipers has been transferred back to Russell, the original founder of Vipers. The
&lt;a href="http://steamcommunity.com/groups/viperservers#announcements/detail/205255298394906049"&gt;announcement&lt;/a&gt; was posted to the group earlier today.&lt;/p&gt;
&lt;p&gt;I've also transferred data from the Vipers blog to my personal one here and removed links to Vipers from most posts
since they will all fail to resolve correctly. Unfortunately, it's not worth it to preserve small bits of history in
this case and was just easier to remove the links. The best I can do it transfer the blog posts and copy snippets or
screenshots here. Direct links to the forum discussions has been intentionally removed.&lt;/p&gt;</content><category term="team vipers"></category></entry><entry><title>Can a machine be taught to flag comments automatically</title><link href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html" rel="alternate"></link><published>2015-01-02T08:47:00-06:00</published><updated>2016-01-09T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-01-02:/can-a-machine-be-taught-to-flag-comments-automatically.html</id><summary type="html">&lt;p&gt;Description of how I automatically flag comments on Stack Overflow&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This post was originally &lt;a href="http://meta.stackoverflow.com/q/280546/189134"&gt;published&lt;/a&gt; by &lt;a href="http://meta.stackoverflow.com/users/189134/andy?tab=profile"&gt;me&lt;/a&gt; on Meta Stack Overflow on December 14, 2014. I've republished it here
so that I can easily update information related to recent developments. If you have questions or comments, I highly
encourage you to visit the &lt;a href="http://meta.stackoverflow.com/q/280546/189134"&gt;question&lt;/a&gt; on Meta Stack Overflow and post there.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;TL;DR: Yes it can.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="background"&gt;Background&lt;a class="headerlink" href="#background" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On June 27, 2014 Skynet awoke. It looked at Stack Overflow and thought "Why are all these people being so chatty and talking about obsolete things? I should nuke them all!" Fortunately, Skynet was a baby and only had access to my 100 comment flags a day.&lt;/p&gt;
&lt;p&gt;Prior to this activation date, the system was fed with 10,000 "Good Comments", "Obsolete" comments and "Too Chatty" comments. These comments were taken from the &lt;a href="http://data.stackexchange.com/"&gt;Stack Exchange Data Explorer&lt;/a&gt;. The "Obsolete" and "Too Chatty" comment types had to meet the following criteria:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Total comment length of less than 100 characters&lt;/li&gt;
&lt;li&gt;Comment has a 0 score&lt;/li&gt;
&lt;li&gt;Had variations of the following phrases:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Phrases&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;'%mark%answer%'&lt;/span&gt;
&lt;span class="err"&gt;'%mark%accept%'&lt;/span&gt;
&lt;span class="err"&gt;'%accept%answer%'&lt;/span&gt;
&lt;span class="err"&gt;'%lease%accept%'&lt;/span&gt;
&lt;span class="err"&gt;'%mark%answer%'&lt;/span&gt;
&lt;span class="err"&gt;'%thank%you%'&lt;/span&gt;
&lt;span class="err"&gt;'%thx%you%'&lt;/span&gt;
&lt;span class="err"&gt;'%.....'&lt;/span&gt;
&lt;span class="err"&gt;'+1%'&lt;/span&gt;
&lt;span class="err"&gt;'-1%'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;"Good Comments" were assumed, initially, to be anything that didn't fall into the above criteria&lt;/p&gt;
&lt;p&gt;This provided a base of 30,000 comments that were roughly categorized into 3 distinct groups. Manually scanning the classifications took several weeks, and through this some of the groupings were changed to reflect a more appropriate classification. Not all comments less than 100 characters starting with "Thank you" are "too chatty", just as not all comments over 100 characters are good comments. I reclassified these comments as if I had encountered them on Stack Overflow.&lt;/p&gt;
&lt;p&gt;My next step was to train a classifier. I had initially assumed that I'd start with a Naive Bayes to get a baseline and then work to something more complicated from there. Perhaps, extract text features, user information, etc. and build a fancy classifier. My initial tests showed that the Naive Bayes was accurate 80-90% of the time with test data.&lt;/p&gt;
&lt;p&gt;I combined the classifier's certainty of classification with an acceptable threshold of when I'd allow a flag to be issued in my name. Tuning these threshold took a few weeks but eventually I determined the following thresholds were appropriate for my use:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="gh"&gt;Type            | Threshold     | Flagging Enabled&lt;/span&gt;
&lt;span class="gh"&gt;--------------------------------------------------&lt;/span&gt;
too chatty      | 0.9997        | True
obsolete        | 0.99          | True
good comment    | 0.9999        | False
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When a comment is classified, if it exceeds the threshold for one of the above, it is recorded into my database for future retraining. If flagging is enabled, the API is &lt;a href="http://api.stackexchange.com/docs/comment-flag-options"&gt;utilized&lt;/a&gt; to issue an &lt;a href="http://api.stackexchange.com/docs/create-comment-flag"&gt;appropriate&lt;/a&gt; flag. Obviously, I don't want to flag good comments, but I do want to record them so that I can reuse the data in a later training step.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;What have the results of this experiment been? From my point of view, I'd venture that it's been successful. I have automatically flagged over 17,000 comments. As of December 17, 2014, the process has been running for 173 days. My comment flagging stats are currently:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;26885   comments flagged&lt;/span&gt;
&lt;span class="err"&gt;26714   deemed helpful&lt;/span&gt;
&lt;span class="err"&gt;171     declined&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Started at (approximately):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;9885    comments flagged&lt;/span&gt;
&lt;span class="err"&gt;9847    deemed helpful&lt;/span&gt;
&lt;span class="err"&gt;38      declined&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This gives me an overall accuracy of 99.36%. Down from 99.61% when no automated process was involved.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;There are pictures that help tell this story too. In this first one, we see that the rolling 10 day average for the number of declined flags has stayed below two flags a day. In October, there was a two week period where the rolling average was 0 and nearly a month long period where the system did not make any mistakes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Flags per day with rolling 10 day average" src="https://andrewwegner.com/images/flags_per_day_rolling_average.png"/&gt;&lt;/p&gt;
&lt;p&gt;Since November, the number of mistakes has climbed slightly. The biggest number of mistakes it has made was the opening day of Winter Bash 2014. Purely speculation, but I believe this was the moderators being protective of content and not wanting people to farm the &lt;a href="http://winterbash2014.stackexchange.com/resolution"&gt;Resolution hat&lt;/a&gt;. Of course, I don't know this. Another theory I have about this uptick since November is the adjustment to day light saving time. My process starts 10 minutes after UTC. It is possible that this earlier hour has caused my flags to be processed by a different moderator, or a moderator that is more awake/less hungry/in a different mood than previously at this point in the daily rotation cycle or because they &lt;a href="http://meta.stackexchange.com/a/215397/186281"&gt;lost their keys&lt;/a&gt; that day.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;img alt="Total flagged vs Total Declined" src="https://andrewwegner.com/images/total_flags_vs_total_declined.png"/&gt;&lt;/p&gt;
&lt;p&gt;Except for 3 days, since June 27th, the process has flagged 100 comments a day. In this chart, you can see the number of declined comment flags along the bottom.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;img alt="Number of comments saved per day" src="https://andrewwegner.com/images/comments_saved_per_day.png"/&gt;&lt;/p&gt;
&lt;p&gt;Finally, this chart shows the number of comments that the system wanted to act on (and a rolling 5 day average). When the system was brought online, it was acting on 700-800 comments a day (saving to my local database). Many of these were being classified as "Good Comments". You can see the day that I adjusted the threshold for "Good Comments" to be acted upon (saved). The drop in the number of comments the system saved is dramatic. Instead of saving 700-800 comments daily, the system now averages about 150 comments to save. Since I don't flag "Good Comments", I feel this is the appropriate action to take.&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="flagged-but-declined"&gt;Flagged but declined&lt;a class="headerlink" href="#flagged-but-declined" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As shown above, I've had comments flags declined. Some of these obviously should have been and required a retraining or threshold adjustment on my part. Others, in my opinion, should have been removed as noise. Below is a small sampling of both types of comments.&lt;/p&gt;
&lt;p&gt;Recent comments that I feel are noise:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27420526/i-want-to-play-from-frame-2-and-then-stop-at-frame-3/27425983#comment43388489_27425983"&gt;yes thank you so much for you help it works sorry for the late reply&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27476522/how-to-call-a-function-by-a-pointer/27476639#comment43387801_27476639"&gt;Wow it works. Thank you very much!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27284958/why-thread-id-creates-not-in-order/27285031#comment43038003_27285031"&gt;wow that works!Thanks so much for your advice!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27375504/remove-legends-for-each-point-and-keep-only-those-which-are-outliers-for-ggplot/27380631#comment43387125_27380631"&gt;Ok, the works great, thank you so much!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/14907518/modal-view-controllers-how-to-display-and-dismiss/14910469#comment43386201_14910469"&gt;Thank you very much for your explanation, you rock dude !!!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are some comments that were incorrectly flagged:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/18545905/meteor-without-mongo#comment42850716_18545905"&gt;@Spina: yes. Check my answer. You can simply point MONGO_URL to an invalid URL.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27007685/how-can-i-position-divs-at-the-bottom-of-container-div-and-inline/27007772#comment42544238_27007772"&gt;Sorry, my error. I was: "position", not "display". Check it: jsfiddle.net/hvfku99c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/26745185/multiple-spacebar-conditional-operators/26745790#comment42078870_26745790"&gt;I believe UI.registerHelper is, being deprecated. Please check my updated answer.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other comments are flagged but then edited prior to a moderator seeing the comment. The edit adds information to the post, thus the declination is justified:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27406267/neo4j-very-slowly-using-shortestpath#comment43271781_27406267"&gt;Yes, I have indexes. Let me show my schema&lt;/a&gt; was edited to the much more useful: &lt;code&gt;Yes, I have indexes for UUID and Permission. In fact rlationship is a variable length here (e)-[rp:Has_Pocket|Has_Document*0..]-&amp;gt;d&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/26535662/how-to-read-files-in-sequence-from-a-directory-in-opencv/26536198#comment41709286_26536198"&gt;Here is the question i had posted first using FIleStorage issue&lt;/a&gt; was edited to include the link to the referenced post.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's also worth noting that despite getting flags declined, some comments do eventually disappear. This is due to either flags raised by other community members putting the comment back in front of a moderator or by simply accumulating enough community flags for the system to act automatically. In either case, the desired result of removing noise has been accomplished.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27006363/node-js-parse-filename-from-url/27006555#comment42544432_27006555"&gt;Oh, derr. good point. Edited.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stackoverflow.com/questions/27073761/redefining-the-hitbox-of-objects/27073838#comment42659999_27073838"&gt;You're right! Hopefully you see my point anyways.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id="lessons-and-observations"&gt;Lessons and Observations&lt;a class="headerlink" href="#lessons-and-observations" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Replication to other sites would depend on site culture&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a (fairly) non-subjective site, Stack Overflow made a good test case for this. On a site like &lt;a href="http://communitybuilding.stackexchange.com/"&gt;Community Building&lt;/a&gt;, &lt;a href="http://pets.stackexchange.com/"&gt;Pets&lt;/a&gt;, &lt;a href="http://parenting.stackexchange.com/"&gt;Parenting&lt;/a&gt; or other site that accepts subjective answers, "too chatty" would be much harder to classify.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://meta.stackoverflow.com/q/277314/189134"&gt;+/-1 has been discouraged&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The observation I made on my own that comments with this type of content were distracting has been noticed by others as well. This was actually a very nice validation of my own process and some of the &lt;a href="https://stackedit.io/viewer#!provider=gist&amp;amp;gistId=af9d8186690cb658aafe&amp;amp;filename=commentblacklistresults.md"&gt;results&lt;/a&gt; posted on that thread show many such comments continue to be noise. Of course, this change did also force users to modify their content and may have added new patterns that can be utilized in future training.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ability to &lt;a href="http://meta.stackexchange.com/q/245416/186281"&gt;automatically check flags&lt;/a&gt; would be great so that automated runs could be paused if it goes crazy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The process of checking that my flagging history remains accurate is time consuming. The status of a flag can't be acquired via the API. I've submitted a feature request for this information to be added to the API. With this information, flagging can be paused or stopped if X number of flags are declined.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stack Overflow's volume of comments is a crutch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Due to the &lt;a href="http://data.stackexchange.com/stackoverflow/query/200435#graph"&gt;high volume of comments&lt;/a&gt; and limited number of comment flags my account has available, I can afford to be picky on which comments I want to act on. The classifier itself is about 85% accurate in determining the type of comment. However, I artificially increase my accuracy by only acting on comments that have a very high classifier certainty by forcing this certainty level to meet or surpass my threshold values from above. Smaller sites, with a lower volume, don't have the benefit of having enough comments to be this picky. It is on these sites that a more feature based classifier would be important.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The human element is still unpredictable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My classifier was trained utilizing my idea of how comments should be flagged. Prior to automating this, I was not 100% accurate. Additionally, moderators are not 100% accurate in their processing of flags. &lt;a href="http://meta.stackoverflow.com/q/278813/189134"&gt;Users&lt;/a&gt; &lt;a href="http://meta.stackoverflow.com/q/280426/189134"&gt;disagree&lt;/a&gt; on how these rules should be implemented, but are willing to &lt;a href="http://meta.stackoverflow.com/q/278927/189134"&gt;assist&lt;/a&gt; in keeping the site clean. With more than 175K comments a week, every little bit helps.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="discussion"&gt;Discussion&lt;a class="headerlink" href="#discussion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As my title states, my original question was whether or not I can teach a machine how to flag comments as I would. The answer to that is yes. The next question is whether this type of system would be helpful in cleaning up comments across Stack Overflow. My system works only on new comments created around each new UTC. Once my 100 flags are hit (or the API tells me to stop), it shuts down for the day. Having something automated go through historical comments or that can run all day would be beneficial.&lt;/p&gt;
&lt;p&gt;Finally, now that I've admitted that I've been automatically flagging comments, can I continue to do so?&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="update"&gt;Update&lt;a class="headerlink" href="#update" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section has been updated multiple times since the original post. Most recently, it was updated May 3, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned in the introduction, this was originally published in December 2014. How is the system behaving now? It is performing very well.&lt;/p&gt;
&lt;h3 id="process-changes"&gt;Process Changes&lt;a class="headerlink" href="#process-changes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In January 2015, &lt;a href="http://meta.stackoverflow.com/q/283030/189134"&gt;another user&lt;/a&gt; was using a basic query to look for invalid comments. This caused a high number of moderator flags, many of which were declined. My process was caught in this mass decline. This resulted in 49 declined flags for a single day.
This is, by far, the largest number of declined flags the process has generated in a day. It did, however, prompt a process change after consultation with the Stack Overflow moderators.&lt;/p&gt;
&lt;p&gt;The process will no longer flag comments newer than 48 hours old. This provides users with a two day window to see a comment before the system will flag it. This single change has provided a huge improvement in terms of flag acceptance.&lt;/p&gt;
&lt;h3 id="may-2015-11-months"&gt;May 2015 (11 Months)&lt;a class="headerlink" href="#may-2015-11-months" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After nearly a year of running, these are my flagging statistics:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;39938   comments flagged&lt;/span&gt;
&lt;span class="err"&gt;39659   deemed helpful&lt;/span&gt;
&lt;span class="err"&gt;279     declined&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This provides a helpful rate of 99.3%. This is down &lt;em&gt;just&lt;/em&gt; slightly from 99.36% in December. I attribute a large part of the dip to the issue mentioned above.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;img alt="Flags per day with rolling 10 day average" src="https://andrewwegner.com/images/latest_flags_per_day_rolling_average.png"/&gt;&lt;/p&gt;
&lt;p&gt;Here is an updated chart showing the rolling 10 day average for number of declined flags. I've had several stretches of multi-week time frames with no declined flags.&lt;/p&gt;
&lt;p&gt;This is a busy chart, so I've narrowed it down to show just the last 90 days. From here you can see that in the past 90 days there have been only 10 declined flags.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Flags per day with rolling 10 day average - 90 day window" src="https://andrewwegner.com/images/latest_flags_per_day_rolling_average_90day_window.png"/&gt;&lt;/p&gt;
&lt;h3 id="sept-2015-15-months"&gt;Sept 2015 (15 Months)&lt;a class="headerlink" href="#sept-2015-15-months" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It has been almost 15 months since the process started. In that time, the model has gotten more accurate. Since the last update in May, I've had only 3 declined comment flags:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;52351   comments flagged&lt;/span&gt;
&lt;span class="err"&gt;52069   deemed helpful&lt;/span&gt;
&lt;span class="err"&gt;282     declined&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This provides a helpful rate of 99.46%. Here is an updated chart showing the rolling 10 day average for number of declined flags. The 90 day window is not even worth showing. It has three days where a single flag was declined.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Flags per day with rolling 10 day average - 15 Months of data training" src="https://andrewwegner.com/images/declined_per_day_15_months.png"/&gt;&lt;/p&gt;
&lt;h3 id="summary-of-2015"&gt;Summary of 2015&lt;a class="headerlink" href="#summary-of-2015" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I processed comments 359 days out of the year. I missed three in January due to stopping it after a mass decline of flags (more later), I can't account for a missed day in July and August. I don't recall stopping it, but I missed July 3rd and August 19. I also missed December 28th due to a power issue. I flagged 35,960 comments. Of that, 111 were declined.&lt;/p&gt;
&lt;p&gt;By month, this is the break down of rejected flags.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2015 Flag Summary" src="https://andrewwegner.com/images/2015-flag-summary.png"/&gt;&lt;/p&gt;
&lt;p&gt;The blip at the end of November is due to new moderators being elected and adjusting to what other moderators consider "good" versus "bad" comments. I didn't see the spike in the April election which is interesting, but after a couple days in November it's back to normal. The January spike I mentioned above. &lt;/p&gt;
&lt;p&gt;Interesting note: The longest stretch in the year with no declined flags was from August 13th through November 24th.&lt;/p&gt;</content><category term="Stack Exchange"></category><category term="machine learning"></category><category term="automation"></category><category term="programming"></category></entry><entry><title>Moderation postion on Moderators</title><link href="https://andrewwegner.com/moderation-postion-on-moderators.html" rel="alternate"></link><published>2014-07-02T10:51:00-05:00</published><updated>2014-12-04T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2014-07-02:/moderation-postion-on-moderators.html</id><summary type="html">&lt;p&gt;I've thrown my hat into the ring for a moderation position on Stack Exchange's newest site: Moderators&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been the owner of Vipers for almost 5 years. In that time I've help the community grown and get stronger. I've helped
members begin their own communities and I've maintained the game servers the players utilize 24 hours a day. I've been 
concerned about low activity, excited about new events and updates, and watched the community ebb and flow through out
the years. I've dealt with trolls, spammers, and new community members. I think I've gained valuable experience in 
managing a community.&lt;/p&gt;
&lt;p&gt;I'm also a member on &lt;a href="http://stackoverflow.com/users/189134/andy"&gt;Stack Overflow&lt;/a&gt; and over the years gotten to know others that enjoy the "Meta" aspect of 
Stack Exchange. That's the "behind the scenes", "how does this site work?" discussions and activities. &lt;/p&gt;
&lt;h2 id="moderators"&gt;Moderators&lt;a class="headerlink" href="#moderators" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;A few days ago, I found a way to merge my experience with Vipers and the knowledge of the Stack Exchange platform. A new 
community started recently: &lt;a href="http://moderators.stackexchange.com"&gt;Moderators&lt;/a&gt;. The idea behind this site is for people building, administering, managing or
cultivating digital communities to have a place to ask others with similar experiences questions. I love it!&lt;/p&gt;
&lt;p&gt;One of the things a new site needs on the Stack Exchange network is a set of pro tempore moderators. While Stack Exchange 
believe in &lt;a href="http://blog.stackoverflow.com/2009/05/a-theory-of-moderation/"&gt;community moderation&lt;/a&gt;, there are still some things that require more access. These pro tempore moderators
are those people. I &lt;a href="http://meta.communitybuilding.stackexchange.com/a/80/78"&gt;nominated&lt;/a&gt; myself for one such position.&lt;/p&gt;
&lt;h3 id="the-nomination"&gt;The Nomination&lt;a class="headerlink" href="#the-nomination" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This is the nomination I presented to the community. In it, I discuss my experience with Vipers and some of our challenges.
One in particular that I mention is the &lt;a href="https://andrewwegner.com/monitoring-language-on-the-game-servers.html"&gt;automated language filter&lt;/a&gt; we have on the game servers.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I am an administrator/site owner of a medium sized gaming community that runs on a PHPBB3 board. We host multiple game 
servers as well. I've got a team of moderators that help keep the forum and game servers clean. I've run this site for 
5 years, after taking it over from the original creator of the community who wanted to move on. In my time as admin, 
we've seen the number of participants on the forum increase. We've seen our game server population increase as well. 
I attribute this to getting the community involved in change discussions.&lt;/p&gt;
&lt;p&gt;One of our biggest changes occurred several years ago. Community members complained that our game servers would be over 
run with trolls at hours when moderators weren't available and spewing filth. The community wanted a cleaner game 
server experience. Users wanted these players gone immediately. Previous community leaders felt that trolling of this 
kind was part of the game and did nothing. After some discussions regarding what was and wasn't appropriate, we decided 
to be (for lack of a better term) "family friendlier". Certain 'extreme' phrases were no longer tolerated at all. A 
technical solution was built to automatically remove players that violated these rules. This solution allowed users to 
swear, but once it became excessive (again, defined by the community) they, too, were removed.&lt;/p&gt;
&lt;p&gt;The tool we have (PHPBB3) may not have the reputation, badges, or increasing privileges used here on Stack Exchange but 
for my community that has not been a negative. Engaging with the community in discussions and letting the members provide 
input that me and my team utilize has been extremely beneficial.&lt;/p&gt;
&lt;p&gt;I have no experience moderating a Stack Exchange site. I don't feel that's a down side though. I can provide the 
"outside" perspective in a Stack Exchange heavy group. That does mean, though, that I'd depend on and expect the 
community to provide feedback on how moderation in being handled. Much like my existing gaming community, input from the 
community to the moderation team is important and the moderation team should be listening to that input. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="appointment"&gt;Appointment&lt;a class="headerlink" href="#appointment" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Updated on August 12, 2014&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I have been &lt;a href="http://meta.communitybuilding.stackexchange.com/q/138/78"&gt;appointed&lt;/a&gt; to a moderator position on Moderators. I now "moderator the moderators", as the running joke 
has been on meta and the chatroom. I am looking forward to helping this community grow and to providing my experience 
of community management outside of Stack Exchange to this position.&lt;/p&gt;
&lt;h2 id="renaming-to-community-building"&gt;Renaming to Community Building&lt;a class="headerlink" href="#renaming-to-community-building" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated on December 4, 2014&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Almost since the beginning of Moderators, there have been conversations about whether the name is limiting our scope. We aren't
a community for &lt;em&gt;only&lt;/em&gt; moderation questions. We are a community about how to build communities and moderation happens to
be a part of community building. (How many times can you say "community" before it sounds weird?)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://meta.communitybuilding.stackexchange.com/q/140/78"&gt;Discussions&lt;/a&gt; began in August about possible name changes. These &lt;a href="http://meta.communitybuilding.stackexchange.com/q/175/78"&gt;discussions&lt;/a&gt; continued into October as we worked on
the &lt;a href="http://meta.communitybuilding.stackexchange.com/q/172/78"&gt;scope&lt;/a&gt; of our site. Finally, on December 2, we received our new name: &lt;a href="http://meta.communitybuilding.stackexchange.com/q/193/78"&gt;Community Building&lt;/a&gt;. It's the same great site
but with a much more relevant name. &lt;/p&gt;</content><category term="Stack Exchange"></category><category term="moderation"></category></entry><entry><title>How to appeal a ban effectively</title><link href="https://andrewwegner.com/how-to-appeal-a-ban-effectively.html" rel="alternate"></link><published>2014-04-22T22:26:00-05:00</published><updated>2014-04-22T22:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2014-04-22:/how-to-appeal-a-ban-effectively.html</id><summary type="html">&lt;p&gt;Following up on last week's post about improper ways to appeal, this post shows effective appeals and why they worked&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In &lt;a href="https://andrewwegner.com/how-not-to-appeal-a-ban.html"&gt;last week's post&lt;/a&gt;, I showed three ways that appealing bans on the Vipers forums would fail. Everyone makes mistakes
and we try to recognize that when someone comes to the forums and makes a good appeal. We usually offer an unadvertised 
"last chance". This is the chance to prove you've changed. If you fail, you are gone for good. If, however, you have changed
behaviors, this allows you to play on the Vipers servers again. To get this chance though, you have to make an appeal.&lt;/p&gt;
&lt;h2 id="super-secret-formula-for-getting-unbanned"&gt;Super secret formula for getting unbanned&lt;a class="headerlink" href="#super-secret-formula-for-getting-unbanned" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The secret to a successful appeal is to do all of the following in your appeal thread:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Post in complete sentences, using mostly correct english. I'm not going to mark you off for simple spelling mistakes, but
 I'm not going to read your post if it looks like you typed it from your phone to your teenage buddy. &lt;/li&gt;
&lt;li&gt;Stay polite. If you lose your cool, it's much less likely we are going to want to work with you. Remember, this is a game.
 You not being able to play on one server is not the end of the world. &lt;/li&gt;
&lt;li&gt;Explain why you think your ban was inappropriate. Make this short and to the point. &lt;/li&gt;
&lt;li&gt;Don't lie. I have logs. I know how to read logs. I even have ways of quickly searching through the logs for specific
 times, if you provide that information. If your story doesn't match what I see in the logs, I'm not going to engage with you.&lt;/li&gt;
&lt;li&gt;Answer questions from the admins. It's entirely possible you didn't provide a crucial bit of information or we need to 
 wait for input from the banning admin. In either case, if an administrator asks you a question, you should probably answer
 it. When you do so, follow the first two bullet points above. &lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The sad thing is most of the appeals fail at step 1. These posts are to facilitate communication between the admin team
and the player that wants to return to the server. In these appeals I try to educate a player on &lt;em&gt;why&lt;/em&gt; they were banned 
in the first place. If it's difficult to understand what is being said, it's very hard to have this conversation.&lt;/p&gt;</content><category term="team vipers"></category><category term="moderation"></category></entry><entry><title>How NOT to appeal a ban</title><link href="https://andrewwegner.com/how-not-to-appeal-a-ban.html" rel="alternate"></link><published>2014-04-14T22:26:00-05:00</published><updated>2014-04-14T22:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2014-04-14:/how-not-to-appeal-a-ban.html</id><summary type="html">&lt;p&gt;I'm reasonable. The other Vipers admins are reasonable. We'll listen to your ban appeal, unless you do some of this...&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been running Vipers for about four and a half years. In that time I've seen my share of players get banned. The "good"
ones realize they screwed up and come back when the ban has expired and never have an issue again. These types of players
are common if they are first time offenders. The minute someone gets a second ban, the likelihood of them getting another
ban shoots way up.&lt;/p&gt;
&lt;h2 id="our-rules"&gt;Our Rules&lt;a class="headerlink" href="#our-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Vipers has five very simple rules. These are presented every time someone joins any of our game servers. They have to
click "Continue" to move past them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Vipers Rules" src="https://andrewwegner.com/images/vipers-rules.png"/&gt;&lt;/p&gt;
&lt;p&gt;We have a very simple structure for how bans work. Unless you are incredibly egregious in your behavior, or are out right
cheating by using hacks of some kind, you get a 4 strike policy. The ban length for the first three increases for each, but you
are allowed back. On the forth, we show you the door. Most of our bans are &lt;a href="https://andrewwegner.com/monitoring-language-on-the-game-servers.html"&gt;automated&lt;/a&gt;, thus are violating the very first rule.&lt;/p&gt;
&lt;h2 id="bad-appeals"&gt;Bad appeals&lt;a class="headerlink" href="#bad-appeals" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Playing on our servers is not a right. It is not a guarantee. We are not obligated to provide a gaming environment for you
to spew your filth. If you can't meet our simple rules, you can leave. If you want to get back into the servers after your
forth offense, you have to come to us and ask. You should think about how you get someone to do what you want in "the
 real world".&lt;/p&gt;
&lt;h3 id="method-1-freedom-of-speech"&gt;Method 1: Freedom of Speech&lt;a class="headerlink" href="#method-1-freedom-of-speech" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I think this one is my favorite. Last I checked, I'm not the government of the United States. I'm a private citizen providing
a private server for others to play on. My server, my rules (technically, the community's rules, but you understand...)
I am not bound by the First Amendment to allow you to say whatever you want.&lt;/p&gt;
&lt;p&gt;An example:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Freedom of speech appeal" src="https://andrewwegner.com/images/vipers-speech-appeal-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Let's break down some of the flaws:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, and most importantly, we do not have a member named "DarkWolf", let alone an admin&lt;/li&gt;
&lt;li&gt;DarkWolf was banned, automatically, 2 minutes prior to the person making this appeal.&lt;/li&gt;
&lt;li&gt;The chat logs show that the person appealing even noticed the ban and made a comment. It was this comment that
 triggered the ban.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not seen in this image is the response when this was pointed out and the appeal denied. The response managed to hit all
of the trigger words we ban for on the servers. Just in case we were reconsidering the denial, at this point we're not.&lt;/p&gt;
&lt;h3 id="method-2-admin-abuse"&gt;Method 2: Admin Abuse&lt;a class="headerlink" href="#method-2-admin-abuse" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Admins are evil and are holding a grudge! They hate me and ban for inappropriate language. Honest, I never said anything bad.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's amazing how quickly that tune changes when I can produce exact, timestamped, logs with their Steam ID attached to it. It's even
more amusing when the admin being accused is "Zephyr", the automated process that watches for such language.&lt;/p&gt;
&lt;p&gt;An example:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Admin abuse appeal" src="https://andrewwegner.com/images/vipers-abuse-appeal-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Let's break down this one too:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Zephyr is a bot. It is not holding a grudge and it is not stalking you&lt;/li&gt;
&lt;li&gt;Swearing, unless very very excessive, isn't going to trigger a ban&lt;/li&gt;
&lt;li&gt;Chat logs show this is the 4th automated ban. In each ban, the user has managed to slip in multiple offensive phrases
 before being automatically kicked&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="method-3-ranting"&gt;Method 3: Ranting&lt;a class="headerlink" href="#method-3-ranting" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A rant isn't helpful to anyone. It doesn't endear the poster to the community. The administrators don't want to read through
a rambling, unformated, exposition.&lt;/p&gt;
&lt;p&gt;An example:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Rant appeal" src="https://andrewwegner.com/images/vipers-rant-appeal-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Our break down:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Several logic errors and contradictions to their own arguments&lt;/li&gt;
&lt;li&gt;Doesn't actually mention they are looking to be unbanned, just that they want to complain about the rules. (It's mentioned
 in a later post that they'd like to be unbanned)&lt;/li&gt;
&lt;li&gt;Chat logs clearly indicate the player was fond of certain slurs. This is the reason for the bans&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="method-4-threats-to-the-server"&gt;Method 4: Threats to the server&lt;a class="headerlink" href="#method-4-threats-to-the-server" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Threats to attack the server in some way are not going to get you unbanned. There are only two possible outcomes to this
appeal type. Either you are successful and the server is off line (now how are you going to play even if unbanned) or we
ignore your tantrum and leave you banned.&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDOS appeal" src="https://andrewwegner.com/images/vipers-ddos-appeal-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Break down:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I have no reason to unban you. You've threatened the servers and made an ultimatum that effectively holds us hostage:
 "Either I get to play with you, or I'll take down your servers".&lt;/li&gt;
&lt;li&gt;You offer no proof of your claims (unsurprisingly, none existed)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;h2 id="summary"&gt;Summary&lt;a class="headerlink" href="#summary" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Above I've posted three of the most common methods people use to appeal their ban on the Viper servers. Every time one of
these types of appeals is posted, it is rejected and the player is told they aren't welcome. All I (and the community) ask
is a little bit of respect. You've already proven that you can't follow our rules if we reach this point. If you have truly
changed, why don't you demonstrate some of that change while requesting the ban be removed.&lt;/p&gt;</content><category term="team vipers"></category><category term="moderation"></category></entry><entry><title>Mann Vs Vipers Beaten!</title><link href="https://andrewwegner.com/mann-vs-vipers-beaten.html" rel="alternate"></link><published>2013-12-05T09:00:00-06:00</published><updated>2013-12-05T09:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2013-12-05:/mann-vs-vipers-beaten.html</id><summary type="html">&lt;p&gt;It took months and endless hours of trying, but it's been done. Wave 9 has been beaten.&lt;/p&gt;</summary><content type="html">&lt;p&gt;The Team Vipers' Mann Vs Machine modification - Mann Vs Vipers - that was completed in August has finally been beaten. 
Last night a starving group of players finally put down Wave 9. &lt;/p&gt;
&lt;p&gt;The players were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MooMooCow&lt;/li&gt;
&lt;li&gt;CutieVamp&lt;/li&gt;
&lt;li&gt;Batman&lt;/li&gt;
&lt;li&gt;Starfox&lt;/li&gt;
&lt;li&gt;Healthy Cyanide&lt;/li&gt;
&lt;li&gt;Zhiv&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The team struggled against the Admin bots - InsaneMosquito, Venom and SchooledYa. I've been told we are terrifying to play
against and making us MvM bots with even higher stats made it even more terrifying. (I approve.)&lt;/p&gt;
&lt;p&gt;Here's a video of Wave 9 from the victory. The winning strategy appears to be the one that works against us most of the time. 
Separate the medic (me), from the Heavy (Venom) and the Soldier (SchooledYa). Together, we're hard to stop, but apart we
can each be picked on for a while until there is no health left. The bots must have learned that weakness as well (I don't approve.)&lt;/p&gt;
&lt;p&gt;Congratulations to the winners!&lt;/p&gt;
&lt;p&gt;
&lt;iframe allowfullscreen="true" frameborder="0" height="315" src="//www.youtube.com/embed/PIpd2SInvYM" width="560"&gt;&lt;/iframe&gt;
&lt;/p&gt;</content><category term="team vipers"></category><category term="community"></category></entry><entry><title>I had a secret addiction to the TF2 idling economy but I'm better now (honest)</title><link href="https://andrewwegner.com/i-had-a-secret-addiction-to-the-tf2-idling-economy-but-i'm-better-now-(honest).html" rel="alternate"></link><published>2013-08-13T00:01:00-05:00</published><updated>2013-08-13T00:01:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2013-08-13:/i-had-a-secret-addiction-to-the-tf2-idling-economy-but-i'm-better-now-(honest).html</id><summary type="html">&lt;p&gt;Hi everyone, I'm Andy, and I used to idle.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On July 11, 2013, Valve released a &lt;a href="http://www.teamfortress.com/post.php?id=11105"&gt;patch&lt;/a&gt; to Team Fortress 2 to limit idling. Idling is the process of launching
Team Fortress and then letting it run for a few hours and collecting item drops. It used to be simple to do by utilizing
the &lt;code&gt;-textmode&lt;/code&gt; &lt;a href="https://developer.valvesoftware.com/wiki/Command_Line_Options#Command-line_parameters_2"&gt;game parameter&lt;/a&gt;. This would "launch" the game without graphics. From there, you just let it run and
come back in a few hours with 8-10 new items (your weekly limit).&lt;/p&gt;
&lt;p&gt;The idea behind this was to then trade or craft these into metal. The metal could be used to trade for keys, hats, etc. and
all you to be "rich". The quotes are there because I do realize that being rich in a virtual game does not make one rich in
the real world. But, since the &lt;a href="https://wiki.teamfortress.com/wiki/Mann-Conomy_Update"&gt;Mann-Conomy Update&lt;/a&gt; introduced this massive meta game to Team Fortress, I've tried to stay
out of it.&lt;/p&gt;
&lt;p&gt;I failed. I didn't just idle one account. I idled 17 accounts. That is between 136 and 170 items a week. That's between 68 to 85
scrap metal a week. That's between 7.55 and 9.44 refined metal a week. That is between 3 and 4 keys a week (depending on
who I trade with). Keys are the backbone of the economy. Get enough of those and you can trade for anything else.&lt;/p&gt;
&lt;p&gt;I honestly don't know what my goal was. I wasn't interested in the fancy hats (ooooh...shiny pixels). I didn't open crates
with the keys. I did utilize the keys to get &lt;a href="https://wiki.teamfortress.com/wiki/Tour_of_Duty_Ticket"&gt;Tour of Duty&lt;/a&gt; tickets for me and some friends. That's honorable, right?&lt;/p&gt;
&lt;h2 id="how-did-this-happen"&gt;How did this happen?&lt;a class="headerlink" href="#how-did-this-happen" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This all started with &lt;a href="https://andrewwegner.com/give-some-refined-win-some-prizes.html"&gt;the bot I built for Vipers to handle the raffles&lt;/a&gt;. I realized that I could automate much more
than trading with players. I could automate trading between bots. I could automate &lt;em&gt;crafting&lt;/em&gt; - which is relatively time
consuming, especially when you have 136 items to go through. I could automate trading with established scrap bank bots. These
bots will take any two weapon drops and give you one scrap, even if the two items can't be crafted together. The idea is
that they get enough weapons that eventually they'll be able to craft it down to metal.&lt;/p&gt;
&lt;h3 id="the-set-up"&gt;The set up&lt;a class="headerlink" href="#the-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To idle 17 accounts I needed to figure out what my computer could handle. I had to figure out how to run multiple instances
of Steam and Team Fortress at a time. Enter an application I'd utilized before: &lt;a href="http://www.sandboxie.com/"&gt;Sandboxie&lt;/a&gt;. This application provides
isolated sandboxes for applications to run in. Normally Steam won't run more than once on a machine. But, if you launch
it via Sandboxie, the host OS (and other Sandboxie environments) can't see that Steam is running in another instance.&lt;/p&gt;
&lt;p&gt;A bit of experimentation showed that I could handle 6 accounts idling at a time and have the computer remain just barely
usable. I created new accounts and split them into which day of the week they'd be run. I had three days out of the week
designated for idling.&lt;/p&gt;
&lt;p&gt;A batch script was built to launch the Sandboxie environments of the day that was to idle. Then it'd launch Team Fortress
in each of those environments. Then I'd go to bed. When I woke up the next morning, I'd shut down the environments. I'd
repeat this for two more nights. At the end of the third night, I had all the items I could get for the week.&lt;/p&gt;
&lt;p&gt;Accounts could not be free accounts. This meant that I needed to either buy an item for each account, or trade for an
&lt;a href="https://wiki.teamfortress.com/wiki/Upgrade_to_Premium_Gift"&gt;"Upgrade to Premium Gift"&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="getting-items-to-a-single-account"&gt;Getting items to a single account&lt;a class="headerlink" href="#getting-items-to-a-single-account" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next step in the process was to convert all the items to metal. Normally, this would take place by either logging into
each account and crafting there and then trading everything to a master account, or trading everything first then crafting.
In either case, 17 accounts is a lot to handle and trading/crafting is rather boring.&lt;/p&gt;
&lt;p&gt;My solution was to modify the raffle bot. I'd designate one account as a master account. This would be the account that
received items. All others would dump items to it. I'd log into the account that was receiving items and initiate a trade
with each other bot in turn. I'd issue a command &lt;code&gt;add all&lt;/code&gt; and that bot would dump it's inventory into trade. Making it
through all the bots would take 5 minutes. Previously it would take me an hour or more to log into each account and
manually add items to the trade windows and then confirm the trade on both sides. &lt;em&gt;yawn&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="crafting"&gt;Crafting&lt;a class="headerlink" href="#crafting" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The next step was crafting items to metal. The rule was that any two weapons utilized by the same class could be
crafted to scrap metal. That sounds simple enough.&lt;/p&gt;
&lt;p&gt;After lots of trial and error, I'd built a set of commands that would select compatible weapons and craft them together. This
particular aspect wasn't documented by Steam (or the reverse engineered SteamKit2 library I was utilizing). Crafting would
take about 15 seconds to get all compatible items to scrap and then combining 9 scrap to get a refined metal. This saved
inventory space.&lt;/p&gt;
&lt;p&gt;With the simple command &lt;code&gt;craftall&lt;/code&gt;, all those new weapons would be crafted into metal and then combined into refined metal. This
would be done in less than a minute. Previously, I'd have to initiate each crafting session, add all items per craft, wait for the
craft to complete and then repeat. This was another 15-30 minutes saved.&lt;/p&gt;
&lt;h3 id="left-overs"&gt;Left overs&lt;a class="headerlink" href="#left-overs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After crafting, there would still be left over weapons. There were weapons that had run out of same class items to craft
with. The solution was to trade these away in groups of two to &lt;a href="http://scrapbank.me/"&gt;ScrapBank.me&lt;/a&gt; and get scrap metal back. This could be
further combined to refined metal again wasting space.&lt;/p&gt;
&lt;h3 id="metal-to-keys"&gt;Metal to Keys&lt;a class="headerlink" href="#metal-to-keys" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;At this point, human intervention was required again. I had to convert my metal to keys. I did this via trading. The easy
way to do this was to find someone running a keybot, that would take metal for a key. Many exist, but all of them overcharge.
The other option was to look for a trader that was getting rid of a bulk set of keys and then trade them. In either case,
I'd end the week with 3-4 keys. I'd trade these for Tour of Duty tickets and go play a game with friends.&lt;/p&gt;
&lt;p&gt;The actual work required on my part was starting the idling for the night, shutting down idling in the morning, starting
the automated trade, crafting and trade left overs processes and finally trading metal for keys. What used to take me hours
to do each week, I could not do in less than an hour (the bulk of which ended up being trading metal for keys).&lt;/p&gt;
&lt;h2 id="what-changed"&gt;What changed?&lt;a class="headerlink" href="#what-changed" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Valve released a patch to limit how effective idling was. Their "Mann-Conomy" was seeing rapid inflation. The price of
keys (which they sold for physical money) in metal was rapidly increasing. From the time I started this to the time I ended
it, it jumped from 2-3 refined per key to 9-10 per key, with no sign of stopping. Casual players were complaining they couldn't
get enough items to trade for this stuff. The patch also required that you click to confirm each new received item.&lt;/p&gt;
&lt;h2 id="im-ok-honest"&gt;I'm ok. Honest.&lt;a class="headerlink" href="#im-ok-honest" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I tried for a few days to find an effective work around. I didn't. When I wasn't able to find one, I transferred all items
to the master account and went through the process of converting to keys. With that, I purchased the final set of
Tour of Duty tickets. The idle bots were shut down.&lt;/p&gt;
&lt;p&gt;It's been a month now. The bots are still down. I'm still around. Looking back on this, I'm happy Valve broke this. It wasn't
doing anything for me other than providing me with something to do: "Need to idle tonight", "Need to craft and trade today", etc.
Now I have that time back.&lt;/p&gt;
&lt;p&gt;I am pleased with the technical challenges I over came to get this done though. Crafting was the biggest, but I think I'm
most proud of the automated transfer of items to the master. Since the bots had to communicate via Steam and not via
a local application, working out how I was going to do that took some time.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;That, my friends, was my addiction to the meta game of a hat simulator in a first person shooter. I'm over it now and
looking forward to some other project.&lt;/p&gt;</content><category term="automation"></category><category term="programming"></category><category term="gaming"></category></entry><entry><title>Give some refined, Win some prizes</title><link href="https://andrewwegner.com/give-some-refined-win-some-prizes.html" rel="alternate"></link><published>2013-02-25T09:00:00-06:00</published><updated>2013-04-03T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2013-02-25:/give-some-refined-win-some-prizes.html</id><summary type="html">&lt;p&gt;The new raffle bot is introduced to the community&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Financially, Vipers is supported by donations from the community. When the community doesn't cover the cost, I end up
covering the difference. This isn't my favorite thing to do in the world, but we've been pretty successful in the past. 
In recent months, though, we've been coming up short more frequently. This has motivated me (and the rest of the admin
team to find ways to cover costs). Now we have one.&lt;/p&gt;
&lt;h2 id="welcome-to-the-new-raffle-bot"&gt;Welcome to the new raffle bot&lt;a class="headerlink" href="#welcome-to-the-new-raffle-bot" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've built a Raffle bot based on &lt;a href="https://github.com/Jessecar96/SteamBot"&gt;SteamBot&lt;/a&gt;, which is the base of &lt;a href="https://scrap.tf/"&gt;scrap.tf&lt;/a&gt;. Entries to raffles will be one entry 
per refined metal. You can have an unlimited number of entries. I will convert the refined metal to various prizes 
(with the goal being keys most of the time).&lt;/p&gt;
&lt;p&gt;Then we'll have the system select a set of winners from the entries. A user can only win once per raffle, so even if you you
have a gigantic number of entries, your odds of winning more than one position are zero. Only one win per steam id.&lt;/p&gt;
&lt;p&gt;Using the prices from &lt;a href="http://backpack.tf/"&gt;backpack.tf&lt;/a&gt;, the bot will determine the "value" of the items within the trade.&lt;/p&gt;
&lt;h2 id="how-does-this-off-set-costs"&gt;How does this off set costs?&lt;a class="headerlink" href="#how-does-this-off-set-costs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Items that are received that are of high value or any additional keys we can get based on raffle entries will be sold on 
various TF2 trading markets. The profits from these trades will be used to cover some community costs.&lt;/p&gt;
&lt;h2 id="keep-high-value-items-for-future-raffles"&gt;Keep high value items for future raffles?&lt;a class="headerlink" href="#keep-high-value-items-for-future-raffles" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This question was added based on feed back from the community. It was added on March 20, 2013&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The original plan was to sell any such items. However, due to community feedback, I've changed my mind. We will utilize 
"high value" items as prizes for future raffles. These future raffles will not be announced until any running raffles are 
complete. It is also possible that such a raffle will run separately from the planned monthly ones.&lt;/p&gt;
&lt;h2 id="our-first-winners"&gt;Our first winners&lt;a class="headerlink" href="#our-first-winners" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated on April 3, 2013&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Our first raffle completed at Midnight on April 1st. I was surprised by the number of entries we received. I'm even more 
surprised that the second one has begun and is already three quarters of the way to the number of entries it took a month
to receive. People want those keys, and I saw mention of those Bill's Hats too.&lt;/p&gt;
&lt;p&gt;The number of entries we received allowed us to completely cover the community costs that donations didn't cover. Thank
you to all our players that entered!&lt;/p&gt;
&lt;p&gt;Our first winners are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Cashprizes: Winner of 10 keys&lt;/li&gt;
&lt;li&gt;Popinfresh: Winner of 7 keys&lt;/li&gt;
&lt;li&gt;Iamthebaron: Winner of 4 refined metal&lt;/li&gt;
&lt;li&gt;That Guy From That Thing: Winner of 1 refined metal&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="First Raffle Bot Entries and Winners" src="https://andrewwegner.com/images/rafflebot-entries.png"/&gt; &lt;/p&gt;</content><category term="team vipers"></category><category term="automation"></category><category term="community"></category><category term="programming"></category></entry><entry><title>Homing projectiles are awesome!</title><link href="https://andrewwegner.com/homing-projectiles-are-awesome!.html" rel="alternate"></link><published>2012-06-30T08:02:00-05:00</published><updated>2015-05-20T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2012-06-30:/homing-projectiles-are-awesome!.html</id><summary type="html">&lt;p&gt;Pyro is an under utilized class on the Crit server. This post explains how I've fixed that.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="stupid-soldier-spam"&gt;Stupid soldier spam&lt;a class="headerlink" href="#stupid-soldier-spam" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The appeal of the crit server is fast game play, overpowered shots, and nearly instant death if you aren't paying attention.
The down side is the soldier spam. Lots of it. It's not unusual to have a team of soldiers spamming rockets. This is part
of the reason we stuck a class limit on Soldiers. &lt;/p&gt;
&lt;p&gt;Pyro is a common way to counter a soldier firing at long range. The problem with pyro is that it has limited long range weapons 
in return. Unless you can sneak up on an enemy (not easy with spam and some of the maps), the pyro is stuck taking pot shots
with either the Flare gun or the shotgun. &lt;/p&gt;
&lt;p&gt;Two weeks ago, I added a plugin to the server that made Pyro much more effective at helping the team without needing to advance 
to the front line constantly.&lt;/p&gt;
&lt;h2 id="reflectiles"&gt;Reflectiles&lt;a class="headerlink" href="#reflectiles" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Reflected Projectiles - Reflectiles, if you will - becoming homing projectiles when a Pyro air blasts them away. These
newly tracking projectiles will track an opposing team member and hunt them down. If the player being tracked dies before
the projectile hits them, the projectile will select a new target. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Well, that seems unfair. How do you defend against a homing projectile as a soldier?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is called &lt;strong&gt;Team&lt;/strong&gt; Fortress 2. You have team mates. Utilize them. That homing projectile can be reflected again by a Pyro
on your team. Each time a projectile is reflected it gets just a bit faster. &lt;/p&gt;
&lt;h2 id="source-code"&gt;Source Code&lt;a class="headerlink" href="#source-code" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated May 20, 2015 with link to GitHub instead of the old SVN, my apologies for missing that link when migrating to this blog
It is important to note that this version hasn't been updated in a LONG time but was still functioning when Vipers shut
down. If it doesn't work, the first thing to try is updating SourceMod's gamedata. This was the fix every other time
it didn't work&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The source code is released on Github. &lt;/p&gt;
&lt;p&gt;The repository is: &lt;a href="https://github.com/AWegnerGitHub/Vipers-Server-Plugins"&gt;https://github.com/AWegnerGitHub/Vipers-Server-Plugins&lt;/a&gt;&lt;/p&gt;</content><category term="team vipers"></category><category term="programming"></category></entry><entry><title>Monitoring Language on the game servers</title><link href="https://andrewwegner.com/monitoring-language-on-the-game-servers.html" rel="alternate"></link><published>2012-04-22T12:13:00-05:00</published><updated>2015-01-08T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2012-04-22:/monitoring-language-on-the-game-servers.html</id><summary type="html">&lt;p&gt;Team Vipers is proud of it's friendly atmosphere. This post describes how I automated a large part of the process&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My admin tool of choice for the TF2 servers is &lt;a href="http://www.hlsw.org/"&gt;HLSW&lt;/a&gt;. It's decent at allowing me to manage a server without ever
needing to log to the server. My biggest complaint about it is that I can only watch the game chat of one server at a time.
Sometimes, it's helpful to see an ongoing conversation to resolve minor problems before they become big ones. For example,
claims of "hacking" usually turn out to be completely baseless. But, if multiple users (and more importantly, multiple
&lt;em&gt;trusted&lt;/em&gt; users) suddenly start mentioning a hacker, I can step in and resolve the problem without entering the server.
HLSW is good for this. A hacker is confined to one server.&lt;/p&gt;
&lt;p&gt;The biggest problem is when there are reports of lag across all of the game servers. Vipers has a dedicated machine that
runs 5 game servers. If all five suddenly report lag, there is a problem somewhere. With HLSW, though, I can't see all of
the servers at once. Thus, I've built a tool...&lt;/p&gt;
&lt;h2 id="chat-monitor"&gt;Chat Monitor&lt;a class="headerlink" href="#chat-monitor" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All chat that occurs on the servers is logged. I've used this to resolve complaints of unfair bans and reports of hackers.
I built in a hook to these logs from the application template to quickly pull known aliases of users. It's been invaluable
in solving problems of "what happened" on the servers.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Multiserver Chat monitor" src="https://andrewwegner.com/images/vipers-chat-monitor.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've expanded it's usefulness. Now I can load a single page and see all chat activity occurring on all active game servers
on a single screen. It provides, at a glance, a quick way to see if there are problems on the servers. It also allows me
to step back from picking which server I think will be "bad" and monitor that. Now I can monitor all of them at once.&lt;/p&gt;
&lt;h2 id="inappropriate-words"&gt;Inappropriate words&lt;a class="headerlink" href="#inappropriate-words" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;As a community, we've chosen to set a higher standard for our players. As such, we have a restriction on a total of 3
words and a few derivatives of those words. This system is in place because the community stepped forward and wanted to
clean up the experience on the servers a bit. The problem with these higher standards is that we don't have admins on the
game servers (or watch chat logs) 24 hours a day. Thus, while admins sleep, a troll can wander through and spew garbage.
Unless a user reports this behavior, we will never be aware of it.&lt;/p&gt;
&lt;p&gt;I've built a system to handle this automatically. The system will monitor chat logs across all servers. If a user hits the
threshold for banning, they will be removed from the server and banned for a day. The logic to the system is this:&lt;/p&gt;
&lt;h3 id="automated-removal-logic"&gt;Automated removal logic&lt;a class="headerlink" href="#automated-removal-logic" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Inappropriate terms are configured with a "weight". This "weight" will be used to calculate whether or not a user
 surpasses a threshold set for being banned.&lt;/li&gt;
&lt;li&gt;System monitors chat logs for configured terms.&lt;/li&gt;
&lt;li&gt;If a term is found, the offending message is saved. The term weight is added to the user's current threshold value.
 If this is the user's first time saying one of these terms, they start at 0 and this weight is added.&lt;/li&gt;
&lt;li&gt;If user exceeds the threshold, the system issues a ban to Sourcebans. The user is then kicked from the game server.
 The ban length will be 1 day.&lt;/li&gt;
&lt;li&gt;The system keeps messages for a total of 5 minutes. If a message is older than that, the system forgets it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Currently, the three inappropriate terms all have a threshold of &lt;code&gt;1&lt;/code&gt;. This means they saying the words results in a ban.
Homophobic, racist remarks aren't welcome on the Viper servers. We can't prevent it, but we can deal with offenses swiftly.
The 5 minute window is added because the community requested that excessive swearing also be limited. We don't want to
outright ban it, but they don't want a swear filled rant to occur after every match.&lt;/p&gt;
&lt;p&gt;Thus, I built in the 5 minute window and the thresholds. The system is configured to catch common swear words, but the words
have a low weight. It'd take repeated spamming of the words in a 5 minute window to reach the threshold and be removed from
the server.&lt;/p&gt;
&lt;h3 id="updated-removal-logic"&gt;Updated removal logic&lt;a class="headerlink" href="#updated-removal-logic" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Updated May 17, 2012&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The automated system has been active for almost a month. I'm finding that the system has been removing the same set of
players every other day. They aren't learning. This is despite the message they are shown when removed from the server.
I've made a change to the logic in how long a ban will last. It provides a 4 strike system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First offence: Weight of term(s) said times 1. This means, for most cases, they are issued a single day ban.&lt;/li&gt;
&lt;li&gt;Second offence: Weight of term(s) said times 3. This means, for most cases, they are issued a three day ban.&lt;/li&gt;
&lt;li&gt;Third offence: Weight of terms said times 21. This means, for most cases, they are issued a three week ban.&lt;/li&gt;
&lt;li&gt;Forth offence: Permanent removal from the game servers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The community has been very enthusiastic about how quickly users of inappropriate terms are removed. I've seen a few minor
complaints about the permanent removal of users on the forth offense. I've told the community that &lt;em&gt;if&lt;/em&gt; a user protests the 
ban and &lt;em&gt;if&lt;/em&gt; they can show they've learned our rules, I will provide one additional chance after the user has waited a minimum
of a month from from last time they were banned. If they return to their previous activities, they will be re-banned and
they will not be able to return in the future.&lt;/p&gt;
&lt;h2 id="update-at-shutdown"&gt;Update at shutdown&lt;a class="headerlink" href="#update-at-shutdown" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated January 20, 2015&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In January 2015, Team Vipers &lt;a href="https://andrewwegner.com/thanks-for-all-the-fish.html"&gt;shut down&lt;/a&gt;. With that shutdown, all chat monitoring also shut down. The system was active
from April 23, 2012 to January 4, 2015, for a total of 987 days. In that time, 4457 bans were issued for inappropriate
language. That is over 4 users a day being removed from our player base because they couldn't maintain a respectful
attitude. I consider that a success. I believe Viper community members did too.&lt;/p&gt;</content><category term="team vipers"></category><category term="automation"></category><category term="programming"></category></entry><entry><title>Connect Python to OSI Soft PI</title><link href="https://andrewwegner.com/connect-python-to-osi-soft-pi.html" rel="alternate"></link><published>2012-02-07T12:45:00-06:00</published><updated>2012-04-16T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2012-02-07:/connect-python-to-osi-soft-pi.html</id><summary type="html">&lt;p&gt;How I connected Python to OSI Soft PI&lt;/p&gt;</summary><content type="html">&lt;p&gt;OSI PI is a historian database. I had a task to connect a python application to this database. I asked a question on 
&lt;a href="http://stackoverflow.com/questions/8898114/how-can-i-connect-python-2-6-to-osi-pi"&gt;Stack Overflow&lt;/a&gt; about whether this was a simple problem to solve. After two weeks I still hadn't gotten a viable response,
so I had to build by own solution.&lt;/p&gt;
&lt;p&gt;I did reach out to the vendor first for help. Their response back was not helpful. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Looks like pyodbc is written against ODBC 3.x.  The OSI PI ODBC driver is using ODBC 2.0.  The python ODBC driver manager 
will convert most ODBC 3 calls on the fly to ODBC 2 ones. Anything added to 3, however, will obviously fail. You would 
need to find some way to make sure that your only using 2.0 compliant ODBC calls.  Currently their is not a PI ODBC 
driver that is compliant with ODBC 3.0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, it looks like the vendor doesn't support Python (odd, they are named "PI", but I digress). Additionally, the drivers provided 
by the company initially didn't work. &lt;/p&gt;
&lt;p&gt;The code below shows how I was able to finally connect python to OSI PI. It may not be the most elegant, but it 
functions for the purposes of my application. Initially I was attempting to connect using the &lt;a href="https://github.com/mkleehammer/pyodbc"&gt;pyodbc&lt;/a&gt; module. Unfortunately, 
OSI PI would return a message like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pyodbc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nl"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;IM002&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[IM002] [OSI][PI ODBC][PI]PI-API Error &amp;lt;pilg_getdefserverinfo&amp;gt; 0 (0) (SQLDriverConnectW); [01000] [Microsoft][ODBC Driver Manager] The driver doesn&amp;#39;t support the version of ODBC behavior that the application requested (see SQLSetEnvAttr). (0)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;They vendor mentioned that using OLEDB instead may prove more fruitful. Thus, the code below is how I got connected using 
the vendor provided OLDEB driver. The downside is that I also had to do this all through COM objects using &lt;a href="http://python.net/crew/skippy/win32/Downloads.html"&gt;win32com&lt;/a&gt;. 
I'm not knocking the module, because it is extremely useful and I've done some great things with it.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;win32com.client&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.Connection&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.RecordSet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ConnectionString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Provider=PIOLEDB;Data Source=&amp;lt;server&amp;gt;;User ID=&amp;lt;username&amp;gt;;database=&amp;lt;database&amp;gt;;Password=&amp;lt;password&amp;gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;We&amp;#39;ve connected to the database.&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;db_cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;SELECT tag FROM pipoint WHERE tag LIKE &amp;#39;TAG0001%&amp;#39;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ActiveConnection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db_cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EOF&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;#print oRS.Fields.Item(&amp;quot;tag&amp;quot;).Value   # Ability to print by a field name&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;        &lt;span class="c1"&gt;# Ability to print by a field location&lt;/span&gt;
        &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MoveNext&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Not connected&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I followed up on my Stack Overflow post about 2 months after posting my solution with the following note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Just following up on this after using it for a couple months. This is still the only way I've found to do this with 
python, but it seems to be very slow when I need to run a large number of queries. I suspect it is because I have to 
open/close the database connection for each query, but OSI PI/ADODB complains if I do not. Performance has not reached a 
point where I am forced to rewrite this yet. If/when I do I will follow up again. In the meantime others using this 
solution should be aware that it is slow when running many queries.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="technical"></category></entry><entry><title>A new, more fair, RTD</title><link href="https://andrewwegner.com/a-new-more-fair-rtd.html" rel="alternate"></link><published>2011-02-04T20:01:00-06:00</published><updated>2015-05-20T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2011-02-04:/a-new-more-fair-rtd.html</id><summary type="html">&lt;p&gt;A description of how the Roll The Dice plugin has been updated&lt;/p&gt;</summary><content type="html">
&lt;h2 id="the-old-rtd"&gt;The old RTD&lt;a class="headerlink" href="#the-old-rtd" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Viper's own LinuxLover, aka &lt;a href="https://forums.alliedmods.net/member.php?u=38829"&gt;pheadxdll&lt;/a&gt; on the &lt;a href="https://forums.alliedmods.net/index.php"&gt;SourceMod forums&lt;/a&gt;, wrote the &lt;a href="https://forums.alliedmods.net/showthread.php?p=666222"&gt;original version&lt;/a&gt; of the Roll the Dice
plugin. It has provided countless hours of fun for players. After all, who doesn't love getting Toxic while standing near an enemy 
spawn and hearing the rage as they die immediately. It's usually worth the instant death that follows when the effect
wears off ten seconds later.&lt;/p&gt;
&lt;p&gt;There were problems though. The biggest was that the chances of getting a Good vs Bad roll were not equal. Instead, you 
had a roughly equal chance of getting any roll. There were 14 possible rolls. You had a 1 out of 14 chance of getting a specific
effect. However, 9 of those effects were negative. Thus, you had a much higher chance of getting a negative effect vs a 
positive one. The other major problem was that it was very difficult to add new effects. Finally, with the released mod
not being updated, and LinuxLover departing Vipers to handle his own community on the Randomizer server, it was next to
impossible to get changes made.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;NOTE&lt;/em&gt;: LinuxLover released a new version of RTD (the 0.4 branch) sometime after we had forked the version we had. The new
version on SourceMod contains many of the same features we have. It does not, however, contain all of them.&lt;/p&gt;
&lt;h2 id="the-new-rtd"&gt;The new RTD&lt;a class="headerlink" href="#the-new-rtd" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The logic for how rolls are determined has been changed. There is now a list of Good Effects and a list of Bad Effects. When
someone rolls, the first thing that is done is determine whether or not we are going to have a Good or Bad effect. That is a 
50/50 chance. Then it randomly selects one of the effects that are active and appropriate for the player's current class
that falls under the winning category. This should even out the Good vs Bad complaints.&lt;/p&gt;
&lt;p&gt;Another change that I've added is that we can now more easily add effects. Some new effects have been added:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Powerplay: When Uber isn't enough...you need Kritz and Uber. &lt;/li&gt;
&lt;li&gt;Freeze Bullets: You've been shot! You should run away, but you can't. You're frozen in place for the next ten seconds, if 
 you're lucky.&lt;/li&gt;
&lt;li&gt;Fire Bullets: A bullet wound isn't enough. You need to be on fire too.&lt;/li&gt;
&lt;li&gt;No crits: Haha! You are on an all crits server and you just lost your crits. Go sit at the little kid table.&lt;/li&gt;
&lt;li&gt;Valve Rockets: We've included something that may be slightly overkill. You tell me:&lt;/li&gt;
&lt;li&gt;+9900% damage&lt;/li&gt;
&lt;li&gt;+9000% clip size&lt;/li&gt;
&lt;li&gt;+75% firing speed&lt;/li&gt;
&lt;li&gt;+500 health on kill&lt;/li&gt;
&lt;li&gt;10 seconds of crits on kill&lt;/li&gt;
&lt;li&gt;+200% speed&lt;/li&gt;
&lt;li&gt;+60% reload time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because sometimes overkill is needed. &lt;/p&gt;
&lt;p&gt;We've been testing performance of this over the last few months. Today is the day that everyone can get it without
   an admin being around.&lt;/p&gt;
&lt;p&gt;For those that haven't seen it, here is one of our first tests back in November&lt;/p&gt;
&lt;p&gt;
&lt;iframe allowfullscreen="true" frameborder="0" height="315" src="//www.youtube.com/embed/OzHNr1Bz5QQ" width="560"&gt;&lt;/iframe&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Headless Horseless Headmann: That's right, you can be the Halloween nightmare.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Homing Projectiles: Is that soldier aimbotting?! Nope. His rockets are just following you where ever you go. Boom! Oh, 
 sniper arrows and pyro flares are probably something to avoid too.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, I added in the ability to log rolls to a database so that we can find fancy stats and ensure it's rolling fairly. I'll
update this post in a few months with some of our gathered stats.&lt;/p&gt;
&lt;h2 id="source-code"&gt;Source Code&lt;a class="headerlink" href="#source-code" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Updated May 20, 2015 with link to GitHub instead of the old SVN, my apologies for missing that link when migrating to this blog
It is important to note that this version hasn't been updated in a LONG time and all effects may not work any more. Specifically,
homing probably doesn't work because the Sidewinder extension had been broken by a Valve update in mid-2014. Other effects
should continue to work&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The source code is released on Github. It requires several common modules which are all available on the SourceMod forums.&lt;/p&gt;
&lt;p&gt;The repository is: &lt;a href="https://github.com/AWegnerGitHub/Vipers-Server-Plugins"&gt;https://github.com/AWegnerGitHub/Vipers-Server-Plugins&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="statistics"&gt;Statistics&lt;a class="headerlink" href="#statistics" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section was updated in January 2015 after the shutdown&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="good-vs-bad"&gt;Good vs Bad&lt;a class="headerlink" href="#good-vs-bad" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I don't have exact stats on Good vs Bad rolls before the rewrite, but we started logging all rolls with the rewrite. This is the 
split of Good vs Bad. I am very happy with an almost exactly 50/50 split over nearly a million RTDs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="RTD Split" src="https://andrewwegner.com/images/rtd-split.png"/&gt;&lt;/p&gt;
&lt;h3 id="class-with-the-most-rtds"&gt;Class with the most RTDs&lt;a class="headerlink" href="#class-with-the-most-rtds" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Solider was the most popular class on the crit server. The images below show number of times our soldiers got certain rolls. Note that God Mode is 
low because the community decided having both God Mode and Powerplay was redundant. They decided to keep Power play. God Mode was
disabled about a year after this version was released. Homing is low because it wasn't implemented until about 18 months after
the initial release.&lt;/p&gt;
&lt;p&gt;&lt;img alt="RTD Soldier" src="https://andrewwegner.com/images/rtd-soldier.png"/&gt;&lt;/p&gt;
&lt;h3 id="class-with-the-least-rtds"&gt;Class with the least RTDs&lt;a class="headerlink" href="#class-with-the-least-rtds" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Medics rolled RTD the least number of times. This means sense for two reasons. First, they were not a common class on the crit server. When 
nearly everything is one hit, one kill, it's very hard to build uber. Second, when you &lt;em&gt;do&lt;/em&gt; try to build Uber, ruining it with a 50/50
shot at getting a bad roll isn't good for the team. The low God Mode and Homing results are the same here as they were for the soldier.&lt;/p&gt;
&lt;p&gt;&lt;img alt="RTD Medic" src="https://andrewwegner.com/images/rtd-medic.png"/&gt; &lt;/p&gt;</content><category term="team vipers"></category><category term="programming"></category></entry><entry><title>A special kind of troll</title><link href="https://andrewwegner.com/a-special-kind-of-troll.html" rel="alternate"></link><published>2010-12-28T16:04:00-06:00</published><updated>2011-07-07T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-12-28:/a-special-kind-of-troll.html</id><summary type="html">&lt;p&gt;Thoughts on Viper's most recent troll&lt;/p&gt;</summary><content type="html">
&lt;h2 id="what-happened"&gt;What happened?&lt;a class="headerlink" href="#what-happened" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Over the Christmas holiday, the Team Vipers forums were hit by "multiple" users who decided it was a good idea to use our community 
as a battle ground. A Viper member stepped in to "help" resolve the problem by attempting to play mediator. (Notice the
air quotes. These are important later) The battling users turned on this member and escalated the matter to threats of violence. 
When the member stopped responding, the users got bored and began spamming the board. &lt;/p&gt;
&lt;p&gt;Due to a combination of it being Christmas and the admins doing Christmas-y things with their families, this went on for
hours. There were several rounds of clean ups, but the battle continued over nearly a 48 hour period. &lt;/p&gt;
&lt;h2 id="why-is-this-troll-different"&gt;Why is this troll different?&lt;a class="headerlink" href="#why-is-this-troll-different" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;After Christmas festivities had ended and I had time to sit down in front of a computer to investigate what happened, I began
piecing together a time line of events. It turns out that all of these "users" were coming from the same IP address.
On top of that, they shared the same IP address as the member that attempted to "help". Odd...&lt;/p&gt;
&lt;h3 id="a-little-more-background"&gt;A little more background&lt;a class="headerlink" href="#a-little-more-background" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The member that was "helping" had recently been approached by the admin team in an effort to clarify some questions about
their age. One of the admins had been presented evidence that the user was under the age of 16, which we all know if the 
minimum age to be a Vipers member. &lt;/p&gt;
&lt;p&gt;The user took this as a threat that we were going to remove them from the community entirely via bans on the servers and 
forums. They posted a rant on their "sub-community". To mean this seems much more like a place where people that didn't
like our rules go to complain about us in an unproductive manner. I'm still not sure why they set up this community in
the first place, because they have always expressed a very keen interest in Vipers. &lt;/p&gt;
&lt;h3 id="follow-up-with-the-member"&gt;Follow up with the member&lt;a class="headerlink" href="#follow-up-with-the-member" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When I started seeing a pattern between the battling users and the member, I sent a Steam message to the member asking
if they were around so that we could chat. The conversation began with me asking about the rant they posted and whether
or not they were aware that we allowed players under 16 to play on the servers, but not be members. They said they were
not aware of this and seemed pleased they'd still be around.&lt;/p&gt;
&lt;p&gt;I thanked them for their attempt to help over the holiday. Then I mentioned that it was odd that all of the users were 
coming from the same IP address. It was agreed that was odd. When I said that there was another user that used that IP in 
the past, they stopped responding. A few hours later I got a message saying they were back and around to talk again but
they'd closed the Steam chat window and lost the conversation.&lt;/p&gt;
&lt;p&gt;A few minutes later they began complaining that their own forum had been spammed. I'll admit I was curious, so I went to
take a look. There were multiple "users" having a very similar battle across the other forum. The member had posted messages
as the voice of the community that it had to stop or they'd issue bans.&lt;/p&gt;
&lt;p&gt;I was sick of the game at this point. I mentioned that I knew they were all of the users involved. I'd issued bans to the 
user accounts on the forum. I revoked their Viper membership and banned their main account. I also made a note that they 
could appeal the ban in 6 months time. I figured they'd forget about us.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It takes a special kind of troll to spam their own site to try and convince someone you aren't a spammer.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id="after-effect-of-the-bans"&gt;After effect of the bans&lt;a class="headerlink" href="#after-effect-of-the-bans" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point the member was less than pleased. There were vague threats made against me, the server, and anything they
could think of that would offend me. I simply ignored the user on Steam. &lt;/p&gt;
&lt;p&gt;This didn't sit well, apparently. The user attempted a denial of service attack on the game servers, which our hosting 
provider mitigated. Part of this mitigation involves sending me a list of IP addresses that were attempting to connect 
to the server at the time of the attack, and part of the traffic that automatically triggered their counter measures.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, there were only a few IP addresses. Geolocation says they are all in the same city. One of those IP addresses
is the IP of the user. &lt;/p&gt;
&lt;h2 id="what-is-going-to-change"&gt;What is going to change?&lt;a class="headerlink" href="#what-is-going-to-change" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The biggest problem I see out of all of this is that we didn't have active admins during the initial wave of spam. I can't fault
the admin team, after all it was Christmas. However, there have been a few requests recently for a couple more game server admins.
I feel this incident just confirms that we need a couple more. In the coming days, we'll announce who our new admins will be.&lt;/p&gt;
&lt;p&gt;The member that has been removed has been banned from the servers and the forums. We've also destroyed two new user accounts
they created since the spam wave. This is business as usual. I did offer them the chance to appear at the end of June. 
I suspect they will not.&lt;/p&gt;
&lt;h2 id="the-appeal"&gt;The appeal&lt;a class="headerlink" href="#the-appeal" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section was added on July 7th, 2011 after the user appealed their ban&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It seems I was wrong. They filed an appeal to their ban. Of course it took place over another holiday (4th of July). Fortunately,
our two European admins were still around while the rest of us were out enjoying some fireworks. &lt;/p&gt;
&lt;p&gt;The appeal was filed on the forums, as is usual. Community members stepped in to experess their unhappiness that the user
would consider returning after what they did over Christmas. One of the admins that were around put a message in the admin
area and asked for feedback from other admins. &lt;/p&gt;
&lt;p&gt;When I returned home after some amazing fireworks, I found I had an email from our hosting provider. They'd blocked another
attempted denial of service attack. I logged into the forums to see what was going on and noticed that the appeal thread
was not going well. The user were getting more and more upset at the community members who were rallying against their
return. It eventually ended with a note saying that they hope Vipers never recovers from the DDOS. At this point one of the
other admins locked the thread. &lt;/p&gt;
&lt;p&gt;A check of the IP address the user was utilizing to post the messages and the list of IPs involved in the attempted DDOS
showed that the IP was on the list, and again they were all in the same city (and the same city as in December). &lt;/p&gt;
&lt;p&gt;Their appeal was rejected. They were informed they would not be welcome back.&lt;/p&gt;
&lt;p&gt;After this appeal, I don't believe anything will need to change on our side. The appeal process concluded faster than normal.
Attempts to DDOS the community server makes the decision rather easy for the admins. &lt;/p&gt;</content><category term="team vipers"></category><category term="moderation"></category></entry><entry><title>Multiple IP addresses on the same physical network card</title><link href="https://andrewwegner.com/multiple-ip-addresses-on-the-same-physical-network-card.html" rel="alternate"></link><published>2010-11-17T12:54:00-06:00</published><updated>2010-11-17T12:54:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-11-17:/multiple-ip-addresses-on-the-same-physical-network-card.html</id><summary type="html">&lt;p&gt;A quick walkthrough on how to configure a single network card to pull multiple IP addresses (RedHat based distribution)&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are times when a server can be allocated more than one IP Address even though it contains only one physical 
network card. To associate these IP addresses with the server some manipulation of networking settings will need to be 
performed. The steps outlined in this walk-through are for RedHat based systems. This tutorial is for statically assigned 
IP Addresses (as a server generally will have).
For this walk through we are going to add one additional IP address to &lt;code&gt;eth0&lt;/code&gt;. Navigate to&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cd /etc/sysconfig/network-scripts&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copy &lt;code&gt;ifcfg-eth0&lt;/code&gt; to &lt;code&gt;ifcfg-eth0:0&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;cp ifcfg-eth0 ifcfg-eth0:0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we need to modify the new file slightly so that it gets it's own IP address. Open &lt;code&gt;ifcfg-eth0:0&lt;/code&gt; in your favorite editor&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;DEVICE=eth0:0           &amp;lt;-- Change this to match the new eth0:0 file we just created&lt;/span&gt;
&lt;span class="err"&gt;BOOTPROTO=none&lt;/span&gt;
&lt;span class="err"&gt;BROADCAST=x.x.x.x       &amp;lt;-- This is the broad cast address for the subnet the new IP is on&lt;/span&gt;
&lt;span class="err"&gt;DNS1=x.x.x.x            &amp;lt;-- This is the main DNS server you are using (example: 64.120.14.26)&lt;/span&gt;
&lt;span class="err"&gt;GATEWAY=x.x.x.x         &amp;lt;-- This is the gateway address for the subnet the new IP is on&lt;/span&gt;
&lt;span class="err"&gt;HWADDR=&amp;lt;DO NOT CHANGE&amp;gt;  &amp;lt;-- Don&amp;#39;t change this from what is existing. The Hardware address is the same as the physical one&lt;/span&gt;
&lt;span class="err"&gt;IPADDR=x.x.x.x          &amp;lt;-- This is your new IP address&lt;/span&gt;
&lt;span class="err"&gt;NETMASK=x.x.x.x         &amp;lt;-- This is the netmask for the subnet the new IP is on&lt;/span&gt;
&lt;span class="err"&gt;ONBOOT=yes              &amp;lt;-- Leave to yes&lt;/span&gt;
&lt;span class="err"&gt;OPTIONS=layer2=1&lt;/span&gt;
&lt;span class="err"&gt;TYPE=Ethernet&lt;/span&gt;
&lt;span class="err"&gt;PREFIX=29&lt;/span&gt;
&lt;span class="err"&gt;DEFROUTE=yes&lt;/span&gt;
&lt;span class="err"&gt;NAME=&amp;quot;System eth0:0&amp;quot;    &amp;lt;-- Change to reflect new name of device&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Save your file with the new settings. Now we need to restart the networking service:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;service network restart&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When the network components come back up you should see your new device in the &lt;code&gt;ifconfig&lt;/code&gt; command. To add more IPs, 
copy and replace values as specified above.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Fixing MYISAM Crashed Tables</title><link href="https://andrewwegner.com/fixing-myisam-crashed-tables.html" rel="alternate"></link><published>2010-05-14T10:08:00-05:00</published><updated>2010-05-14T10:08:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-05-14:/fixing-myisam-crashed-tables.html</id><summary type="html">&lt;p&gt;How to fix MyISAM tables that are marked as crashed&lt;/p&gt;</summary><content type="html">&lt;p&gt;For various reasons, MyISAM tables are known to crash. When this happens, the following message will be displayed:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;INVALID SQL: 145 : Table &amp;#39;{something}&amp;#39; is marked as crashed and should be repaired&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I've found this error occurs when MySQL is unexpectedly shut down - whether from a power failure to the entire server or 
if MySQL itself has issues and you use the &lt;code&gt;kill&lt;/code&gt; command to stop it. Unexpected shut downs, especially while these tables 
are being used, do not make MyISAM tables happy.&lt;/p&gt;
&lt;p&gt;To fix this, you need the ability to stop MySQL in a controlled manner, and you need to know where the database files 
are stored.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;locate *.MYI&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will return where all the MYI files are stored. In this example, I am using&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;/var/lib/mysql/mysql/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Go to the directory of the crashed table using the &lt;code&gt;cd&lt;/code&gt; command. Next, stop MySQL. This is to ensure the tables are not 
accessed while we perform our repair functions. If you don't perform this step, the repair may not succeed.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;service mysqld stop&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we are going to perform two repair functions. The first one may take a while depending on the size of your tables.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;myisamchk -r --force --safe-recover *.MYI&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The second repair step is used to ensure all table states are updated correctly and repair any minor indexing issues. It 
is likely that this step is not needed after performing the previous step, but it should only take a few seconds now.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;myisamchk --force --fast --update-state *.MYI&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, restart MySQL&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;service mysqld start&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="technical"></category></entry><entry><title>Automated template for membership applications</title><link href="https://andrewwegner.com/automated-template-for-membership-applications.html" rel="alternate"></link><published>2009-10-30T22:30:00-05:00</published><updated>2009-10-30T22:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2009-10-30:/automated-template-for-membership-applications.html</id><summary type="html">&lt;p&gt;How Team Vipers improved user applications and admin participation in the process&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Not to long ago, applications for new membership in Team Vipers consisted of someone wandering onto the site, posting a
few words and an administrator saying they were accepted as a member. This worked when we were a small community. We
aren't small any more. We have 5 servers and hundreds of players a day. Each server has their own sub-community. There
are players joining the forums than entire groups of people have never met because they play exclusively on one game server.&lt;/p&gt;
&lt;p&gt;Admins were also inconsistent in how (or if) they voted. Some admins didn't realize they could have a say, thinking it
was a privilege granted to only the senior administrators. We've built a system to resolve many of these problems and to
make the administration side easier.&lt;/p&gt;
&lt;h2 id="whats-new"&gt;What's new?&lt;a class="headerlink" href="#whats-new" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The new system presents all users with an application template. They fill out the form and the system handles the rest.
The New Users and Applications subforum has been modified so that no one, except the bot, can create topics. They
topics will only be created when the form is submitted. When a user applies to join Vipers, we will automatically
include relevant information about the user as we know them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HLStats information: This helps us get a sense of where they play and how often they play. It will help admins identify
 users they &lt;em&gt;should&lt;/em&gt; recognize based on the servers they frequent (because we all know certain servers are better than
 others ;) &lt;em&gt;cough&lt;/em&gt; Vanilla Nest vs Crits &lt;em&gt;cough&lt;/em&gt; )&lt;/li&gt;
&lt;li&gt;Ban information: This will check if the user has any recorded bans in &lt;a href="http://www.sourcebans.net/"&gt;Sourcebans&lt;/a&gt;. It's important to know if the
 user has been banned previously.&lt;/li&gt;
&lt;li&gt;Known aliases: Pulling information from our chat logs and Valve's profile page, we can build a list of known aliases.
 This helps identify users that frequently change names but have been around a while.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There may be other features we add in the future as well.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Updated January 2012&lt;/em&gt; I've removed HLStats from the servers and removed it from new application information. We have
added a check of a user's &lt;a href="http://steamrep.com/api.php"&gt;Steam Reputation&lt;/a&gt; instead.&lt;/p&gt;
&lt;p&gt;After a user applies, they are put into a two week hold. During this week it is expected they will stick around the forums
and learn about the community they just applied to. Even better would be that they had done this before applying. While
this two week hold is in place, the administration team will be able to cast they votes in a separate sub-forum. They can
hold administration specific discussions - usually details that are important for admins to know, but don't &lt;em&gt;need&lt;/em&gt; to be
public. Once voting is complete, if they become a member, the system automatically grants appropriate forum and server
related permissions.&lt;/p&gt;
&lt;h3 id="voting-rules"&gt;Voting rules&lt;a class="headerlink" href="#voting-rules" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Three admin "Yes" votes and zero "No" votes grants the user membership immediately after the two week window has expired&lt;/li&gt;
&lt;li&gt;One or two "No" votes places a message on the user's application that the administrators are still considering the application&lt;/li&gt;
&lt;li&gt;Three or more "No" votes rejects the application&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="possible-responses"&gt;Possible Responses&lt;a class="headerlink" href="#possible-responses" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="accepted-by-admin-team"&gt;Accepted by admin team&lt;a class="headerlink" href="#accepted-by-admin-team" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you reach a total of three or more admin "Yes" votes, and do not get three or more admin "No" votes, you will be accepted
as a member of Vipers and automatically have your forum access modified. You will receive a message similar to this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Application Accepted" src="https://andrewwegner.com/images/application-accepted.png"/&gt;&lt;/p&gt;
&lt;h3 id="denied-by-admin-team"&gt;Denied by admin team&lt;a class="headerlink" href="#denied-by-admin-team" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If you reach three or more "No" votes your application will be denied. This will occur even if you receive more "Yes" votes
than "No" votes. Vipers is not a majority rule community. The decision has been made that if three admins do not feel comfortable
accepting your application, you will not be granted membership. You will receive a message similar to this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Application Denied by Admins" src="https://andrewwegner.com/images/application-denied.png"/&gt;&lt;/p&gt;
&lt;h3 id="denied-due-to-lack-of-votes"&gt;Denied due to lack of votes&lt;a class="headerlink" href="#denied-due-to-lack-of-votes" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To be accepted, your application requires a minimum of three "Yes" votes. If this can not be reached (and you also can't reach
 three "No" votes), your application will be rejected due to lack of votes from the admin team. This means that the admin team
 does not feel strongly either way about your application. Post on the forums. Play in the servers. Get to know our players
 and the community at large and then try again in a month. You will receive a message similar to this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Application Denied with not enough votes" src="https://andrewwegner.com/images/application-denied-not-enough-votes.png"/&gt;&lt;/p&gt;
&lt;h3 id="denied-because-of-age"&gt;Denied because of age&lt;a class="headerlink" href="#denied-because-of-age" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Repeat after me: "Age does not equal maturity." However, it has a very strong correlation. Over time we have learned that younger
 players tend to bring a lower maturity level that most of the community does not care for. As such, we've decided to set a minimum
 age requirement of 16. If a user indicates they are less than that, the system will reject their application with a message similar to
 this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Application Denied because of age" src="https://andrewwegner.com/images/application-denied-underage.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Updated January 2010&lt;/em&gt; This process has been in place for a few months now. It has gone very well. We've reduced the clutter
in the applications forum. We've also seen the number of "forgotten" applications drop dramatically.&lt;/p&gt;
&lt;h2 id="original-announcement"&gt;Original Announcement&lt;a class="headerlink" href="#original-announcement" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The original announcement is posted here for future reference.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Zephyr is an automated robot designed to improve our new member application process. The current process, which involves copying a template to a new thread and the potential for applications to become misplaced, is cumbersome and inefficient. The goal of Zephyr is to remove as much of the manual process as possible.&lt;/p&gt;
&lt;p&gt;Now, our new applicants will fill out an actual application online. The same information will be requested, but it will be in a more reliable format and will not require an applicant copy and paste anything between threads. This new application will be posted in the same forum as you're used to, and members will be freely able to comment and discuss the applicant via that thread. It will also display which date admin voting will be open, which is two full weeks after the original application post. This will hopefully cut down on any confusion related to the delay between application and voting.&lt;/p&gt;
&lt;p&gt;As another note, from now on Zephyr will be the only user capable of creating new threads in the New Member Application forum. As previously stated, members will be able to post comments on existing threads, but the only new threads will come from the application process. This will keep the forum cleaner and help prevent applications from becoming lost or forgotten about.&lt;/p&gt;
&lt;p&gt;Once again, Zephyr is an automated robot. It is not programmed to respond to comments or questions. Doing so will not get your question answered. As always, if you have questions or comments about the application process, Zephyr, or anything else, you're welcome to send them to any admin. We'll be more than happy to help.&lt;/p&gt;
&lt;p&gt;You may all bow to your Robotic Overlord now.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="team vipers"></category><category term="automation"></category><category term="community"></category><category term="programming"></category></entry></feed>