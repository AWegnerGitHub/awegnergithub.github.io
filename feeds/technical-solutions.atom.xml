<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ponderings of an Andy - Technical Solutions</title><link href="https://andrewwegner.com/" rel="alternate"></link><link href="https://andrewwegner.com/feeds/technical-solutions.atom.xml" rel="self"></link><id>https://andrewwegner.com/</id><updated>2018-09-26T12:30:00-05:00</updated><entry><title>Backing up Ubuntu laptop to Ubuntu Server with passwordless rsync</title><link href="https://andrewwegner.com/ubuntu-backup-rsync.html" rel="alternate"></link><published>2018-09-26T12:30:00-05:00</published><updated>2018-09-26T12:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-09-26:/ubuntu-backup-rsync.html</id><summary type="html">&lt;p&gt;The server has been running and the laptop needs to be backed up. This walks through how I did it.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The server has been running for almost nine months. It's been backing up family data and pictures from phones without any problems. Now it's time to back up the laptop because I have the space and really should make sure the stuff that isn't work related (ie. the stuff that is in the work git repositories) is also backed up. &lt;/p&gt;
&lt;p&gt;Enter &lt;a href="https://rsync.samba.org/"&gt;&lt;code&gt;rsync&lt;/code&gt;&lt;/a&gt;. &lt;/p&gt;
&lt;h2 id="how-to"&gt;How To&lt;a class="headerlink" href="#how-to" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;My goal is to automatically back up my home directory from the laptop to the server on a daily basis. This will provide a once a day backup and if I need to do more than that in the future, it will be as easy as modifying the final cronjob that I'll use.&lt;/p&gt;
&lt;h3 id="ssh-key"&gt;SSH Key&lt;a class="headerlink" href="#ssh-key" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first step is setting up an SSH key so that I don't have to manually provide a password. I can, in the future, add restrictions on the server side as to what this particular key will be able to do too. I'm not doing that today though, because I don't open SSH to the outside world. &lt;/p&gt;
&lt;p&gt;The first thing to do is generate a new key. I already have an SSH key configured, but it has a password. On the laptop, run the follwoing:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-keygen -t rsa -b 2048 -f ~/.ssh/laptop-rsync-key
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When asked to enter a passphrase, simply press enter and then enter again to confirm the empty passphrase.&lt;/p&gt;
&lt;p&gt;This will put &lt;code&gt;laptop-rsync-key&lt;/code&gt; and &lt;code&gt;laptop-rsync-key.pub&lt;/code&gt; in my user's &lt;code&gt;.ssh/&lt;/code&gt; directory.&lt;/p&gt;
&lt;h3 id="copy-the-public-key-to-the-server"&gt;Copy the public key to the server&lt;a class="headerlink" href="#copy-the-public-key-to-the-server" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Next, we need to copy the public key that was just generated to the server. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;scp&lt;/span&gt; &lt;span class="o"&gt;~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;laptop&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rsync&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pub&lt;/span&gt; &lt;span class="n"&gt;andy&lt;/span&gt;&lt;span class="mf"&gt;@192.168.140.187&lt;/span&gt;&lt;span class="o"&gt;:~/&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ssh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once it's been copied, log into the server. Now you need to add this key to the &lt;code&gt;authorized_keys&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd ~/.ssh
cat laptop-rsync-key.pub &amp;gt;&amp;gt; authorized_keys
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="rsync-command"&gt;rsync command&lt;a class="headerlink" href="#rsync-command" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final command to back up my home directory is pretty simple. This command is going to tell &lt;code&gt;rsync&lt;/code&gt; to use the new SSH key that was just created, to exclude all dot files and directories, and to delete anything that has been removed on the laptop from the server. The backup will go in &lt;code&gt;~/backup/laptop&lt;/code&gt; on the server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rsync -a -e "ssh -i ~/.ssh/laptop-rsync-key" ~/ andy@nas:~/backup/laptop --exclude=".*" --exclude=".*/" --delete
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once I confirmed this worked, I added it to my user's crontab on the laptop. It will run once a day now.&lt;/p&gt;
&lt;h2 id="next-steps"&gt;Next steps&lt;a class="headerlink" href="#next-steps" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next steps I'll take be taking are to restrict the new SSH key on the server to only allow it to perform &lt;code&gt;rsync&lt;/code&gt; tasks. This can be done by slightly modifying the appropriate line in &lt;code&gt;authorized_keys&lt;/code&gt;. I'll see how this daily, single, back up works for a while. If I need to, I may change it to a rotating weekly backup. I don't forsee that right now, but I need a few weeks of seeing how this works and if the single day is good enough. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Deploying a Flask Slack app on Google Cloud Platform</title><link href="https://andrewwegner.com/slack-app-google-cloud.html" rel="alternate"></link><published>2018-07-13T10:00:00-05:00</published><updated>2018-07-13T10:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-07-13:/slack-app-google-cloud.html</id><summary type="html">&lt;p&gt;Setup a Slack app using Flask and deploy it to Google's Cloud&lt;/p&gt;</summary><content type="html">
&lt;h2 id="background-and-goals"&gt;Background and goals&lt;a class="headerlink" href="#background-and-goals" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At work I am the software QA team lead (I haven't given myself a fancy title, but I should). As such, I spend a lot of time in JIRA tracking our bug and feature requests and in Slack working with every aspect of the company to ensure the new features work as expected and bugs as appropriately squashed. As new releases approach their release date, I start running more queries to ensure everything will be done on time.&lt;/p&gt;
&lt;p&gt;Mini-rant: I hate JIRA's UI. It's slow, clunky and makes rolling things up as I need them unnecessarily complicated.&lt;/p&gt;
&lt;p&gt;Despite that complaint, JIRA is good because it has so much flexibility on the web UI and, even better, it has an API I can use to automate the queries I use. So, that's what I did. Our last release was larger and more complex than the ones we've done in the last year (since I started). The reason for this complexity was that we needed to coordinate our updates with those of our third party billing platform. Messing up how we bill customers is a great way to get into a "discussion" with the higher ups at any company.&lt;/p&gt;
&lt;p&gt;In this release, I started poking around &lt;a href="https://developer.atlassian.com/server/jira/platform/rest-apis/"&gt;JIRA's API&lt;/a&gt;. With very little work, I'd managed to automatically run the queries that were taking a significant amount of time in the UI. I formatted these nicely and started posting the results in Slack during our update calls so that all of the developers were on the same page. From my point of view, these calls were more efficient. After the release was pushed out, I decided to see what it'd take to make these queries available to everyone via a Slack slash command.&lt;/p&gt;
&lt;p&gt;This article will talk about the process I went through, give a small tutorial for a basic command, explain how I tested locally, provide a few tips that deal with pitfalls I encountered and explain how I deployed this to Google's cloud platform.&lt;/p&gt;
&lt;h2 id="writing-the-flask-app"&gt;Writing the Flask app&lt;a class="headerlink" href="#writing-the-flask-app" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://api.slack.com/slash-commands"&gt;Slack's slash apps&lt;/a&gt; do not run on Slack's platform. When a slash command is issued, it calls a predefined URL and awaits a response. My experience is with Python. I've used both Flask and Django web frameworks. These commands will be small and don't need any of the back end batteries that Django includes, so I chose to use Flask to handle the commands I wanted to create.&lt;/p&gt;
&lt;h3 id="slash-pitfall-1-timeouts"&gt;Slash Pitfall 1: Timeouts&lt;a class="headerlink" href="#slash-pitfall-1-timeouts" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The first pitfall that I encountered was before I even started writing code. Slack only allows a slash command 3000 milliseconds to respond, before it times out. Unfortunately, connecting to JIRA and running the series of queries I need takes a minimum of 5 seconds. Fortunately, the workaround for this was simple: Use &lt;a href="https://api.slack.com/slash-commands#responding_response_url"&gt;delayed responses&lt;/a&gt; by responding to the initial command with a confirmation message of some kind, then perform the work and respond again using the Slack passed &lt;code&gt;response_url&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id="sample-application"&gt;Sample Application&lt;a class="headerlink" href="#sample-application" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The application code below is a simple toy example. It will respond to the command "/hello-world" and then reply again after a few seconds, to simulate the delayed responses I needed.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;wraps&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thread&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;abort&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;jsonify&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;
&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Flask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="vm"&gt;__name__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;SLACK_VERIFICATION_TOKEN&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="c1"&gt;# Put your token here&lt;/span&gt;
&lt;span class="n"&gt;SLACK_TEAM_ID&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt; &lt;span class="c1"&gt;# Put your team ID here&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;validate_request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Decorator to validate request is from slack"""&lt;/span&gt;
    &lt;span class="nd"&gt;@wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_request_validity&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;is_request_valid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;abort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;400&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;check_request_validity&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;is_request_valid&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Validate a request is from Slack"""&lt;/span&gt;
    &lt;span class="n"&gt;is_token_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'token'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;SLACK_VERIFICATION_TOKEN&lt;/span&gt;
    &lt;span class="n"&gt;is_team_id_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'team_id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;SLACK_TEAM_ID&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;is_token_valid&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;is_team_id_valid&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;slack_command_response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Respond to a Slack command"""&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response_type&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'in_channel'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;response_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s1"&gt;'response_type'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;'text'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;response_text&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;post&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;start_command_worker&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Switch to new event loop and run forever"""&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_event_loop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_forever&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="n"&gt;command_loop&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_event_loop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;command_worker&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;start_command_worker&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;command_loop&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
&lt;span class="n"&gt;command_worker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;hello_world&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Sends "Hello World!" to Slack after 5 seconds"""&lt;/span&gt;
    &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;slack_command_response&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;response_text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="nd"&gt;@app.route&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/hello-world'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;methods&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'POST'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nd"&gt;@validate_request&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;command_hello_world&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;command_loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;call_soon_threadsafe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello_world&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                      &lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;form&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'response_url'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;jsonify&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;response_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'ephemeral'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Waiting to greet you..."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# This is used when running locally. Gunicorn is used to run the&lt;/span&gt;
    &lt;span class="c1"&gt;# application on Google App Engine. See entrypoint in app.yaml.&lt;/span&gt;
    &lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'127.0.0.1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;port&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="sample-application-walkthrough"&gt;Sample Application Walkthrough&lt;a class="headerlink" href="#sample-application-walkthrough" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The only interesting thing in the imports here is the inclusion of &lt;code&gt;asyncio&lt;/code&gt;. Since I need to fire off an immediate response and then do the "real work", I'll funnel that work into worker threads. I'm also including &lt;code&gt;functools.wraps&lt;/code&gt; because I'm making a decorator for validating a request is coming from Slack. For a single command, this type of decorator isn't needed, but I have multiple Slack slash commands in the real application. I figured it'd be helpful to show here too. This application will also need the &lt;a href="http://docs.python-requests.org/en/master/"&gt;requests&lt;/a&gt; library.&lt;/p&gt;
&lt;p&gt;Speaking of that decorator, the first function encountered in the code is &lt;code&gt;validate_request&lt;/code&gt;. This will be the decorator that ensures a request came from Slack. It calls &lt;code&gt;is_request_valid&lt;/code&gt;, which compares the passed &lt;code&gt;token&lt;/code&gt; and &lt;code&gt;team_id&lt;/code&gt; to the values we've previously saved. If they match, the request is valid. If they don't match, the request is invalid. This application is only for my team and won't be distributed elsewhere.&lt;/p&gt;
&lt;p&gt;Next up is &lt;code&gt;slack_command_response&lt;/code&gt;, which is used to send text back to Slack. It will respond to the &lt;code&gt;response_url&lt;/code&gt; parameter. This is passed by Slack and is part of the &lt;code&gt;request.form&lt;/code&gt; object Flask receives. This can be found at &lt;code&gt;request.form['response_url']&lt;/code&gt;. It will reply either &lt;code&gt;ephemeral&lt;/code&gt; (default) or &lt;code&gt;in_channel&lt;/code&gt;. The first will reply only to the user and will hide the slash command that was used. The second will reply to the entire channel and will leave the slash command visible to all.&lt;/p&gt;
&lt;p&gt;Starting the worker thread is done in &lt;code&gt;start_command_worker&lt;/code&gt; and the next three lines. This will fire up a thread that listens forever. It will not take place on the main thread, which allows Flask to respond immediately and then perform work in the background. Remember, this is a small application and will work for the scale me and my team will be using this on. This is most certainly not designed for a huge number of users constantly using it.&lt;/p&gt;
&lt;p&gt;Now it's time to get to the real work. &lt;code&gt;hello_world&lt;/code&gt; and &lt;code&gt;command_hello_world&lt;/code&gt;. If you've used Flask before, you can see that &lt;code&gt;command_hello_world&lt;/code&gt; will be the function associated with a user hitting &lt;code&gt;http:\\server.tld\hello-world&lt;/code&gt; with a &lt;code&gt;POST&lt;/code&gt; request. Slack only sends &lt;code&gt;POST&lt;/code&gt; requests, so I care about &lt;code&gt;GET&lt;/code&gt; methods. In &lt;code&gt;command_hello_world&lt;/code&gt;, we send a call to the command worker thread, telling it to call &lt;code&gt;hello_world&lt;/code&gt; and then pass the &lt;code&gt;response_url&lt;/code&gt; as a parameter. The function immediately returns a response to Slack telling the user to wait.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;hello_world&lt;/code&gt;, the function sleeps for a few seconds before sending a response back to the passed &lt;code&gt;response_url&lt;/code&gt;. This &lt;code&gt;sleep&lt;/code&gt; is to emulate "real work" being done. In my case, it's five seconds of queries to JIRA to gather and format all of the data I want to return.&lt;/p&gt;
&lt;p&gt;Finally, this can run locally by firing up Flask. I tested with this command:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FLASK_APP=jira-slack-integration.py flask run
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When deploying to Google App Engine, the &lt;code&gt;main&lt;/code&gt; function won't be utilized. I cover that below.&lt;/p&gt;
&lt;h2 id="testing-the-application"&gt;Testing the application&lt;a class="headerlink" href="#testing-the-application" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Now it's time for everyone's favorite part of development: TESTING!&lt;/p&gt;
&lt;h3 id="slack-set-up-part-1"&gt;Slack set up - Part 1&lt;a class="headerlink" href="#slack-set-up-part-1" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To test a Slack application, though, some set up within Slack is needed: create a Slack Application, set up and gather tokens, and set up slash command end points.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;First, create a &lt;a href="https://api.slack.com/apps?new_app=1"&gt;new Slack App&lt;/a&gt;. Fill out the name and select the appropriate workspace.&lt;/li&gt;
&lt;li&gt;After submission, it redirects to a basic information section about the new application. Scroll down to "App Credentials". Copy the &lt;code&gt;Verification Token&lt;/code&gt; and put it in the &lt;code&gt;SLACK_VERIFICATION_TOKEN&lt;/code&gt; variable in the Flask application.&lt;/li&gt;
&lt;li&gt;Open Slack in the browser, sign in, and then open the web console. In Chrome, do this with &lt;kbd class="light"&gt;CTRL&lt;/kbd&gt;+&lt;kbd class="light"&gt;SHIFT&lt;/kbd&gt;+&lt;kbd class="light"&gt;I&lt;/kbd&gt; or with &lt;kbd class="light"&gt;F12&lt;/kbd&gt; in FireFox. View the page source and search for &lt;code&gt;team_id&lt;/code&gt;. It will look something like this: &lt;code&gt;"T083XXXX"&lt;/code&gt;. Copy this value to &lt;code&gt;SLACK_TEAM_ID&lt;/code&gt; in the Flask application.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="ngrok-set-up"&gt;ngrok set up&lt;a class="headerlink" href="#ngrok-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Before slash commands can be set up in Slack, you need a development environment and an easy way to access our development server. One option is to punch holes in the router's firewall to point to your development machine. This works if you are on a home network and you'll be the only machine running the development server. It's no so easy if your set up is more complicated or infrastructure is outside of your control.&lt;/p&gt;
&lt;p&gt;I choose to use &lt;a href="https://ngrok.com/"&gt;ngrok&lt;/a&gt; instead. This application provides you with a free, secure and public URL to your local development environment without worrying about your NAT or firewall settings.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sign up. After that the four steps to complete setup are shown&lt;/li&gt;
&lt;li&gt;Download ngrok. There are downloads for a variety of operating systems. This includes Ubuntu, which I use for my work related development work.&lt;/li&gt;
&lt;li&gt;Unzip ngrok to any location: &lt;code&gt;unzip /path/to/ngrok.zip&lt;/code&gt; This places an &lt;code&gt;ngrok&lt;/code&gt; binary in the selected location.&lt;/li&gt;
&lt;li&gt;Set up the authentication token. This is a one time step. This will create a &lt;code&gt;~/.ngrok2/ngrok.yml&lt;/code&gt; file.&lt;/li&gt;
&lt;li&gt;Start &lt;code&gt;ngrok&lt;/code&gt;. If you're using the script from above, Flask should run on the local machine on port 5000. The command to start &lt;code&gt;ngrok&lt;/code&gt; to point to the Flask server is: &lt;code&gt;./ngrok http 5000&lt;/code&gt;. In another command prompt start the Flask application.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="slack-set-up-part-2"&gt;Slack set up - Part 2&lt;a class="headerlink" href="#slack-set-up-part-2" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ngrok&lt;/code&gt; provides a public URL. In the screenshot below, my URL is &lt;code&gt;https://1eed8eae.ngrok.io&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ngrok dashboard" src="https://andrewwegner.com/images/ngrok.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; This changes every time &lt;code&gt;ngrok&lt;/code&gt; is stated.&lt;/p&gt;
&lt;p&gt;At this point, I can visit &lt;code&gt;https://1eed8eae.ngrok.io/hello-world&lt;/code&gt; in my browser and get an error message because I didn't configure it to support &lt;code&gt;GET&lt;/code&gt; requests.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go back to Slack and the management area where the new application was set up.&lt;/li&gt;
&lt;li&gt;Select "Slash Commands"&lt;/li&gt;
&lt;li&gt;Select "Create New Command"&lt;/li&gt;
&lt;li&gt;Put in the command users will use within Slack. This can be anything.&lt;/li&gt;
&lt;li&gt;Enter the request URL. This will be &lt;code&gt;https://1eed8eae.ngrok.io/hello-world&lt;/code&gt; with this example&lt;/li&gt;
&lt;li&gt;Provide a description of the command&lt;/li&gt;
&lt;li&gt;Add a usage hint. This is useful if you are passing parameters to the command.&lt;/li&gt;
&lt;li&gt;Press save&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Slash Command Example" src="https://andrewwegner.com/images/slash-command-example.png"/&gt;&lt;/p&gt;
&lt;p&gt;The slash command is now set up. The last step is installing the application. Go back to "Basic Information" and expand "Install your app to your workspace" then press the green "Install App to Workspace" button. You'll be presented with an oAuth Access Token. For this example application, it's not needed.&lt;/p&gt;
&lt;p&gt;Now go into any channel in Slack and use the new &lt;code&gt;/hello-world&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Important Note:&lt;/strong&gt; If/when you shut down and restart &lt;code&gt;ngrok&lt;/code&gt;, you'll get a new end point. The slash command will need to be modified to point to this new request URL to continue to function. These changes will not be required once the application is deployed to Google's App Engine.&lt;/p&gt;
&lt;h2 id="deploy-application-to-app-engine"&gt;Deploy application to App Engine&lt;a class="headerlink" href="#deploy-application-to-app-engine" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This project requires the use of the &lt;a href="https://cloud.google.com/appengine/docs/the-appengine-environments"&gt;flexible app engine environment&lt;/a&gt; (vs. standard environment). The biggest reason for this is due to the network requirements. It seems that anything other than Node.js has networking restrictions, and the sample application needs to connect to Slack and my application also needed to connect to JIRA. Another downside of the standard environment is that it only supports Python 2.7. I don't believe there is anything in the example application that would break on Python 2, but there are a few Python 3 specific things I used in my real application (f strings, are one).&lt;/p&gt;
&lt;p&gt;The flexible environment isn't free though. It's always on. The sample application and my real application are so small and used by so few people that it costs less than fifty cents a day. This isn't a huge deal when the rest of our Google cloud bill exceeds that by a couple orders of magnitude, but it is something to consider if you are just running this as a small side thing. It's not free.&lt;/p&gt;
&lt;h3 id="set-up-gcloud-sdk"&gt;Set up gcloud SDK&lt;a class="headerlink" href="#set-up-gcloud-sdk" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Due to the size of this application, the &lt;a href="https://cloud.google.com/appengine/docs/flexible/python/"&gt;quick start tutorial&lt;/a&gt; that Google provides is perfect.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using the Google Cloud Platform console, create a new App Engine project and enable billing (billing must be enabled). This can be done from &lt;a href="https://console.cloud.google.com/projectselector/appengine/create?lang=flex_python&amp;amp;st=true"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download the &lt;a href="https://cloud.google.com/sdk/docs/"&gt;Google Cloud SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Extract this to any location. To add it to the path, run &lt;code&gt;./google-cloud-sdk/install.sh&lt;/code&gt;. If this isn't done, the full path needs to be in all &lt;code&gt;gcloud&lt;/code&gt; commands.&lt;/li&gt;
&lt;li&gt;Initialize the SDK by running &lt;code&gt;gcloud init&lt;/code&gt; and follow the prompts on screen. You'll need access to a browser for this step as you'll be authorizing your account using oAuth.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="set-up-appyaml"&gt;Set up app.yaml&lt;a class="headerlink" href="#set-up-appyaml" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With &lt;code&gt;gcloud&lt;/code&gt; set up on your development machine, there is one last step to do: Configuring the &lt;code&gt;app.yaml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;This file contains information on the type of environment you'll be deploying to. Create and save an &lt;code&gt;app.yaml&lt;/code&gt; file in the same directory as the Flask application. For this example, the Flask application is in a file saved as &lt;code&gt;example-script.py&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;runtime&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;env&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;flex&lt;/span&gt;
&lt;span class="n"&gt;entrypoint&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;gunicorn&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;$PORT&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;app&lt;/span&gt;

&lt;span class="n"&gt;runtime_config&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;python_version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="n"&gt;manual_scaling&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;instances&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cpu&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
  &lt;span class="n"&gt;memory_gb&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;
  &lt;span class="n"&gt;disk_size_gb&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other than the &lt;code&gt;entrypoint&lt;/code&gt; line, this is the example &lt;code&gt;app.yaml&lt;/code&gt; provided by Google. &lt;code&gt;example-script&lt;/code&gt; is the name of the file that contains the Flask application.&lt;/p&gt;
&lt;h3 id="deploy-to-google"&gt;Deploy to Google&lt;a class="headerlink" href="#deploy-to-google" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Finally, it's time to deploy this application to Google. From within the same directory where &lt;code&gt;example-script.py&lt;/code&gt; resides, run:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gcloud app deploy
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Wait a few minutes for the deployment to occur. When it's complete, the command prompt will say so and provide a URL where the application is accessible.&lt;/p&gt;
&lt;p&gt;The last thing that needs to be done, is repointing the slash commands to this new location. With it deployed to Google's Cloud Platform, the &lt;code&gt;ngrok&lt;/code&gt; provided URLs need to be changed. The endpoints remain the same though.&lt;/p&gt;
&lt;p&gt;Once the slash commands are changed and saved, test them out and enjoy the new slash commands hosted on Google's App Engine.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Set up Dynamic CloudFlare IP with Let's Encrypt</title><link href="https://andrewwegner.com/setup-lets-encrypt.html" rel="alternate"></link><published>2018-04-25T09:30:00-05:00</published><updated>2018-04-25T09:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-25:/setup-lets-encrypt.html</id><summary type="html">&lt;p&gt;Time to make the server accessible from the internet and secure it with an SSL certificate&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the two previous articles, I installed &lt;a href="https://andrewwegner.com/installing-nextcloud.html"&gt;NextCloud&lt;/a&gt; and &lt;a href="https://andrewwegner.com/installing-gitlab.html"&gt;GitLab&lt;/a&gt;. These are running on the server, inside my local network, with 
no firewall rules set up to allow it to be accessible from the internet. That's great if I plan on sitting at home all the time and never
accessing anything from the outside. However, I do plan on that. That means I need to make this server accessible from the internet. On top
of that, I want to secure the connection to the server with SSL, so that I'm not uploading pictures or code in a way that everyone can read.&lt;/p&gt;
&lt;h2 id="setting-up-cloudflare"&gt;Setting up CloudFlare&lt;a class="headerlink" href="#setting-up-cloudflare" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This new server sits in my house, which sits on a residential ISP network. Obviously, this isn't going to have 24x7 uptime, but that's fine
with me. One thing that I will need, is a way to access this server regardless of the IP address my ISP has given me. This can (and does) change
frequently enough that it'd be annoying to keep track of my current IP manually. &lt;/p&gt;
&lt;p&gt;My solution: set up a DNS entry. In the two previous articles, I set up the Apache virtual hosts with subdomains:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ServerName nas.example.com
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ServerName gitlab.example.com
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It's time to utilize those. Then I will only need to visit those URLs and Apache will handle routing to the correct application.&lt;/p&gt;
&lt;p&gt;I use CloudFlare to handle DNS for this blog. I described the process to &lt;a href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;set up CloudFlare&lt;/a&gt; a few years ago and never 
looked at it again. "It just works." Hooray! &lt;/p&gt;
&lt;p&gt;For this, we're going to add two new A entries to reflect the subdomains I want to use. I'll point it at my IP address initially too. &lt;/p&gt;
&lt;h3 id="automating-the-ip-adddress-updates"&gt;Automating the IP adddress updates&lt;a class="headerlink" href="#automating-the-ip-adddress-updates" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The initial set up of the A entry/IP address takes a minute. The trick is automating that process every time your IP address changes. I 
am doing that with a small Python script called &lt;a href="https://github.com/Ethaligan/cloudflare-ddns"&gt;&lt;code&gt;cloudflare-ddns&lt;/code&gt;&lt;/a&gt;. Clone this to the server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/ethaligan/cloudflare-ddns.git
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, we need to set up zone information. This is the configuration file that will be used to update your A records. Copy example.com.yml to the
name of your domain. For example:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd zones
cp example.com.yml andrewwegner.com.yml
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we need to edit the newly copied file to contain appropriate zone information, CloudFlare API information and your domain.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c"&gt;%YAML 1.1&lt;/span&gt;
# &lt;span class="n"&gt;Your&lt;/span&gt; &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;email&lt;/span&gt; &lt;span class="n"&gt;address&lt;/span&gt;
&lt;span class="n"&gt;cf_email&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'your_cloudflare_email_address'&lt;/span&gt;

# &lt;span class="n"&gt;Your&lt;/span&gt; &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;API&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;
# &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;support&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cloudflare&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;hc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;us&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;200167836&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;do&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;find&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;my&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Cloudflare&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;API&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;
&lt;span class="n"&gt;cf_api_key&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;YOUR_CLOUDFLARE_API&lt;/span&gt;

# &lt;span class="n"&gt;Cloudflare&lt;/span&gt; &lt;span class="n"&gt;zone&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;
# &lt;span class="n"&gt;If&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt; &lt;span class="n"&gt;updating&lt;/span&gt; &lt;span class="s"&gt;'ddns.example.com'&lt;/span&gt; &lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;this&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="s"&gt;'example.com'&lt;/span&gt;
&lt;span class="n"&gt;cf_zone&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;com&lt;/span&gt;

# &lt;span class="n"&gt;List&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;records&lt;/span&gt;
# &lt;span class="n"&gt;If&lt;/span&gt; &lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt; &lt;span class="n"&gt;updating&lt;/span&gt; &lt;span class="s"&gt;'example.com'&lt;/span&gt; &lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="n"&gt;its&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="s"&gt;'@'&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
# &lt;span class="n"&gt;Only&lt;/span&gt; &lt;span class="n"&gt;write&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;subdomain&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'ddns'&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="s"&gt;'ddns.example.com'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;cf_records&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s"&gt;'nas'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
        &lt;span class="nb"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ERROR&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s"&gt;'gitlab'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
        &lt;span class="nb"&gt;log&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ERROR&lt;/span&gt;

# &lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="n"&gt;used&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;discover&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="n"&gt;IP&lt;/span&gt; &lt;span class="n"&gt;address&lt;/span&gt;
# &lt;span class="n"&gt;The&lt;/span&gt; &lt;span class="n"&gt;faster&lt;/span&gt; &lt;span class="n"&gt;one&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt; &lt;span class="n"&gt;but&lt;/span&gt; &lt;span class="n"&gt;it&lt;/span&gt; &lt;span class="n"&gt;may&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;be&lt;/span&gt; &lt;span class="n"&gt;available&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;your&lt;/span&gt; &lt;span class="n"&gt;system&lt;/span&gt;
# &lt;span class="n"&gt;Available&lt;/span&gt; &lt;span class="k"&gt;methods&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'http'&lt;/span&gt; &lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt;
&lt;span class="n"&gt;cf_resolving_method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s"&gt;'dig'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, I am updating two subdomains (&lt;code&gt;nas&lt;/code&gt; and &lt;code&gt;gitlab&lt;/code&gt;) that are part of the &lt;code&gt;example.com&lt;/code&gt; domain. Those should be changed to reflect your set up.&lt;/p&gt;
&lt;p&gt;Last, we need to schedule this to run on a regular basis so that CloudFlare always points to the correct IP address. I did this with a crontab entry:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;*/30 * * * * python3 /path/to/cloudflare-ddns.py -z example.com
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, change &lt;code&gt;example.com&lt;/code&gt; to your domain, and it will use the appropriate YML file. With this entry, my DNS entries are updated every 30 minutes. That 
is frequently enough for my needs.&lt;/p&gt;
&lt;h2 id="lets-encrypt-ssl"&gt;Let's Encrypt (SSL)&lt;a class="headerlink" href="#lets-encrypt-ssl" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With the subdomains set up and working, it's time to install some SSL certificates. In previous articles, I had entries in my Apache virtual hosts that pointed to
SSL certificates. This is where we'll set those up. &lt;/p&gt;
&lt;p&gt;Let's Encrypt certificates are valid for 90 days. Renewing certificates, though, can be easily automated. Since I need my certificates to work through CloudFlare,
because it provides my DNS services, I use a hook in Let's Encrypt's ACME client &lt;a href="https://github.com/lukas2511/dehydrated"&gt;&lt;code&gt;dehydrated&lt;/code&gt;&lt;/a&gt; to handle everything.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd ~
git clone https://github.com/lukas2511/dehydrated
cd dehydrated
mkdir hooks
git clone https://github.com/kappataumu/letsencrypt-cloudflare-hook hooks/cloudflare
pip install -r hooks/cloudflare/requirements.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This downloads deydrated and then downloads the CloudFlare hook that is needed. It installs the required libraries too. &lt;/p&gt;
&lt;p&gt;The last bit of configuration that is needed is setting up a &lt;code&gt;config&lt;/code&gt; file in the &lt;code&gt;dehydrated&lt;/code&gt; directory.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nano `dehydrated/config`
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add the following three lines&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;export CF_EMAIL=YOUR_CLOUDFLARE_EMAILADDRESS
export CF_KEY=YOUR_CLOUDFLARE_API
export CF_DEBUG=true
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Substitute your CloudFlare login email and API key as appropriate. The &lt;code&gt;CF_DEBUG&lt;/code&gt; line can be set to &lt;code&gt;false&lt;/code&gt; if you don't wish debugging information to be printed to &lt;code&gt;logs/&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Register with Let's Encrypt and accept their terms of service:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./dehydrated --register --accept-terms
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, you're ready to generate/install the SSL certificates needed. One note: I needed to adjust the shebang line in hooks/cloudflare/hook.py to be &lt;code&gt;python3&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Run the following commands to generate the certificates. These will end up in &lt;code&gt;dehydrated/certs&lt;/code&gt; with the full URL of each certificate. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./dehydrated -c -d nas.example.com -t dns-01 -k 'hooks/cloudflare/hook.py'
./dehydrated -c -d gitlab.example.com -t dns-01 -k 'hooks/cloudflare/hook.py'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The path to these files are what will go in your Apache Virtual Host files:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SSLCertificateFile /path/to/dehydrated/certs/nas.example.com/cert.pem
SSLCertificateKeyFile /path/to/dehydrated/certs/nas.example.com/privkey.pem
SSLCertificateChainFile /path/to/dehydrated/certs/nas.example.com/chain.pem
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I set up a crontab entry for each of my subdomains to attempt to renew the certificate once a week. Dehydrated will not attempt to renew a certificate if it's not going to 
expire in less than 30 days, so we aren't making unneeded calls to Let's Encrypt. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;0 1 6 * * /path/to/dehydrated/dehydrated -c -d nas.example.com -t dns-01 -k '/path/to/dehydrated/hooks/cloudflare/hook.py'
10 1 6 * * /path/to/dehydrated/dehydrated -c -d gitlab.example.com -t dns-01 -k '/path/to/dehydrated/hooks/cloudflare/hook.py'
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this final step, I have a home server that I can access from anywhere. It allows me to backup pictures automatically, holds my private repositories and is protected
by SSL. The SSL certificates renew automatically.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Setting up GitLab on the new server</title><link href="https://andrewwegner.com/installing-gitlab.html" rel="alternate"></link><published>2018-04-13T08:30:00-05:00</published><updated>2018-04-13T08:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-13:/installing-gitlab.html</id><summary type="html">&lt;p&gt;Let's set up some private repositories on GitLab&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Back when I ran Vipers, my fellow admins and I hosted a small set of code repositories -
SVN, Mercurial and Git - to host some of our custom code. We ran &lt;a href="https://rhodecode.com/"&gt;RhodeCode&lt;/a&gt; and
the fork, &lt;a href="https://kallithea-scm.org/"&gt;Kallithea&lt;/a&gt;, when RhodeCode close sourced some of it's code and
couldn't figure out if the license it used actually allowed themselves to do that. A private
repository was awesome for plugins, server configurations and personal projects.&lt;/p&gt;
&lt;p&gt;When the community was shuttered, some of the &lt;a href="https://github.com/AWegnerGitHub/Vipers-Server-Plugins"&gt;plugin code was migrated to GitHub&lt;/a&gt; and it's
sat there untouched since. My personal projects were either migrated to GitHub or
simply stored outside of version control if it couldn't go in a public repository. That was
less than ideal, but it worked. With the new home server set up, I wanted to get source control set
back up for my non-public personal projects.&lt;/p&gt;
&lt;p&gt;I rejected RhodeCode right away due to the experiences I had when they changed licenses. Turns out,
they had done it again in the meantime. I didn't want to deal with that. I attempted to install
Kallithea using their &lt;a href="http://kallithea.readthedocs.io/en/stable/installation.html"&gt;instructions&lt;/a&gt;, but I kept running into Python syntax errors. It wasn't
worth the time and effort to figure out the problem.&lt;/p&gt;
&lt;p&gt;So, I turned to &lt;a href="https://about.gitlab.com/"&gt;GitLab&lt;/a&gt;. It'd definitely overkill for what I really need, but it works and
if I ever truly decide to get fancy, I have a lot of other tools I can use. The &lt;a href="https://about.gitlab.com/pricing/self-hosted/feature-comparison/"&gt;core&lt;/a&gt; functionality
is what I'll be using and is free. The three other versions cost some money and contain features that
would be useful for large team, not a single developer or very small team.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;a class="headerlink" href="#installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="dependencies"&gt;Dependencies&lt;a class="headerlink" href="#dependencies" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Installing GitLab is pretty simple. There are a couple dependencies needed, but I already had both OpenSSH 
and Postfix installed, so I was able to skip the first step in the &lt;a href="https://about.gitlab.com/installation/#ubuntu"&gt;official installation guide&lt;/a&gt;. I installed
the Ubuntu Omnibus package.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install -y curl openssh-server ca-certificates postfix
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="getting-the-package"&gt;Getting the package&lt;a class="headerlink" href="#getting-the-package" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The GitLab repository needs to added and then installed. To add the repository, issue this command:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.deb.sh | sudo bash
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To install the GitLab package, you need to provide an environment variable when you issue your
&lt;code&gt;apt-get install&lt;/code&gt; command. This will be the URL where you want to access your GitLab installation.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo EXTERNAL_URL="http://gitlab.example.com" apt-get install gitlab-ee
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="complete-the-installation"&gt;Complete the installation&lt;a class="headerlink" href="#complete-the-installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the install, above is complete, you need to log in to complete the process. In your browser,
navigate to the URL you provided above. Set/reset the password as prompted and then login. &lt;/p&gt;
&lt;h2 id="post-install-tweaks"&gt;Post-install Tweaks&lt;a class="headerlink" href="#post-install-tweaks" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="using-apache-instead-of-nginx"&gt;Using Apache instead of Nginx&lt;a class="headerlink" href="#using-apache-instead-of-nginx" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The omnibus package comes with Nginx bundled. Unfortunately, I don't have any experience managing
an Nginx instance but do have experience with Apache. I want to use something that I know to make
my life easier. Fortunately, GitLab can handle this with a few &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/tree/master/web-server/apache"&gt;minor changes to the configuration&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;In the &lt;code&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; file you'll need to make several settings changes. You also need Apache 
already installed and the &lt;code&gt;www-data&lt;/code&gt; user (on Ubuntu) added to the &lt;code&gt;gitlab-www&lt;/code&gt; group.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find &lt;code&gt;nginx['enable']&lt;/code&gt; and set it to &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;web_server['external_users'], add&lt;/code&gt;www-data` to the array. Note that this is an array and not a single string.&lt;/li&gt;
&lt;li&gt;In `gitlab_rails['trusted_proxies'], add the IP address of the Apache web server. &lt;/li&gt;
&lt;li&gt;Change the gitlab workhorse settings to the following (default) values. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These may already be in the configuration file. If so, you probably don't need to modify them.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gitlab_workhorse['listen_network'] = "tcp"
gitlab_workhorse['listen_addr'] = "127.0.0.1:8181"
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, run &lt;code&gt;sudo gitlab-ctl reconfigure&lt;/code&gt; for the settings to take effect.&lt;/p&gt;
&lt;p&gt;Now, you need to configure Apache's virtual host. GitLab provides &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/tree/master/web-server/apache"&gt;example virtual hosts&lt;/a&gt;. Since I installed
the omnibus package and am using Apache 2.4, I selected the &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/blob/master/web-server/apache/gitlab-omnibus-apache24.conf"&gt;&lt;code&gt;gitlab-omnibus-apache24.conf&lt;/code&gt;&lt;/a&gt; file. Adjust all
instances of &lt;code&gt;YOUR_SERVER_FQDN&lt;/code&gt; to the fully qualified domain name of your server.&lt;/p&gt;
&lt;p&gt;This will go in &lt;code&gt;/etc/apache2/sites-available/&lt;/code&gt; and a symlink in &lt;code&gt;/etc/apache2/sites-enabled/&lt;/code&gt; will point to this file.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo touch /etc/apache2/sites-available/gitlab.conf
sudo ln -s /etc/apache2/sites-available/gitlab.conf /etc/apache2/sites-enabled/gitlab.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="use-ssl-to-access-gitlab"&gt;Use SSL to access GitLab&lt;a class="headerlink" href="#use-ssl-to-access-gitlab" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The example virtual host provided by GitLab uses HTTP only. I want to set up my instance to use HTTPS. I'll be 
doing this with &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;, like I did when I set up NextCloud in the previous post. I cover the exact 
&lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;steps for Let's Encrypt&lt;/a&gt; in another post. The keys referenced in the virtual host configuration file below created 
by that process. &lt;/p&gt;
&lt;p&gt;The first change to make is to redirect the HTTP version of your domain to HTTPS. The goal is that all traffic to
GitLab will go over SSL. Adjust the &lt;code&gt;ServerName&lt;/code&gt; variable as appropriate.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  ServerName gitlab.example.com
  ServerSignature Off

  RewriteEngine on
  RewriteCond %{HTTPS} !=on
  RewriteRule .* https://%{SERVER_NAME}%{REQUEST_URI} [NE,R,L]
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, everything in the &lt;a href="https://gitlab.com/gitlab-org/gitlab-recipes/blob/master/web-server/apache/gitlab-omnibus-apache24.conf"&gt;sample&lt;/a&gt; virtual host file can be put in the &lt;code&gt;&amp;lt;VirtualHost *:443&amp;gt;&lt;/code&gt; block.&lt;/p&gt;
&lt;p&gt;At the top of this block, we need to reference the Let's Encrypt keys:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;SSLProtocol&lt;/span&gt; &lt;span class="nt"&gt;all&lt;/span&gt; &lt;span class="nt"&gt;-SSLv2&lt;/span&gt;
&lt;span class="nt"&gt;SSLHonorCipherOrder&lt;/span&gt; &lt;span class="nt"&gt;on&lt;/span&gt;
&lt;span class="nt"&gt;SSLCipherSuite&lt;/span&gt; &lt;span class="s2"&gt;"ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS"&lt;/span&gt;
&lt;span class="nt"&gt;Header&lt;/span&gt; &lt;span class="nt"&gt;add&lt;/span&gt; &lt;span class="nt"&gt;Strict-Transport-Security&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"max-age=15768000;includeSubdomains"&lt;/span&gt;
&lt;span class="nt"&gt;SSLCompression&lt;/span&gt; &lt;span class="nt"&gt;Off&lt;/span&gt;
&lt;span class="nt"&gt;SSLCertificateFile&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;dehydrated&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;certs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;gitlab&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;example&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;cert&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;pem&lt;/span&gt;
&lt;span class="nt"&gt;SSLCertificateKeyFile&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;dehydrated&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;certs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;gitlab&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;example&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;privkey&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;pem&lt;/span&gt;
&lt;span class="nt"&gt;SSLCertificateChainFile&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;to&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;dehydrated&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;certs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;gitlab&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;example&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;chain&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;pem&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Save and restart Apache. You should be automatically redirected over HTTPS when you visit your GitLab URL.&lt;/p&gt;
&lt;h3 id="allow-spaces-in-repository-names"&gt;Allow spaces in repository names&lt;a class="headerlink" href="#allow-spaces-in-repository-names" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;One of the only problems I ran into with GitLab is that, by default, repositories with spaces in them can't be viewed
in the web browser. It throws a &lt;code&gt;400 Bad Request&lt;/code&gt; when trying to view the directory. There is a &lt;a href="https://gitlab.com/gitlab-org/gitlab-ce/issues/32585"&gt;bug report&lt;/a&gt; 
regarding this problem. The developers are working on updating the samples in a way that is guaranteed to work through
the whole system. &lt;/p&gt;
&lt;p&gt;For me, though, the first comment which suggests a minor &lt;code&gt;RewireRule&lt;/code&gt; change works great. In the virtual host, fine the line&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;RewriteRule .* http://127.0.0.1:8181%{REQUEST_URI} [P,QSA,NE]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and remove the &lt;code&gt;NE&lt;/code&gt; so that it reads&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;RewriteRule .* http://127.0.0.1:8181%{REQUEST_URI} [P,QSA]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Restart Apache and you can navigate to the directory with a space.&lt;/p&gt;
&lt;h3 id="setting-up-smtp"&gt;Setting up SMTP&lt;a class="headerlink" href="#setting-up-smtp" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;GitLab can send out emails and requires the ability to do so when resetting a password, at minimum. I don't want this
email to be marked as spam, so I used one of the free providers from &lt;a href="https://docs.gitlab.com/omnibus/settings/smtp.html#smtp-settings"&gt;here&lt;/a&gt; and set up an account. After editing the 
&lt;code&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; file to match the provider I selected, I ran &lt;code&gt;gitlab-ctl reconfigure&lt;/code&gt;. Now any emails GitLab
sends out goes through the trusted email provider instead of coming directly from my residential IP address. This means 
my mail provider trusts it. I also send out less than 5 emails a month currently, so I am &lt;em&gt;well&lt;/em&gt; below the tier where I
lose my "free" status.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;At this point, GitLab is set up over SSL on my server. I can log in and start setting up repositories. Migrating and importing 
the code bases I didn't want to put on a public GitHub account was very satisfying. Maybe I'll look into some of the 
more advanced features GitLab offers in the near future, but for the time being I'm happy with what I have and the 
knowledge that I can expand what I do with GitLab.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Travis CI doesn't keep your environment variable secure</title><link href="https://andrewwegner.com/travisci-insecure-environment-variables.html" rel="alternate"></link><published>2018-04-02T12:30:00-05:00</published><updated>2018-04-02T12:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-02:/travisci-insecure-environment-variables.html</id><summary type="html">&lt;p&gt;Travis CI does not keep your environment variables secure if you transfer a repository.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On December 27, 2017 I reported a security issue directly to the security team as their &lt;a href="https://github.com/travis-ci/travis-ci/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; recommends. I received an automated response that a human would
follow up with me soon. It was their end of year, two week vacation (which is awesome!). I sent the same email again on January 26, 2018 and received a response back from AJ Bowen, a Build Infrastructure Engineer at Travis CI on January 29, 2018. They'd created an internal issue to track the behavior and would follow up within two weeks. &lt;/p&gt;
&lt;p&gt;I followed up with AJ on February 28, 2018 and didn't receive a response. We're now over three months since my initial report. I believe it's time to make this more public so 
that others know to be careful with their Travis CI managed environment variables.&lt;/p&gt;
&lt;h2 id="the-issue"&gt;The Issue&lt;a class="headerlink" href="#the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/"&gt;Travis CI &lt;/a&gt; is an application that allows you to automatically test and deploy applications after a commit is pushed to GitHub. I've used this ability to run unit tests, 
&lt;a href="https://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html"&gt;automatically deploy updates to PyPI&lt;/a&gt;, and more recently when testing deployment to AWS using the Serverless framework. It's that last one that led me to this issue.&lt;/p&gt;
&lt;p&gt;Part of deploying to AWS requires that you have credentials to deploy. I didn't want to put my AWS deploy credentials in GitHub, even if they are &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Encrypting-environment-variables"&gt;encrypted&lt;/a&gt;. Instead, 
I decided to set my variables in the &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Defining-Variables-in-Repository-Settings"&gt;Travis CI Settings&lt;/a&gt;. I went forward with my testing, watched the deploys happen as expected and eventually needed to transfer my
repository to a third party. &lt;/p&gt;
&lt;p&gt;I used GitHub to transfer the repository to the new owner. We tested a build and watched it deploy. The Travis CI console showed a successful deploy. The problem is, 
it deployed to &lt;em&gt;my&lt;/em&gt; AWS account using &lt;em&gt;my&lt;/em&gt; AWS credentials. These "secure" environment variables had been transfered to a third party and were no longer in my control.&lt;/p&gt;
&lt;h2 id="reproduction-short-version"&gt;Reproduction - Short Version&lt;a class="headerlink" href="#reproduction-short-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Reproducing the issue is trivial. The short version is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On one GitHub account, create a repository with a &lt;code&gt;.travis.yml&lt;/code&gt; file &lt;/li&gt;
&lt;li&gt;On the Travis CI account associated with step 1, set up an environment variable and elect &lt;em&gt;not&lt;/em&gt; to show the value in the build log&lt;/li&gt;
&lt;li&gt;Transfer the GitHub repository to another account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, the environment variables defined in step 2 are accessible by the new owner from step 3. &lt;/p&gt;
&lt;h2 id="reproduction-long-version"&gt;Reproduction - Long Version&lt;a class="headerlink" href="#reproduction-long-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The detailed steps taken to reproduce this issue show that Travis CI is simply looking for the environment variable values and scrubbing those from the build logs. Once transfered, an edit can be introduced to show these variables with minimal work. &lt;/p&gt;
&lt;h3 id="create-a-repository"&gt;Create a repository&lt;a class="headerlink" href="#create-a-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Create a new repository and add something. For this test, I created a simple Python Hello World file, and named it &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Hello World")
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit this change to your new repository.&lt;/p&gt;
&lt;h3 id="enable-travis-ci-integration"&gt;Enable Travis CI integration&lt;a class="headerlink" href="#enable-travis-ci-integration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Go to &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt; and log in with the GitHub account associated with the above step. Sync your account. Then enable integration by changing the repository switch.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Enable Integration" src="https://andrewwegner.com/images/1-travis-enable-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="create-a-travisyml-file"&gt;Create a .travis.yml file&lt;a class="headerlink" href="#create-a-travisyml-file" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the integration now in place, set up a basic build script by adding a &lt;code&gt;.travis.yml&lt;/code&gt; file to the repository. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"3.5"&lt;/span&gt;
&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; 
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This script will set up a build task and run your &lt;code&gt;hello.py&lt;/code&gt; file, using Python 3.5. You will see that "Hello World!" is printed in the build console.&lt;/p&gt;
&lt;p&gt;&lt;img alt="First Build" src="https://andrewwegner.com/images/2-travis-first-build.png"/&gt;&lt;/p&gt;
&lt;h3 id="add-environment-variables"&gt;Add Environment Variables&lt;a class="headerlink" href="#add-environment-variables" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that our build script is working, we can work on "deployment". Deployment to AWS (or other cloud services) requires that you provide credentials. I am not a fan of 
including credentials in my repository, even if they are encrypted. Opting for an environment variable should be more secure, as the credentials are never in your repository
in the first place. &lt;strong&gt;It is important to note that you are still giving your credentials to Travis CI in this case.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To set up environment variables, click on "More Options" and "Settings" within the Travis CI application.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Travis Settings" src="https://andrewwegner.com/images/3-add-variable-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Now scroll down to "Environment Variables". Add the name of the variable and the value. Be sure to leave the default value of "Off" selected. You don't want to display this 
value in the build log. Finally click "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a variable" src="https://andrewwegner.com/images/4-add-variable-2.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've added a second variable for further testing.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a second variable" src="https://andrewwegner.com/images/5-add-variable-3.png"/&gt;&lt;/p&gt;
&lt;p&gt;Notice that variable values are hidden from view after clicking "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Variable values hidden" src="https://andrewwegner.com/images/6-variables-added.png"/&gt;&lt;/p&gt;
&lt;h3 id="check-values-during-build"&gt;Check values during build&lt;a class="headerlink" href="#check-values-during-build" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the variables saved, restart your build. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Restart Build" src="https://andrewwegner.com/images/7-restart-build.png"/&gt;&lt;/p&gt;
&lt;p&gt;When the build has completed, check the build log. Even though we aren't using these values yet, we can see the environment variables exist and are "Secure".&lt;/p&gt;
&lt;p&gt;&lt;img alt='"Secure" Variables' src="https://andrewwegner.com/images/8-variables-secure.png"/&gt;&lt;/p&gt;
&lt;h3 id="accessing-the-values"&gt;Accessing the values&lt;a class="headerlink" href="#accessing-the-values" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;These values are not actually secure. Travis CI is filtering for the values of these environment variables and if the specific string is found, it is scrubbed from
the log. We can see this with a small change to &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;aws_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_ACCESS_KEY_ID'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;aws_secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_SECRET_ACCESS_KEY'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS KEY ID: |{}{}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS SECRET KEY: |{} {}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, we are splitting the values of the environment variables in half. For the &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt; value, you smash these two together. This will match the 
environment variable value, and will not be shown because the pattern still matches the value:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;|{}{}|
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, we split the two halves with a space and print it out. This will be shown, because the extra space no longer matches the exact value of the 
environment variable.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;|{} {}|
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit and push the change to GitHub. In Travis CI, we see the following in the build log:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Accessing the values" src="https://andrewwegner.com/images/9-variables-filtered-by-match.png"/&gt;&lt;/p&gt;
&lt;p&gt;As expected, the first pattern is hidden because it matches the environment variable. The second pattern is shown, because the space in the middle means the pattern no longer 
matches.&lt;/p&gt;
&lt;h3 id="transfer-the-repository"&gt;Transfer the repository&lt;a class="headerlink" href="#transfer-the-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've shown the variables are accessible, it's time to transfer the repository to a new owner. In GitHub, this can be accomplished by going to the repository settings
and going down to the red "danger area". Once you've entered the name of the current repository and the name of the new owner, we wait for the new owner to accept the transfer.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Transfer the repository" src="https://andrewwegner.com/images/10-transfer-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="build-with-the-new-owner"&gt;Build with the new owner&lt;a class="headerlink" href="#build-with-the-new-owner" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Make a change and commit it to the new repository. I simply modified the "Hello World" line:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Hello World from new owner!")
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A new build will kick off. You can see that the repository has transfered to the new owner in the build log. You can also see the environment variables were transfered to the 
new owner. Other than the new owner being listed, the build log shows the same output as before&lt;/p&gt;
&lt;p&gt;&lt;img alt="Everything has transfered" src="https://andrewwegner.com/images/11-build-after-transfer.png"/&gt;&lt;/p&gt;
&lt;h3 id="variables-in-the-ui"&gt;Variables in the UI&lt;a class="headerlink" href="#variables-in-the-ui" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You can also see these variables have transfered by going back to "More Options", then "Settings" in Travis CI. The values are still hidden behind the input password field. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Variables in UI" src="https://andrewwegner.com/images/12-variables-transfered.png"/&gt;&lt;/p&gt;
&lt;h2 id="impact-of-bug"&gt;Impact of bug&lt;a class="headerlink" href="#impact-of-bug" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The example above shows two problems. The bigger problem, in my opinion, is that environment variables are transfered to a new owner. The secondary problem is that "secure"
variables are really just obfuscated. Accessing them is trivial. With this demonstration, we added in a step to show that the variables can be seen by the original
owner. However, it is just as likely that the new owner could introduce such a change after the repository is transfered.&lt;/p&gt;
&lt;p&gt;This bug requires the owner of the repository to perform the "dangerous" GitHub action of transferring a repository. That means it's impact is limited. However, it's just as
likely that the original owner has forgotten that environment variables were set up in Travis CI, an entirely separate system. &lt;/p&gt;
&lt;p&gt;When a GitHub repository is transfered to a new owner, the environment variables in Travis CI should not travel with. This is especially true for the "secure" variables. I'd 
rather that a build breaks after the transfer due to the lack of appropriate variables being set up than having my cloud credentials be sent to a third party. &lt;/p&gt;
&lt;h2 id="mitigation"&gt;Mitigation&lt;a class="headerlink" href="#mitigation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Mitigation of this bug, until Travis CI stops transferring environment variables to new repository owners, requires the original owner to remove the variables prior to 
transferring the repository. One of the steps that the owner should take is to log into Travis CI and ensure all secure variables have been removed from the Travis CI 
environment. This will break the builds, but it will also ensure that private variables aren't leaked unintentionally to a third party.&lt;/p&gt;
&lt;h2 id="repository"&gt;Repository&lt;a class="headerlink" href="#repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The repository for testing is available on &lt;a href="https://github.com/AWegnerGitHub/TravisIssue"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This issue has been reported in the following places:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/travis-ci/travis-ci/issues/9430"&gt;Travis CI Github Issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://news.ycombinator.com/item?id=16737099"&gt;Hacker News&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chat.stackexchange.com/transcript/message/43757867#43757867"&gt;Charcoal HQ&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="technical"></category></entry><entry><title>Installing NextCloud</title><link href="https://andrewwegner.com/installing-nextcloud.html" rel="alternate"></link><published>2018-03-27T23:30:00-05:00</published><updated>2018-03-27T23:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-03-27:/installing-nextcloud.html</id><summary type="html">&lt;p&gt;The ZFS pool is set up. It's time to use all that storage space and install NextCloud.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the last post, I described how I &lt;a href="https://andrewwegner.com/zfs-pool-on-ubuntu.html"&gt;set up ZFS on the new server&lt;/a&gt;. With a newly configured operating system and tons of space, it's time to start using it. One of the goals
I &lt;a href="https://andrewwegner.com/new-house-server.html"&gt;mentioned&lt;/a&gt; when I set up this server was the ability to: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Back up data from all devices in the house automatically. As camera phones have gotten better, we've found that we carry our bulky digital camera less and less. The problem
 with the phone camera is that we need to get the pictures to the computer. I don't want to hunt down a data cable or email the pictures to myself. I'm also not a fan of 
 posting everything to social media. I want my phone to send the pictures to a backup location automatically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm going to accomplish that by hosting an instance of &lt;a href="https://nextcloud.com/"&gt;NextCloud&lt;/a&gt; on this new server. Fortunately, the install process is pretty simple for this one. NextCloud provides 
&lt;a href="https://nextcloud.com/install/"&gt;installation instructions&lt;/a&gt;. When I installed it in mid-February 2018, it was on version 12.x. As of this post, in late March 2018, it's on version 13.x. I'll cover install
and upgrade processes in this post.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;a class="headerlink" href="#installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;a class="headerlink" href="#prerequisites" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For NextCloud you'll need either MySQL or MariaDB. I host it via Apache2, so we'll have that installed too. NextCloud is written in PHP, meaning we need that too.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install apache2 mariadb-server php7.0 libapache2-mod-php7.0 php7.0-mbstring php7.0-curl php7.0-zip php7.0-gd php7.0-mysql php7.0-mcrypt php7.0-bcmath php7.0-xml php7.0-json php7.0-tidy
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Enable the Apache2 rewrite module and restart the web server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo a2enmod rewrite
sudo service apache2 restart
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="set-up-the-database"&gt;Set up the database&lt;a class="headerlink" href="#set-up-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You'll need to create a database for NextCloud. Log into your database using credentials that can create new users and databases. &lt;code&gt;root&lt;/code&gt; will work.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mysql -uroot -p
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, execute a couple SQL statements to create a database and create a user that can access the database. Make sure you use a secure password.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CREATE DATABASE nextcloud;
GRANT ALL PRIVILEGES ON nextcloud.* TO 'nextclouduser'@'localhost' IDENTIFIED BY 'YOURSECUREPASSWORDHERE';
FLUSH PRIVILEGES;
\q
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="download-nextcloud"&gt;Download NextCloud&lt;a class="headerlink" href="#download-nextcloud" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned above, I initially installed version 12 of NextCloud. The latest version can be found on the &lt;a href="https://nextcloud.com/install/"&gt;NextCloud install page&lt;/a&gt;. The URL from that page should be
used instead of the version 12 link in the following code block. The code block below will be putting NextCloud in the default location Ubuntu has Apache look. You can modify
that as needed. If you do so, the virtual host will need to be modified slightly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo cd /tmp &amp;amp;&amp;amp; wget wget https://download.nextcloud.com/server/releases/nextcloud-12.0.2.zip
sudo unzip nextcloud-12.0.2.zip
sudo mv nextcloud/ /var/www/html
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We need to adjust ownership of the files so that Apache can read them. The default user and group, in this case is &lt;code&gt;www-data&lt;/code&gt;. If you have configured your server to use a 
different user or group, adjust this command accordingly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo chown www-data:www-data -R /var/www/html/nextcloud
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="create-the-virtual-host"&gt;Create the Virtual Host&lt;a class="headerlink" href="#create-the-virtual-host" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll be exposing this to the internet and I'll be accessing it via the internet. That means I really don't want to send data unencrypted to or from NextCloud. I'll be setting
up the standard port 80 web server traffic to redirect to the secure port of 443. I cover &lt;a href="https://andrewwegner.com/setup-lets-encrypt.html"&gt;generating SSL certificates&lt;/a&gt; in another post. I use &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;. The keys 
referenced in the virtual host configuration file below created by that process.&lt;/p&gt;
&lt;p&gt;Create a new virtual host.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo touch /etc/apache2/sites-available/nextcloud.conf
sudo ln -s /etc/apache2/sites-available/nextcloud.conf /etc/apache2/sites-enabled/nextcloud.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you need to edit this newly created file &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo nano /etc/apache2/sites-available/nextcloud.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Paste the following:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerAdmin YOUR@EMAILADDRESS
    DocumentRoot /var/www/html/nextcloud/
    ServerName nas.example.com
    Redirect permanent / https://nas.example.com/

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:443&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerName nas.example.com
    DocumentRoot /var/www/html/nextcloud/
    RewriteCond %{THE_REQUEST} ^.*/index\.php
    RewriteRule ^(.*)index.php$ /$1 [R=301,L]
    SSLEngine on
    SSLCertificateFile /path/to/dehydrated/certs/nas.example.com/cert.pem
    SSLCertificateKeyFile /path/to/dehydrated/certs/nas.example.com/privkey.pem
    SSLCertificateChainFile /path/to/dehydrated/certs/nas.example.com/chain.pem
    &lt;span class="nt"&gt;&amp;lt;IfModule&lt;/span&gt; &lt;span class="err"&gt;mod_headers.c&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        Header always set Strict-Transport-Security "max-age=15552000; includeSubDomains"
    &lt;span class="nt"&gt;&amp;lt;/IfModule&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
 &lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are two separate virtual host configurations being created here. The first one, on port 80, is setting up the permanent redirect to the HTTPS site. &lt;/p&gt;
&lt;p&gt;In the secure virtual host configuration, we're setting a small rewrite rule to provide nicer URLs and configuring the SSL certificates to use. The &lt;code&gt;DocumentRoot&lt;/code&gt; variables
should match the path you installed NextCloud into in the previous step.&lt;/p&gt;
&lt;h3 id="application-configuration"&gt;Application Configuration&lt;a class="headerlink" href="#application-configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are a few settings that you need to change in the NextCloud configuration. Do this by editing &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;. If this file doesn't exist, 
you need to copy &lt;code&gt;/var/www/html/nextcloud/config/config.sample.php&lt;/code&gt; to &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The important settings to check are:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- `datadirectory`: In my case, this was pointed at a dataset I created when I [set up my ZFS pool][1]
- `overwrite.cli.url`: Changed to point to the HTTPS version of the URL I want to use
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="complete-the-installation"&gt;Complete the installation&lt;a class="headerlink" href="#complete-the-installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Restart Apache and the navigate to the domain you've set up for your NextCloud installation. I am assuming that you know how to set up a DNS record for the server name
you specified in your virtual host configuration.&lt;/p&gt;
&lt;p&gt;Once you've reached the domain in your web browser, follow the instructions on screen. You'll need the database username and password you created above. You'll also create an
administration user. &lt;/p&gt;
&lt;h3 id="upgrading"&gt;Upgrading&lt;a class="headerlink" href="#upgrading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After some time, NextCloud will update. You should apply these updates, as they'll include new features and security patches. Log into NextCloud using your administration user.
Click on the Gear icon in the upper right and pick "Settings". On the left hand side, select "Basic settings". Half way down the page you'll see the version you are currently
running and whether or not there is an update available. If there is, you can begin the update from here.&lt;/p&gt;
&lt;p&gt;NextCloud does not support skipping versions when updating. This means if you are on version 12, you can upgrade to version 13. You can not, however, upgrade directly from 12 to 14. &lt;/p&gt;
&lt;h2 id="syncing-data"&gt;Syncing data&lt;a class="headerlink" href="#syncing-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;NextCloud provides client applications that allow you to automatically sync data to your install. There are clients for both computers and mobile devices. My use case only
requires the mobile clients right now, but that may change in the future. From the &lt;a href="https://nextcloud.com/install/"&gt;install page&lt;/a&gt;, you can find the clients for Android, iOS and Windows devices. Select
the appropriate installer on your device.&lt;/p&gt;
&lt;p&gt;Once the mobile client is installed, you need to provide the URL to your installation and a username and password that can access your information. I've enabled automatic
uploads of new pictures from my devices only when I'm on a wireless connection (no sense wasting mobile data). This, however, is why I wanted the SSL certificates. The client
doesn't let me whitelist uploading from specific networks. I'd prefer I don't send my pictures unencrypted.&lt;/p&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been using NextCloud for almost three months so far. I love it. Previously, I'd have to find a data cable and remember to manually backup my pictures once and a while. Now,
it "just happens". If I take a picture at home, it's backed up within seconds. If I take a bunch of pictures while I'm out of the house, my pictures are backed up within 
minutes of me getting home. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Setting up a ZFS pool on Ubuntu 16.04</title><link href="https://andrewwegner.com/zfs-pool-on-ubuntu.html" rel="alternate"></link><published>2018-02-15T22:30:00-06:00</published><updated>2018-02-15T22:30:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-02-15:/zfs-pool-on-ubuntu.html</id><summary type="html">&lt;p&gt;With the backup server assembled, it's time to start configuring it. This post covers setting up the ZFS pool for all the data&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/new-house-server.html"&gt;Previously&lt;/a&gt; in this series, the new NAS was assembled. Ubuntu 16.04 has been installed and updated. It's time to do something with all those hard drives! &lt;/p&gt;
&lt;p&gt;I'll be setting the seven 4TB drives in a single &lt;a href="https://en.wikipedia.org/wiki/ZFS"&gt;ZFS&lt;/a&gt; pool. I'm using ZFS for protection against data corruption. It offers several other &lt;a href="https://wiki.ubuntu.com/ZFS"&gt;features&lt;/a&gt; too. I'll
be using dual parity, which means I could lose two drives and be able to recover. The goal is never to test this, but I'd rather not go through a &lt;a href="https://andrewwegner.com/backup-your-data.html"&gt;data loss scare&lt;/a&gt; again.&lt;/p&gt;
&lt;p&gt;Before we begin, it's a good idea to ensure Ubuntu has been updated.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the update complete, let's get started. &lt;/p&gt;
&lt;h2 id="installing-zfs"&gt;Installing ZFS&lt;a class="headerlink" href="#installing-zfs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Installing the ZFS file system is simple on Ubuntu. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install zfs parted
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ta-da! Your system is now capable of setting up ZFS pools. The &lt;code&gt;parted&lt;/code&gt; package will be used to set up a ZFS pool shortly.&lt;/p&gt;
&lt;h2 id="setting-up-our-pool"&gt;Setting up our pool&lt;a class="headerlink" href="#setting-up-our-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Pools are the basic building block of ZFS. A pool is made up of the underlying devices that will store the data. Setting up our ZFS pool requires a little bit of prep work
for our new drives. First, ensure that the &lt;code&gt;zfs&lt;/code&gt; package installed correctly by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool status
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point in the process, you should get the message &lt;code&gt;no pools available&lt;/code&gt;. &lt;/p&gt;
&lt;h3 id="adding-the-gpt-label"&gt;Adding the GPT label&lt;a class="headerlink" href="#adding-the-gpt-label" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'm setting up this pool with brand new drives. We need to add a &lt;code&gt;GPT&lt;/code&gt; label to each disk so that ZFS doesn't complain about disks having an &lt;code&gt;invalid vdev specification&lt;/code&gt; 
when we create the pool. To do this, we'll find the names of our drives first&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ls -l /dev/sd*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On my system, I get a result similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;brw-rw---- 1 root disk 8,   0 Feb 13 09:23 /dev/sda
brw-rw---- 1 root disk 8,   1 Feb 13 09:23 /dev/sda1
brw-rw---- 1 root disk 8,   2 Feb 13 09:23 /dev/sda2
brw-rw---- 1 root disk 8,   5 Feb 13 09:23 /dev/sda5
brw-rw---- 1 root disk 8,  16 Feb 13 09:23 /dev/sdb
brw-rw---- 1 root disk 8,  32 Feb 13 09:23 /dev/sdc
brw-rw---- 1 root disk 8,  48 Feb 13 09:23 /dev/sdd
brw-rw---- 1 root disk 8,  64 Feb 13 09:23 /dev/sde
brw-rw---- 1 root disk 8,  80 Feb 13 09:23 /dev/sdf
brw-rw---- 1 root disk 8,  96 Feb 13 09:23 /dev/sdg
brw-rw---- 1 root disk 8, 112 Feb 13 09:23 /dev/sdh
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We'll be adding the &lt;code&gt;GPT&lt;/code&gt; labels to each of the unformatted drives. The unformatted ones are the listed drives that don't have a numeral as well. For me, that means we'll
be working with &lt;code&gt;sdb&lt;/code&gt;, &lt;code&gt;sdc&lt;/code&gt;, &lt;code&gt;sdd&lt;/code&gt;, &lt;code&gt;sde&lt;/code&gt;, &lt;code&gt;sdf&lt;/code&gt;, &lt;code&gt;sdg&lt;/code&gt; and &lt;code&gt;sdh&lt;/code&gt;. The &lt;code&gt;sda&lt;/code&gt; drive has been formatted and contains partitions already. Those are &lt;code&gt;sda1&lt;/code&gt;, &lt;code&gt;sda2&lt;/code&gt; and &lt;code&gt;sda5&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;For each drive, except &lt;code&gt;sda&lt;/code&gt; in my case, we need to run the &lt;code&gt;parted&lt;/code&gt; command.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo parted /dev/sdb
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will give you a short dialog. All you will need to do is issue the &lt;code&gt;mklabel GPT&lt;/code&gt; command and then quit (using &lt;code&gt;q&lt;/code&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;GNU Parted 3.2
Using /dev/sdb
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) mklabel GPT
(parted) q
Information: You may need to update /etc/fstab.
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="getting-device-ids"&gt;Getting device IDs&lt;a class="headerlink" href="#getting-device-ids" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the &lt;code&gt;GPT&lt;/code&gt; labels are added, we can create our pool. However, we're not going to use the device paths returned above. Theoretically, those can change (especially if you 
replace a drive). That would be bad and mess with the entire ZFS pool. Instead we're going to create the pool by using the device id. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ls -l /dev/disk/by-id/*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This returns output similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;...
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee20f1d3114 -&amp;gt; ../../sdc
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee20f3ba2b9 -&amp;gt; ../../sdg
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2647227b7 -&amp;gt; ../../sdb
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee26490a21e -&amp;gt; ../../sdd
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9c81501 -&amp;gt; ../../sdh
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9e6ab61 -&amp;gt; ../../sdf
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9e6b857 -&amp;gt; ../../sde
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87 -&amp;gt; ../../sda
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part1 -&amp;gt; ../../sda1
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part2 -&amp;gt; ../../sda2
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part5 -&amp;gt; ../../sda5

...
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT -&amp;gt; ../../sdb
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0 -&amp;gt; ../../sdc
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U -&amp;gt; ../../sdg
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4 -&amp;gt; ../../sdf
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA -&amp;gt; ../../sde
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY -&amp;gt; ../../sdd
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS -&amp;gt; ../../sdh
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671 -&amp;gt; ../../sda
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part1 -&amp;gt; ../../sda1
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part2 -&amp;gt; ../../sda2
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part5 -&amp;gt; ../../sda5
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that both formats symlink to the same location. This means you can pick which ever format you like better. However, I recommend the second one that contains the 
device serial number. It'll make it easier to determine problem disks in the future. &lt;/p&gt;
&lt;h3 id="create-the-pool"&gt;Create the pool&lt;a class="headerlink" href="#create-the-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've determined the device ides for each of our hard drives, it's time to actually create the pool. As I mentioned above, we'll be creating using dual parity
(&lt;code&gt;raidz2&lt;/code&gt;). We'll be naming our pool &lt;code&gt;data&lt;/code&gt;. Once this command is complete, &lt;code&gt;/data&lt;/code&gt; will be where this pool resides.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool create data raidz2 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a little while, but a surprisingly smaller amount of time than I initially expected. &lt;/p&gt;
&lt;p&gt;Once the creation is complete, take a look at the status of your new pool:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool status

  pool: data
 state: ONLINE
  scan: none requested
config:

        NAME                                          STATE     READ WRITE CKSUM
        data                                          ONLINE       0     0     0
          raidz2-0                                    ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS  ONLINE       0     0     0

errors: No known data errors
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That last line is important. No known data errors is good. &lt;/p&gt;
&lt;h2 id="create-datasets"&gt;Create datasets&lt;a class="headerlink" href="#create-datasets" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Where pools are the basic building blocks of ZFS, datasets is a term for a ZFS file system, volume, snapshot or clone. Each dataset can be managed and configured differently.
This means that you can compress one dataset, but leave the others alone. You can put a quota on one, but leave the others without a quota. Creating a dataset is pretty easy:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd /
sudo zfs create data/storage
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a dataset that exists at &lt;code&gt;/data&lt;/code&gt; named &lt;code&gt;storage&lt;/code&gt;. You can have child datasets that inherit attributes from parents (or even grandparents) by doing something
like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zfs create data/storage/music
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create the new dataset at &lt;code&gt;/data/storage&lt;/code&gt; named &lt;code&gt;music&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you've set up your datasets, you can see they were all created and how much space they have available by issuing &lt;code&gt;sudo zfs list&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="set-up-complete"&gt;Set up complete&lt;a class="headerlink" href="#set-up-complete" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With that, we've finished setting up ZFS on Ubuntu 16.04. I set up a few datasets for my purposes. I'm one step closer to getting this running and handling all of the 
digital data in the house. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Choosing an ORM library for a new project</title><link href="https://andrewwegner.com/choosing-orm-library.html" rel="alternate"></link><published>2017-04-26T14:30:00-05:00</published><updated>2017-04-26T14:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-04-26:/choosing-orm-library.html</id><summary type="html">&lt;p&gt;A discussion about how a team picked an ORM library for a new project.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="project-history"&gt;Project History&lt;a class="headerlink" href="#project-history" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt; project is over three years old at this point. It's grown from a small python script to a 
decently sized application that integrates with another project. In that time, it's expanded what types of spam and
patterns it looks for, what chat rooms it posts to, what external services it integrates with and how permissions to
use the system are determined. &lt;/p&gt;
&lt;p&gt;A lot has changed under the hood. I was hoping to put a cool chart here showing code change over time, but some early
decisions with the project really throw off the chart. Using a &lt;a href="https://erikbern.com/2016/12/05/the-half-life-of-code.html"&gt;Ship of Theseus&lt;/a&gt; analogy for code, you can see how 
much has changed. The basic idea is, if a ship leaves port and replaces every plank along it's journey, is it still the 
same ship when it returns? With code, the idea is to apply this to lines of code in an application.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-all.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus" src="https://andrewwegner.com/images/smokey-git-theseus-all.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="what-happened-in-2014"&gt;What happened in 2014?!&lt;a class="headerlink" href="#what-happened-in-2014" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In late 2014, the project attempted their first machine learning method of detecting spam. In this time period, a 
&lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/102aa9c64edafb7f5fef5ba16414f4cefad03d64"&gt;commit&lt;/a&gt; was added that added about 200,000 lines of code to the project. This was almost all training data for a 
Bayesian algorithm. It wasn't needed and probably shouldn't have been added to the main repository. Unfortunately, it 
stayed in the repository for over a year and was finally &lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/68d49ccc0b4981a4ebe91d993f42643542e44d80"&gt;removed&lt;/a&gt; in late 2015. This is the cause of the weird graph 
above, and why almost everything added in 2014 looks like it's missing in later years.&lt;/p&gt;
&lt;h3 id="what-has-really-changed"&gt;What has really changed?&lt;a class="headerlink" href="#what-has-really-changed" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After eliminating that bayesian directory from git history, you can get a much better idea of how much has changed. &lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-filtered.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus - Filtered" src="https://andrewwegner.com/images/smokey-git-theseus-filtered.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Very little of the original code, written in 2014, remains untouched. The explosion in code after that is due to
new detection patterns, chat commands (and a rewrite), integration with MetaSmoke and the introduction of blacklists.&lt;/p&gt;
&lt;p&gt;Even more dramatically, you can see how long a line of code is expected to survive in the code base.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://andrewwegner.com/images/smokey-git-theseus-survival.png"&gt;&lt;img alt="SmokeDetector - Line Survival Rate" src="https://andrewwegner.com/images/smokey-git-theseus-survival.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within one year, the team is removing over 40% what's been committed to the repository. Looking at these commits, 
it was determined that a vast majority aren't even &lt;em&gt;code&lt;/em&gt;. They are new items to blacklist or new patterns to detect. &lt;/p&gt;
&lt;h2 id="enter-the-database"&gt;Enter the database&lt;a class="headerlink" href="#enter-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of this type of data can be stored in a database and managed outside of code. In early 2017, those discussions 
started taking place. Several team members come from a Ruby background and were familiar with it's &lt;a href="https://en.wikipedia.org/wiki/Object-relational_mapping"&gt;ORM&lt;/a&gt; method of
accessing databases. They wanted something similar when a database was brought into SmokeDetector.&lt;/p&gt;
&lt;p&gt;A bit of research was done and it was narrowed down to &lt;a href="http://docs.peewee-orm.com/en/latest/"&gt;peewee&lt;/a&gt; and &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. &lt;/p&gt;
&lt;h3 id="how-to-choose"&gt;How to choose?&lt;a class="headerlink" href="#how-to-choose" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Fortunately for the SmokeDetector team, there weren't any strong opinions either way. The biggest reason for choosing
one over the other came down to a &lt;a href="https://www.reddit.com/r/Python/comments/4tnqai/choosing_a_python_ormpeewee_vs_sqlalchemy/d5jyuug/"&gt;comment made by the peewee author&lt;/a&gt; on reddit. They state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[...] SQLAlchemy is the gold standard for ORM in the Python world. It has a very active community and a maintainer 
who is committed to excellence. If you're a glass-half-empty guy, to put it another way, you can't go wrong if you 
choose SQLAlchemy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The weaknesses they list for using their own package is the smaller ecosystem, support and number of developers.&lt;/p&gt;
&lt;h3 id="technical-differences"&gt;Technical differences&lt;a class="headerlink" href="#technical-differences" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;That's a boring story though. Not to be deterred from such a glowing review from a competitor, I wanted to see what the
technical differences were between the two solutions.&lt;/p&gt;
&lt;p&gt;To that end, I put together a small Python notebook showing the &lt;a href="https://gist.github.com/AWegnerGitHub/201dbaf09740f9ecd797c32ebfc15872"&gt;differences between peewee and SQLAlchemy&lt;/a&gt; in a 
handful of tests. These tests included inserting two settings in an SQLite database, retrieving one, inserting a large
list of users and then retrieving a subset of those users.&lt;/p&gt;
&lt;p&gt;The results were...unremarkable. &lt;/p&gt;
&lt;p&gt;&lt;a href="{filename}peewee-vs-sqlalcheme-results.png"&gt;&lt;img alt="peewee vs SQLAlchemy results" src="{filename}peewee-vs-sqlalcheme-results.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The two libraries each took two tests (out of four) for being faster than the other. In both cases where SQLAlchemy was
faster, it was between two and six times faster. Where peewee was faster it was between a fraction faster and twice as
fast. &lt;/p&gt;
&lt;p&gt;The time scales are so small though, and SmokeDetector doesn't need to have thousands, hundreds or even tens of hits to
the database a second. A hundred extra milliseconds isn't going to cripple anything it handles.&lt;/p&gt;
&lt;p&gt;Thus, the choice was made based on the recommendation of the author of the peewee library. SQLAlchemy has a larger
community and better support. &lt;/p&gt;</content><category term="technical"></category><category term="programming"></category></entry><entry><title>My experiences releasing a package to PyPI</title><link href="https://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html" rel="alternate"></link><published>2016-03-15T12:26:00-05:00</published><updated>2016-03-15T12:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-03-15:/my-experiences-releasing-a-package-to-pypi.html</id><summary type="html">&lt;p&gt;I released StackAPI to PyPI. This post talks about my experiences.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In some of my &lt;a href="http://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;other projects&lt;/a&gt;, I've needed to make extensive use of the Stack Exchange API. I built a small library - StackAPI - to assist in this task and released it on Python's &lt;a href="https://pypi.python.org/pypi/StackAPI"&gt;PyPI repository&lt;/a&gt;. This post is going to cover some of the technical decisions and issues I ran into while going through this process. This was my first project being released to PyPI.&lt;/p&gt;
&lt;p&gt;My goals when releasing this were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clean up my own code so that it is usable by others&lt;/li&gt;
&lt;li&gt;Improve the documentation and host the documentation on &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automatically release it to PyPI, if it passes basic tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those goals sound simple. In the future, they probably will be, but for this first release it wasn't as simple as I was hoping.&lt;/p&gt;
&lt;h2 id="project-layout"&gt;Project Layout&lt;a class="headerlink" href="#project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before this project, I'd written modules and libraries that were used by myself (for personal projects) or as part of a larger application (for work). In both cases, though, I had a directory structure that looked something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/project_root
    /mymodule
        __init__.py
        mymodule.py
    __init__.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This was close to the end goal, but lacked some files in the &lt;code&gt;project_root&lt;/code&gt; that were needed for a proper install via &lt;code&gt;pip&lt;/code&gt;. The important file that was missing was &lt;code&gt;setup.py&lt;/code&gt;. I needed this file to ensure that everything would install with a simple &lt;code&gt;pip install stackapi&lt;/code&gt; &lt;/p&gt;
&lt;h3 id="setuppy"&gt;setup.py&lt;a class="headerlink" href="#setuppy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.py"&gt;&lt;code&gt;setup.py&lt;/code&gt;&lt;/a&gt; is pretty basic and available on GitHub. There are a couple important things though.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt;: This is needed, but I didn't want to have to constantly remember to update this when pushing a version to PyPI. This was one of my first criteria when starting the project. I wanted to automate as much as I could, and versioning was at the top of that list. It's small, but easy to forget and keep syncronized across all the files in the project. I decided to utilize &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; and &lt;a href="http://www.fabfile.org/"&gt;Fabric&lt;/a&gt; to manage this specific field (both here and elsewhere in the project).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;install_requires&lt;/code&gt;: StackAPI is built in the fantasitc &lt;a href="http://docs.python-requests.org/en/master/"&gt;Requests&lt;/a&gt; library. To ensure this was installed when StackAPI was install, it was needed in this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tests_require&lt;/code&gt;: The testsuite I build utilizes the &lt;code&gt;mock&lt;/code&gt; library. I don't want that to be installed if the developer isn't running the tests, so it is added to this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_suite&lt;/code&gt;: I wanted developers to be able to run &lt;code&gt;python setup.py test&lt;/code&gt; to execute the test suite. To do so, I had to point to the where the tests were being executed from.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The rest of &lt;code&gt;setup.py&lt;/code&gt; seemed to be fairly standard when compared to other Python libraries.&lt;/p&gt;
&lt;h3 id="bumpversion-and-fabric"&gt;Bumpversion and Fabric&lt;a class="headerlink" href="#bumpversion-and-fabric" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned, I wanted to automate any versioning that was required. To do so, I used the &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; library and wrote a small &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/fabfile.py"&gt;Fabric&lt;/a&gt; script to handle it automatically. &lt;code&gt;bumpversion&lt;/code&gt; uses a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.cfg"&gt;config file&lt;/a&gt;, to determine what it is going to do. I configured it to automatically create a commit and a new git tag for each version. I then pointed to a couple files where the current version is listed. When &lt;code&gt;bumpversion&lt;/code&gt; is executed, it will change the version in each of those files to the new version. It will then create a single commit to the git repository with a commit message similar to &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bump version: 0.1.6 → 0.1.7&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is nice and clean. It tags the commit for me, which is useful later, when I want to push the change to PyPI.&lt;/p&gt;
&lt;p&gt;To make running &lt;code&gt;bumpversion&lt;/code&gt; a bit easier, I utilized a Fabric routine I found &lt;a href="https://gist.github.com/jbarratt/85c91d7b904462702892"&gt;online&lt;/a&gt; and adjusted it for my purposes. When I run &lt;code&gt;fab release&lt;/code&gt;, all of the &lt;code&gt;bumpversion&lt;/code&gt; 'stuff' occurs. Then I just have to push the commit (and new tag) to GitHub. &lt;/p&gt;
&lt;h3 id="final-project-layout"&gt;Final Project Layout&lt;a class="headerlink" href="#final-project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final project layout I settled on was this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/stackapi
    /docs
        ...
    /stackapi
        __init__.py
        stackapi.py
    /tests
    .gitignore
    .travis.yml
    fabfile.py
    setup.cfg
    setup.py
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="read-the-docs"&gt;Read the Docs&lt;a class="headerlink" href="#read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="configure-the-project"&gt;Configure the project&lt;a class="headerlink" href="#configure-the-project" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In the final project layout, you can see there is a &lt;code&gt;docs&lt;/code&gt; directory. One of my goals was to make this library usable and understandable by other developers. A good part of that means having decent documentation. I spent way more time than I expected cleaning the documentation in the code and creating documentation with examples. Most of that time was spent learning the sphinx documentation style and ReStructuredText, which Read the Docs utilizes.&lt;/p&gt;
&lt;p&gt;The first step in this process was installing and setting up the initial configuration for the documentation:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install sphinx sphinx-autobuild
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, I created the &lt;code&gt;docs&lt;/code&gt; directory and switched to it and ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sphinx-quickstart
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This starts a short, interactive, wizard. Fill out the questions. At the end of this, it creates a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/docs/conf.py"&gt;&lt;code&gt;conf.py&lt;/code&gt;&lt;/a&gt; file in the &lt;code&gt;docs&lt;/code&gt; directory. The rest of the &lt;a href="https://github.com/AWegnerGitHub/stackapi/tree/master/docs"&gt;documentation&lt;/a&gt; is ReStructuredText files.&lt;/p&gt;
&lt;p&gt;To see how the documentation looks, from the &lt;code&gt;docs&lt;/code&gt; directory, run:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;make html
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates a &lt;code&gt;_build&lt;/code&gt; directory. If you open &lt;code&gt;_build/html/index.html&lt;/code&gt;, the documentation can be browsed locally. I do not commit this directory to git, though. It is ignored in &lt;code&gt;.gitignore&lt;/code&gt;, as a user can regenerate it at will.&lt;/p&gt;
&lt;h3 id="configure-read-the-docs"&gt;Configure Read the Docs&lt;a class="headerlink" href="#configure-read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I was satisfied with how the documentation looked, I had to configure Read the Docs to read my GitHub repository. To repeat those steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sign up (or log in) at &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt; (part of this will be associating the account to a GitHub account)&lt;/li&gt;
&lt;li&gt;Visit your &lt;a href="https://readthedocs.org/dashboard/"&gt;dashboard&lt;/a&gt; and click "Import a project"&lt;/li&gt;
&lt;li&gt;Fill out the form, but in my case the defaults were all appropriate. Do note that URLs are case sensitive.&lt;/li&gt;
&lt;li&gt;Click "Create". This is the first version of your documentation.&lt;/li&gt;
&lt;li&gt;To keep the code updating as you update GitHub, log into GitHub and go to the repository's "Settings" page.&lt;/li&gt;
&lt;li&gt;Click "Webhooks &amp;amp; Services"&lt;/li&gt;
&lt;li&gt;Click "Add Service"&lt;/li&gt;
&lt;li&gt;Select "ReadTheDocs" and add the service&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, each time you push a change to the repository, a new set of documents will be built. I then added the Read the Docs badge to my &lt;code&gt;README.rst&lt;/code&gt; for a simple link to the detailed documentation.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt; &lt;span class="ow"&gt;image&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt; https://readthedocs.org/projects/stackapi/badge/?version=latest
&lt;span class="nc"&gt;:target:&lt;/span&gt; &lt;span class="nf"&gt;http://stackapi.readthedocs.org/en/latest/?badge=latest&lt;/span&gt;
&lt;span class="nc"&gt;:alt:&lt;/span&gt; &lt;span class="nf"&gt;Documentation Status&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="force-rebuild-of-docs"&gt;Force rebuild of docs&lt;a class="headerlink" href="#force-rebuild-of-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Toward the very end of this project, Read the Docs had a minor hiccup and failed on building my documentation. I didn't want to force a build by making a fake commit. Instead, Read the Docs provides the information needed to force a rebuild. It requires a very simple &lt;code&gt;POST&lt;/code&gt; to the Post Commit Hook they provide. In my case, this was as simple as running this command (provided from the Dashboard):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -X POST https://readthedocs.org/build/stackapi
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="pypi"&gt;PyPI&lt;a class="headerlink" href="#pypi" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Nearing the end of the journey, it was time to see what exactly PyPI required. The first step was setting up an account on both the Test and Production instances of PyPI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PiPY Test: http://testpypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;li&gt;PyPI Live: https://pypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having one on both was important while testing. It meant that I didn't have to send broken versions to the live PyPI server, and I could adjust ReStructuredText formatting issues without requiring another release to PyPI. Each time a version is pushed to PyPI it &lt;strong&gt;must&lt;/strong&gt; have a new version number. By using the test instance, I could use as many of these fake versions as needed to fix things. Hooray for test environments!&lt;/p&gt;
&lt;p&gt;Before we perform this step automatically, we need to test that the PyPI accounts work. By following portions of a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;"First Time with PyPI"&lt;/a&gt; tutorial, I focused by steps down to these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a &lt;code&gt;.pypirc&lt;/code&gt; file in your home directory - not your project directory. This won't be required once Travis CI is set up and configured, so having the passwords in this, temporarily, wasn't an issue because I eventually deleted the file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The file looks like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[distutils]&lt;/span&gt;
&lt;span class="na"&gt;index-servers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&lt;/span&gt;
&lt;span class="s"&gt;  pypi&lt;/span&gt;
&lt;span class="s"&gt;  pypitest&lt;/span&gt;

&lt;span class="k"&gt;[pypi]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://pypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;

&lt;span class="k"&gt;[pypitest]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://testpypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Register the package on PyPI Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Register the package on PyPI Live: &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Live, &lt;em&gt;if&lt;/em&gt; you're ready for your first release. Remember, once a version is released to PyPI, it can't be used again (or overwritten): &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all of the above passed to your satisfaction, you can remove the &lt;code&gt;.pypirc&lt;/code&gt; file and move on to configuring Travis CI.    &lt;/p&gt;
&lt;h2 id="travis"&gt;Travis&lt;a class="headerlink" href="#travis" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The last step in this process will be using Travis CI to perform some basic tests and, if this was a new release, push the changes to PyPI. The Travis config file is available on &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;GitHub&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;My goal is to support 'modern' Python with this library. I've configured Travis to test against multiple versions of Python, ranging from 2.7 to 3.5. StackAPI is installed using &lt;code&gt;python setup.py -q install&lt;/code&gt;. Then the test suite is run. &lt;/p&gt;
&lt;p&gt;The important bits are in the &lt;code&gt;deploy&lt;/code&gt; section. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="n"&gt;branch&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If there is a new git tag pushed to GitHub, and the tests pass, Travis CI will push the code to PyPI. Since &lt;code&gt;bumpversion&lt;/code&gt; makes a new git tag with each new version, this works perfectly. &lt;/p&gt;
&lt;p&gt;This does require that my password be included in the yml file. To keep this secure, I utilized the &lt;a href="https://blog.travis-ci.com/2013-01-14-new-client/"&gt;Travis Command Line Client&lt;/a&gt; (&lt;code&gt;gem install travis&lt;/code&gt;). In my local directory, I then ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;travis encrypt --add deploy.password
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This added the password to the YML file. &lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This was the first time I've released something to PyPI. It took a lot more set up than I expected it would take. However, now that I've gone through the process, gotten used to the ReStructuredText format that Sphinx and Read the Docs require, and set up PyPI for one project, I think it'll be fairly simple to do in the future. Most of the work is getting the other services to talk with GitHub and practicing good developer habits (documentation...).&lt;/p&gt;
&lt;h2 id="all-stackapi-links"&gt;All StackAPI Links&lt;a class="headerlink" href="#all-stackapi-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of these links are to the various places that StackAPI lives on the internet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: https://github.com/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;: http://stackapi.readthedocs.org/en/latest/&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TravisCI&lt;/strong&gt;: https://travis-ci.org/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPI&lt;/strong&gt;: https://pypi.python.org/pypi/StackAPI&lt;/li&gt;
&lt;/ul&gt;</content><category term="technical"></category></entry><entry><title>How I built a Flask application that integrates with Travis CI and OpenShift</title><link href="https://andrewwegner.com/how-i-set-up-openshift-travisci-and-flask.html" rel="alternate"></link><published>2015-12-11T09:15:00-06:00</published><updated>2015-12-12T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-12-11:/how-i-set-up-openshift-travisci-and-flask.html</id><summary type="html">&lt;p&gt;A walkthrough on how I set up a Flask application on OpenShift and used TravisCI to deploy it&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since I &lt;a href="https://andrewwegner.com/thanks-for-all-the-fish.html"&gt;shut down&lt;/a&gt; Vipers early this year, I've been itching to do &lt;em&gt;something&lt;/em&gt; web related. Web technologies aren't my best technical skill, but I like trying out new things and learning something in the process. I use Python at work. I like Python a lot. With Christmas and New Years coming up, I want to have a project during my down time. My goal is to get a &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; application built and then deployed to &lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt;. Part of this deployment is to utilize &lt;a href="https://travis-ci.org/"&gt;TravisCI&lt;/a&gt;. I'm planning on using &lt;a href="http://pytest.org/latest/"&gt;pytest&lt;/a&gt; and &lt;a href="https://hypothesis.readthedocs.org/en/latest/"&gt;hypothesis&lt;/a&gt; for my test suite. Finally, I want to use my own (sub)domain, instead of the provided &lt;code&gt;rhcloud&lt;/code&gt; one.&lt;/p&gt;
&lt;p&gt;Of these three technologies, I've used only Flask before. The &lt;a href="https://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;comment flagging bot&lt;/a&gt; I built has a dashboard built in Flask. I've never used OpenShift or TravisCI. I selected OpenShift because it has a couple &lt;a href="http://www.paasify.it/compare/heroku-vs-openshift%20online"&gt;features&lt;/a&gt; I want that Heroku doesn't. The biggest one, according to the previous link, was that OpenShift has support for MySQL and Heroku doesn't (surprisingly). I want to use TravisCI and automated testing, because one of my goals for next year at work is to introduce automated tested to our development. (I work with Engineers, not coders...that's my excuse and it's a bad excuse, so I'm going to try and fix it.) To get ready for that goal, I want to test out a system that does continuous integration/automated testing. Both OpenShift and Travis CI provide me with free services. Hypothesis and py.test provide me with a way to generate comprehensive test conditions. &lt;/p&gt;
&lt;h2 id="openshift-set-up"&gt;OpenShift set up&lt;a class="headerlink" href="#openshift-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Signing up for OpenShift was easy. Fill out the form, provide an email address - though they don't like email addresses with &lt;code&gt;+&lt;/code&gt; signs, which is disappointing - and then click the link they email back to you. &lt;/p&gt;
&lt;p&gt;Next, the &lt;code&gt;rhc&lt;/code&gt; OpenShift client tools are needed. This is a Ruby package. I have no experience with Ruby, so I needed to install Ruby as well. I ran into a problem almost immediately. The &lt;a href="https://developers.openshift.com/en/managing-client-tools.html"&gt;page&lt;/a&gt; for installing these tools says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenShift rhc can be run on any operating system with Ruby 1.8.7 or higher assuming you have the requisite user permissions to install programs. Instructions for specific operating systems are provided below. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Based on that, I figured I'd install the latest version of &lt;a href="http://rubyinstaller.org/downloads/"&gt;Ruby&lt;/a&gt;. At the time I tested this, that was 2.2.3. Unfortunately, when I ran the command to install the &lt;code&gt;rhc&lt;/code&gt; tools, I received an error. After a bit of Googling, I found that it doesn't like 2.2x. So, I installed 2.1.7 instead. Next, I ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gem install rhc
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This installs several gems and took a few minutes to complete. Next,&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc setup
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This started the OpenShift setup wizard. It consisted of filling out the few prompts and letting it generate an SSH key and then connecting to my account. Remember the Namespace you select. Again, this took a few minutes.&lt;/p&gt;
&lt;h2 id="flask-setup"&gt;Flask setup&lt;a class="headerlink" href="#flask-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next step was to set up my first "Gear". This would be the Flask application. I'll work on the database next. First, I just want Python and Flask to function properly. Fortunately, this is very easy, as OpenShift has a Flask template.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc app create testapp python-2.7 --from-code=https://github.com/openshift-quickstart/flask-base.git
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am utilizing Python 2.7, because that is the recommendation from the Flask team.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;testapp&lt;/code&gt; can be any alphanumeric string. This is the name that will appear in the Web Console. A specific note, &lt;code&gt;_&lt;/code&gt; is not alphanumeric. I'm getting the feeling that OpenShift doesn't like "special" characters.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--from-code&lt;/code&gt; parameter will download that repository and use it as the base of your application. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, Flask can be run locally using:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python app.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The application can be pushed back to OpenShift at this point and there should be a functional page on your OpenShift domain. In your command line, from the directory of your project:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git add --all
git commit -m "Adding Flask application"
git push
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a moment. At the end, you should see these lines in your command prompt:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Git&lt;/span&gt; &lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Receive&lt;/span&gt; &lt;span class="n"&gt;Result&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Activation&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Deployment&lt;/span&gt; &lt;span class="n"&gt;completed&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If all three are a success, then you should be able to visit your URL. Your URL is a combination of your selected Namespace and the application name you created.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;http://&amp;lt;namespace&amp;gt;-&amp;lt;testapp&amp;gt;.rhcloud.com/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should show a "Welcome to Flask on OpenShift" page. If you append &lt;code&gt;/test&lt;/code&gt; to your URL, you'll get a message that says "It's Alive!"&lt;/p&gt;
&lt;p&gt;If it doesn't, you can check your error logs by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc tail -a &amp;lt;testapp&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="mysql-setup"&gt;MySQL setup&lt;a class="headerlink" href="#mysql-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Next, I set up my application to utilize MySQL. It's the database I have the most experience with, so I decided to keep that aspect of this project simple for myself. The first step was to add a MySQL 5.5 cartridge to my test gear (OpenShift terminology). I did this in the OpenShift web console. The UI provided me with the option to install various databases and one of those was MySQL. Clicking the link caused a few second delay as it was set up, and then I was presented with login credentials to my database. Step one...done.&lt;/p&gt;
&lt;p&gt;The next step is installing the correct Python modules to utilize MySQL. I selected &lt;a href="http://www.pymysql.org/"&gt;PyMySQL&lt;/a&gt; (again, experience) and &lt;a href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. I added these to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;. The idea behind doing it in both places is to make life easy for myself in the future. Additionally, the quick tutorials I've looked at for TravisCI encourage the usage of &lt;code&gt;requirements.txt&lt;/code&gt;, while it seems OpenShift uses the &lt;code&gt;setup.py&lt;/code&gt;. I'll fix that eventually, but getting it set up initially, this will be fastest.&lt;/p&gt;
&lt;p&gt;Add these to &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sqlalchemy==1.0.9
pymysql==0.6.7
Flask-SQLAlchemy==2.1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add this to the &lt;code&gt;install_requires&lt;/code&gt; list in &lt;code&gt;setup.py&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sqlalchemy==1.0.9','pymysql==0.6.7','Flask-SQLAlchemy==2.1'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The nice thing about OpenShift is that the credentials to the database are placed in &lt;a href="https://developers.openshift.com/en/managing-environment-variables.html#database-variables"&gt;environment variables&lt;/a&gt;, so I don't need to embed the passwords, connections strings, or anything potentially sensitive in my code. For MySQL these are available as:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Variable Name               |   Purpose
------------------------------------------------
OPENSHIFT_MYSQL_DB_HOST     |   The host name or IP address used to connect to the database.
OPENSHIFT_MYSQL_DB_PORT     |   The port the database server is listening on.
OPENSHIFT_MYSQL_DB_USERNAME |   The database administrative user name.
OPENSHIFT_MYSQL_DB_PASSWORD |   The database administrative user’s password.
OPENSHIFT_MYSQL_DB_SOCKET   |   An AF socket for connecting to the database (for non-scaled apps only).
OPENSHIFT_MYSQL_DB_URL      |   Database connection URL.
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="utilizing-the-database"&gt;Utilizing the database&lt;a class="headerlink" href="#utilizing-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Setting up SQLAlchemy and MySQL is fairly easy. I tested this with a simple table and ensured that it appeared in the database as expected.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;class&lt;/span&gt; &lt;span class="nx"&gt;User&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;__tablename__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'users'&lt;/span&gt;
    &lt;span class="nx"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'user_id'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;primary_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nx"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few adjustments were made to the import statements of the Flask application:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask_sqlalchemy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SQLAlchemy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A couple variables were created and loaded:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;app.config.from_pyfile('flaskapp.cfg')
db = SQLAlchemy(app)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the &lt;code&gt;flaskapp.cfg&lt;/code&gt; file was modified to include these two lines:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SQLALCHEMY_DATABASE_URI = os.environ['OPENSHIFT_MYSQL_DB_URL'] + os.environ['OPENSHIFT_APP_NAME]
SQLALCHEMY_ECHO = False
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="remote-mysql-access"&gt;Remote MySQL Access&lt;a class="headerlink" href="#remote-mysql-access" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I like to use &lt;a href="https://www.mysql.com/products/workbench/"&gt;MySQL Workbench&lt;/a&gt; while building and testing to watch what's happening in the database. To use that with OpenShift, I had to jump through a few small hoops. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open MySQL Workbench and create a new connection&lt;/li&gt;
&lt;li&gt;Give the connection a name&lt;/li&gt;
&lt;li&gt;In "Connection Method", select "Standard TCP/IP over SSH"&lt;/li&gt;
&lt;li&gt;The SSH Hostname is the full name of your OpenShift gear where MySQL is installed. It should look like &lt;code&gt;namespace-appname.rhcloud.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The SSH Username is the gear's Unique Identifier. This can be found by looking at the &lt;code&gt;OPENSHIFT_GEAR_UUID&lt;/code&gt; environment variable. It can also be found in the web console, but looking at the "remote access" section. It shows a connection string. You need the username portion. This is the part that appears before the &lt;code&gt;@&lt;/code&gt; in the &lt;code&gt;ssh longuniquestring@namespace-appname.rhcloud.com&lt;/code&gt; command. &lt;/li&gt;
&lt;li&gt;Set the SSH key file. On Windows this is in &lt;code&gt;\Users\&amp;lt;username&amp;gt;\.ssh\id_rsa&lt;/code&gt; by default&lt;/li&gt;
&lt;li&gt;Set MySQL Hostname equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_HOST&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set Username equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_USERNAME&lt;/code&gt; (this was also provided to you when you installed MySQL)&lt;/li&gt;
&lt;li&gt;See Password equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_PASSWORD&lt;/code&gt; (again, this was provided to you when MySQL was installed)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="travisci-setup"&gt;TravisCI setup&lt;a class="headerlink" href="#travisci-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I want to play with automated testing. The idea behind this is to get a jump start on a goal for next year at work and to learn something new. I'd like to utilize Travis CI to perform the tests and if they pass, deploy to OpenShift. If the tests fail, I don't want to push a broken build to OpenShift. That's the goal...we'll see how it turns out. But, the first step is getting Travis CI and OpenShift talking to one another.&lt;/p&gt;
&lt;p&gt;Travis CI integrates with GitHub, so what I'm going to do in reality is push to GitHub and let Travis CI pick up the changes. From there, it will perform it's tests. If the tests pass, it will push the commit to OpenShift.&lt;/p&gt;
&lt;p&gt;On GitHub, create a new repository for your source. This is where you will be pushing your code for Travis CI to pick up.&lt;/p&gt;
&lt;p&gt;From your OpenShift directory (which is already a git repository):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git remote rename origin openshift
git remote add origin https://github.com/&amp;lt;USER&amp;gt;/&amp;lt;repositoryname&amp;gt;.git
git push -u origin master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This resets the origin to point to your new GitHub repository and sets up a new remote. Then it pushes the changes to GitHub.&lt;/p&gt;
&lt;p&gt;Log into your &lt;a href="https://travis-ci.org/profile"&gt;Travis CI profile page&lt;/a&gt;. Make sure you are logged into GitHub first, as this will create the profile automatically. Press the "Sync now" button at the top of the page to pull a list of all of your repositories. Once that is done, find the repository you just set up, and enable integration with that repository.&lt;/p&gt;
&lt;p&gt;Next you need to set up Travis CI and the &lt;code&gt;.travis.yml&lt;/code&gt; file. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gem install travis
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install a Ruby script that assists in this process. If you get an error when running this, you need to create an empty &lt;code&gt;.travis.yml&lt;/code&gt; file first and then run the command again.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;travis setup openshift
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fill out the prompts. Defaults should be fine in most cases, but do pay attention to "OpenShift application name". If your GitHub repository is named differently than your OpenShift application name, the default for this prompt will be incorrect.&lt;/p&gt;
&lt;p&gt;One last note, for a quick test you can change the &lt;code&gt;script&lt;/code&gt; section to &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This forces the tests to pass. Once you've written tests, you can do something like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script:
    - py.test
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run your test scripts, utilizing &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Deploy these changes to GitHub:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git add .travis.yml
git commit -m "Deploying Travis"
git push origin master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will commit and push the changes to GitHub. A few seconds later, if you are watching Travis CI, you'll see it notices the new commit and starts running tests. If you tests complete with a status code of &lt;code&gt;0&lt;/code&gt; (successful), it will deploy the changes to OpenShift. If the tests fail (any other status code), it will not deploy to OpenShift.&lt;/p&gt;
&lt;h2 id="pytest-setup"&gt;py.test setup&lt;a class="headerlink" href="#pytest-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Setting up the testing frame work involves a few Python modules. These need to be added to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pytest&amp;gt;=2.8.0
hypothesis==1.16.0
pytest-runner==2.6.2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The next step is setting up some quick integration with &lt;code&gt;setup.py&lt;/code&gt;, so that users can run &lt;code&gt;python setup.py test&lt;/code&gt; and execute your tests.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;setup.py&lt;/code&gt;, add (or edit) the &lt;code&gt;setup_requires&lt;/code&gt; list to include &lt;code&gt;pytest-runner&lt;/code&gt;. Add (or edit) the &lt;code&gt;tests_require&lt;/code&gt; list to include &lt;code&gt;pytest&lt;/code&gt;. I also added the following to my &lt;code&gt;setup.cfg&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[aliases]&lt;/span&gt;
&lt;span class="na"&gt;test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;pytest&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I modified my &lt;code&gt;setup_requires&lt;/code&gt; list a bit, so that it's conditional. Since this would install the &lt;code&gt;pytest-runner&lt;/code&gt; on every call to &lt;code&gt;setup.py&lt;/code&gt;, even when the module wouldn't be called, I wanted the runner to only be required when &lt;code&gt;pytest&lt;/code&gt; is utilized.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'pytest'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ptr'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intersection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pytest_runner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pytest-runner'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;setup_requires&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="c1"&gt;#... Other requirements here&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pytest_runner&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I wanted to test that my tests were working correctly. I created a &lt;code&gt;tests&lt;/code&gt; directory, which is where I plan on storing all of my test cases. &lt;code&gt;pytest&lt;/code&gt; will find any files that start or end with &lt;code&gt;test&lt;/code&gt; and execute them. I created a very simple &lt;code&gt;test_tests.py&lt;/code&gt; file with the following simple test (taken from the &lt;a href="https://hypothesis.readthedocs.org/en/latest/quickstart.html#writing-tests"&gt;Hypothesis Quickstart&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@given(st.integers(), st.integers())
def test_ints_are_commutative(x, y):
    assert x + y == y + x
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, Travis CI needs to be told what to do. Modify the &lt;code&gt;script&lt;/code&gt; key to include &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script:
   - py.test
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After a successful run through Travis, you'll see something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tests/test_tests.py .
=========================== 1 passed in 0.26 seconds ===========================
The command "py.test" exited with 0.
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="custom-domain"&gt;Custom Domain&lt;a class="headerlink" href="#custom-domain" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have my own domain name. I want to utilize OpenShift with one of those domains, instead of the default one provided. Since I've using the free tier, that will rule out using the SSL certificate that is wildcarded to the whole &lt;code&gt;rhcloud.com&lt;/code&gt; domain. I can live with this. If I need SSL on my domain, I'll upgrade.&lt;/p&gt;
&lt;p&gt;To set up OpenShift to use your domain, log into the web console. Go to the gear you are configuring. At the top, where the full domain is displayed, is the option to "Change". Select that option. Input the full domain (and subdomain) you want to utilize and click "Save". After a few seconds, you'll get a notification that the alias was created.&lt;/p&gt;
&lt;p&gt;The next step is to configure the DNS records. I &lt;a href="https://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;utilize&lt;/a&gt; CloudFlare for my domains, so the instructs will be specific to that, but should apply to any DNS system. Login to your management system and go to the area where you can specify DNS records.&lt;/p&gt;
&lt;p&gt;For my test, I set up a subdomain of one of my domains as the alias I wanted to use. In your DNS system, set up a CNAME that points to the original hostname on OpenShift. The CNAME should be the subdomain you told OpenShift about. Save the record. &lt;/p&gt;
&lt;p&gt;CloudFlare recognized this immediately and redirected me to my Flask application. Hooray!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this, the set up is complete. You have a Flask application, connected to MySQL, that is integrated with a CI system which automatically deploys to OpenShift when all tests pass and uses CloudFlare (because I already was doing so), to provide a CDN. &lt;/p&gt;
&lt;p&gt;On to building something!&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Connect Python to OSI Soft PI</title><link href="https://andrewwegner.com/connect-python-to-osi-soft-pi.html" rel="alternate"></link><published>2012-02-07T12:45:00-06:00</published><updated>2012-04-16T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2012-02-07:/connect-python-to-osi-soft-pi.html</id><summary type="html">&lt;p&gt;How I connected Python to OSI Soft PI&lt;/p&gt;</summary><content type="html">&lt;p&gt;OSI PI is a historian database. I had a task to connect a python application to this database. I asked a question on 
&lt;a href="http://stackoverflow.com/questions/8898114/how-can-i-connect-python-2-6-to-osi-pi"&gt;Stack Overflow&lt;/a&gt; about whether this was a simple problem to solve. After two weeks I still hadn't gotten a viable response,
so I had to build by own solution.&lt;/p&gt;
&lt;p&gt;I did reach out to the vendor first for help. Their response back was not helpful. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Looks like pyodbc is written against ODBC 3.x.  The OSI PI ODBC driver is using ODBC 2.0.  The python ODBC driver manager 
will convert most ODBC 3 calls on the fly to ODBC 2 ones. Anything added to 3, however, will obviously fail. You would 
need to find some way to make sure that your only using 2.0 compliant ODBC calls.  Currently their is not a PI ODBC 
driver that is compliant with ODBC 3.0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, it looks like the vendor doesn't support Python (odd, they are named "PI", but I digress). Additionally, the drivers provided 
by the company initially didn't work. &lt;/p&gt;
&lt;p&gt;The code below shows how I was able to finally connect python to OSI PI. It may not be the most elegant, but it 
functions for the purposes of my application. Initially I was attempting to connect using the &lt;a href="https://github.com/mkleehammer/pyodbc"&gt;pyodbc&lt;/a&gt; module. Unfortunately, 
OSI PI would return a message like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pyodbc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nl"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;IM002&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[IM002] [OSI][PI ODBC][PI]PI-API Error &amp;lt;pilg_getdefserverinfo&amp;gt; 0 (0) (SQLDriverConnectW); [01000] [Microsoft][ODBC Driver Manager] The driver doesn&amp;#39;t support the version of ODBC behavior that the application requested (see SQLSetEnvAttr). (0)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;They vendor mentioned that using OLEDB instead may prove more fruitful. Thus, the code below is how I got connected using 
the vendor provided OLDEB driver. The downside is that I also had to do this all through COM objects using &lt;a href="http://python.net/crew/skippy/win32/Downloads.html"&gt;win32com&lt;/a&gt;. 
I'm not knocking the module, because it is extremely useful and I've done some great things with it.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;win32com.client&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.Connection&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.RecordSet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ConnectionString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Provider=PIOLEDB;Data Source=&amp;lt;server&amp;gt;;User ID=&amp;lt;username&amp;gt;;database=&amp;lt;database&amp;gt;;Password=&amp;lt;password&amp;gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;We&amp;#39;ve connected to the database.&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;db_cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;SELECT tag FROM pipoint WHERE tag LIKE &amp;#39;TAG0001%&amp;#39;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ActiveConnection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db_cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EOF&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;#print oRS.Fields.Item(&amp;quot;tag&amp;quot;).Value   # Ability to print by a field name&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;        &lt;span class="c1"&gt;# Ability to print by a field location&lt;/span&gt;
        &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MoveNext&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Not connected&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I followed up on my Stack Overflow post about 2 months after posting my solution with the following note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Just following up on this after using it for a couple months. This is still the only way I've found to do this with 
python, but it seems to be very slow when I need to run a large number of queries. I suspect it is because I have to 
open/close the database connection for each query, but OSI PI/ADODB complains if I do not. Performance has not reached a 
point where I am forced to rewrite this yet. If/when I do I will follow up again. In the meantime others using this 
solution should be aware that it is slow when running many queries.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="technical"></category></entry><entry><title>Multiple IP addresses on the same physical network card</title><link href="https://andrewwegner.com/multiple-ip-addresses-on-the-same-physical-network-card.html" rel="alternate"></link><published>2010-11-17T12:54:00-06:00</published><updated>2010-11-17T12:54:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-11-17:/multiple-ip-addresses-on-the-same-physical-network-card.html</id><summary type="html">&lt;p&gt;A quick walkthrough on how to configure a single network card to pull multiple IP addresses (RedHat based distribution)&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are times when a server can be allocated more than one IP Address even though it contains only one physical 
network card. To associate these IP addresses with the server some manipulation of networking settings will need to be 
performed. The steps outlined in this walk-through are for RedHat based systems. This tutorial is for statically assigned 
IP Addresses (as a server generally will have).
For this walk through we are going to add one additional IP address to &lt;code&gt;eth0&lt;/code&gt;. Navigate to&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd /etc/sysconfig/network-scripts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copy &lt;code&gt;ifcfg-eth0&lt;/code&gt; to &lt;code&gt;ifcfg-eth0:0&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cp ifcfg-eth0 ifcfg-eth0:0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we need to modify the new file slightly so that it gets it's own IP address. Open &lt;code&gt;ifcfg-eth0:0&lt;/code&gt; in your favorite editor&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;DEVICE=eth0:0           &amp;lt;-- Change this to match the new eth0:0 file we just created
BOOTPROTO=none
BROADCAST=x.x.x.x       &amp;lt;-- This is the broad cast address for the subnet the new IP is on
DNS1=x.x.x.x            &amp;lt;-- This is the main DNS server you are using (example: 64.120.14.26)
GATEWAY=x.x.x.x         &amp;lt;-- This is the gateway address for the subnet the new IP is on
HWADDR=&amp;lt;DO NOT CHANGE&amp;gt;  &amp;lt;-- Don&amp;#39;t change this from what is existing. The Hardware address is the same as the physical one
IPADDR=x.x.x.x          &amp;lt;-- This is your new IP address
NETMASK=x.x.x.x         &amp;lt;-- This is the netmask for the subnet the new IP is on
ONBOOT=yes              &amp;lt;-- Leave to yes
OPTIONS=layer2=1
TYPE=Ethernet
PREFIX=29
DEFROUTE=yes
NAME=&amp;quot;System eth0:0&amp;quot;    &amp;lt;-- Change to reflect new name of device
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Save your file with the new settings. Now we need to restart the networking service:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service network restart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When the network components come back up you should see your new device in the &lt;code&gt;ifconfig&lt;/code&gt; command. To add more IPs, 
copy and replace values as specified above.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Fixing MYISAM Crashed Tables</title><link href="https://andrewwegner.com/fixing-myisam-crashed-tables.html" rel="alternate"></link><published>2010-05-14T10:08:00-05:00</published><updated>2010-05-14T10:08:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-05-14:/fixing-myisam-crashed-tables.html</id><summary type="html">&lt;p&gt;How to fix MyISAM tables that are marked as crashed&lt;/p&gt;</summary><content type="html">&lt;p&gt;For various reasons, MyISAM tables are known to crash. When this happens, the following message will be displayed:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;INVALID SQL: 145 : Table &amp;#39;{something}&amp;#39; is marked as crashed and should be repaired
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I've found this error occurs when MySQL is unexpectedly shut down - whether from a power failure to the entire server or 
if MySQL itself has issues and you use the &lt;code&gt;kill&lt;/code&gt; command to stop it. Unexpected shut downs, especially while these tables 
are being used, do not make MyISAM tables happy.&lt;/p&gt;
&lt;p&gt;To fix this, you need the ability to stop MySQL in a controlled manner, and you need to know where the database files 
are stored.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;locate *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will return where all the MYI files are stored. In this example, I am using&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/var/lib/mysql/mysql/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Go to the directory of the crashed table using the &lt;code&gt;cd&lt;/code&gt; command. Next, stop MySQL. This is to ensure the tables are not 
accessed while we perform our repair functions. If you don't perform this step, the repair may not succeed.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service mysqld stop
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we are going to perform two repair functions. The first one may take a while depending on the size of your tables.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;myisamchk -r --force --safe-recover *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The second repair step is used to ensure all table states are updated correctly and repair any minor indexing issues. It 
is likely that this step is not needed after performing the previous step, but it should only take a few seconds now.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;myisamchk --force --fast --update-state *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, restart MySQL&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service mysqld start
&lt;/pre&gt;&lt;/div&gt;</content><category term="technical"></category></entry></feed>