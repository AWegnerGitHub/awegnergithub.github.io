<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ponderings of an Andy - Technical Solutions</title><link href="http://andrewwegner.com/" rel="alternate"></link><link href="http://andrewwegner.com/feeds/technical-solutions.atom.xml" rel="self"></link><id>http://andrewwegner.com/</id><updated>2018-04-02T12:30:00-05:00</updated><entry><title>Travis CI doesn't keep your environment variable secure</title><link href="http://andrewwegner.com/travisci-insecure-environment-variables.html" rel="alternate"></link><published>2018-04-02T12:30:00-05:00</published><updated>2018-04-02T12:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-04-02:/travisci-insecure-environment-variables.html</id><summary type="html">&lt;p&gt;Travis CI does not keep your environment variables secure if you transfer a repository.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;On December 27, 2017 I reported a security issue directly to the security team as their &lt;a href="https://github.com/travis-ci/travis-ci/blob/master/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; recommends. I received an automated response that a human would
follow up with me soon. It was their end of year, two week vacation (which is awesome!). I sent the same email again on January 26, 2018 and received a response back from AJ Bowen, a Build Infrastructure Engineer at Travis CI on January 29, 2018. They'd created an internal issue to track the behavior and would follow up within two weeks. &lt;/p&gt;
&lt;p&gt;I followed up with AJ on February 28, 2018 and didn't receive a response. We're now over three months since my initial report. I believe it's time to make this more public so 
that others know to be careful with their Travis CI managed environment variables.&lt;/p&gt;
&lt;h2 id="the-issue"&gt;The Issue&lt;a class="headerlink" href="#the-issue" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://travis-ci.org/"&gt;Travis CI &lt;/a&gt; is an application that allows you to automatically test and deploy applications after a commit is pushed to GitHub. I've used this ability to run unit tests, 
&lt;a href="http://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html"&gt;automatically deploy updates to PyPI&lt;/a&gt;, and more recently when testing deployment to AWS using the Serverless framework. It's that last one that led me to this issue.&lt;/p&gt;
&lt;p&gt;Part of deploying to AWS requires that you have credentials to deploy. I didn't want to put my AWS deploy credentials in GitHub, even if they are &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Encrypting-environment-variables"&gt;encrypted&lt;/a&gt;. Instead, 
I decided to set my variables in the &lt;a href="https://docs.travis-ci.com/user/environment-variables/#Defining-Variables-in-Repository-Settings"&gt;Travis CI Settings&lt;/a&gt;. I went forward with my testing, watched the deploys happen as expected and eventually needed to transfer my
repository to a third party. &lt;/p&gt;
&lt;p&gt;I used GitHub to transfer the repository to the new owner. We tested a build and watched it deploy. The Travis CI console showed a successful deploy. The problem is, 
it deployed to &lt;em&gt;my&lt;/em&gt; AWS account using &lt;em&gt;my&lt;/em&gt; AWS credentials. These "secure" environment variables had been transfered to a third party and were no longer in my control.&lt;/p&gt;
&lt;h2 id="reproduction-short-version"&gt;Reproduction - Short Version&lt;a class="headerlink" href="#reproduction-short-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Reproducing the issue is trivial. The short version is this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On one GitHub account, create a repository with a &lt;code&gt;.travis.yml&lt;/code&gt; file &lt;/li&gt;
&lt;li&gt;On the Travis CI account associated with step 1, set up an environment variable and elect &lt;em&gt;not&lt;/em&gt; to show the value in the build log&lt;/li&gt;
&lt;li&gt;Transfer the GitHub repository to another account.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, the environment variables defined in step 2 are accessible by the new owner from step 3. &lt;/p&gt;
&lt;h2 id="reproduction-long-version"&gt;Reproduction - Long Version&lt;a class="headerlink" href="#reproduction-long-version" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The detailed steps taken to reproduce this issue show that Travis CI is simply looking for the environment variable values and scrubbing those from the build logs. Once transfered, an edit can be introduced to show these variables with minimal work. &lt;/p&gt;
&lt;h3 id="create-a-repository"&gt;Create a repository&lt;a class="headerlink" href="#create-a-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Create a new repository and add something. For this test, I created a simple Python Hello World file, and named it &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Hello World")
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit this change to your new repository.&lt;/p&gt;
&lt;h3 id="enable-travis-ci-integration"&gt;Enable Travis CI integration&lt;a class="headerlink" href="#enable-travis-ci-integration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Go to &lt;a href="https://travis-ci.org/"&gt;Travis CI&lt;/a&gt; and log in with the GitHub account associated with the above step. Sync your account. Then enable integration by changing the repository switch.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Enable Integration" src="http://andrewwegner.com/images/1-travis-enable-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="create-a-travisyml-file"&gt;Create a .travis.yml file&lt;a class="headerlink" href="#create-a-travisyml-file" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the integration now in place, set up a basic build script by adding a &lt;code&gt;.travis.yml&lt;/code&gt; file to the repository. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;python&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"3.5"&lt;/span&gt;
&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; 
  &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt; &lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This script will set up a build task and run your &lt;code&gt;hello.py&lt;/code&gt; file, using Python 3.5. You will see that "Hello World!" is printed in the build console.&lt;/p&gt;
&lt;p&gt;&lt;img alt="First Build" src="{attach}images/2-first-build.png"/&gt;&lt;/p&gt;
&lt;h3 id="add-environment-variables"&gt;Add Environment Variables&lt;a class="headerlink" href="#add-environment-variables" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that our build script is working, we can work on "deployment". Deployment to AWS (or other cloud services) requires that you provide credentials. I am not a fan of 
including credentials in my repository, even if they are encrypted. Opting for an environment variable should be more secure, as the credentials are never in your repository
in the first place. &lt;strong&gt;It is important to note that you are still giving your credentials to Travis CI in this case.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To set up environment variables, click on "More Options" and "Settings" within the Travis CI application.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Travis Settings" src="http://andrewwegner.com/images/3-add-variable-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Now scroll down to "Environment Variables". Add the name of the variable and the value. Be sure to leave the default value of "Off" selected. You don't want to display this 
value in the build log. Finally click "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a variable" src="http://andrewwegner.com/images/4-add-variable-2.png"/&gt;&lt;/p&gt;
&lt;p&gt;I've added a second variable for further testing.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding a second variable" src="http://andrewwegner.com/images/5-add-variable-3.png"/&gt;&lt;/p&gt;
&lt;p&gt;Notice that variable values are hidden from view after clicking "Add".&lt;/p&gt;
&lt;p&gt;&lt;img alt="Variable values hidden" src="http://andrewwegner.com/images/6-variables-added.png"/&gt;&lt;/p&gt;
&lt;h3 id="check-values-during-build"&gt;Check values during build&lt;a class="headerlink" href="#check-values-during-build" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;With the variables saved, restart your build. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Restart Build" src="http://andrewwegner.com/images/7-restart-build.png"/&gt;&lt;/p&gt;
&lt;p&gt;When the build has completed, check the build log. Even though we aren't using these values yet, we can see the environment variables exist and are "Secure".&lt;/p&gt;
&lt;p&gt;&lt;img alt='"Secure" Variables' src="http://andrewwegner.com/images/8-variables-secure.png"/&gt;&lt;/p&gt;
&lt;h3 id="accessing-the-values"&gt;Accessing the values&lt;a class="headerlink" href="#accessing-the-values" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;These values are not actually secure. Travis CI is filtering for the values of these environment variables and if the specific string is found, it is scrubbed from
the log. We can see this with a small change to &lt;code&gt;hello.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World!"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;aws_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_ACCESS_KEY_ID'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;aws_secret&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;environ&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'AWS_SECRET_ACCESS_KEY'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS KEY ID: |{}{}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"AWS SECRET KEY: |{} {}|"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;aws_secret&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, we are splitting the values of the environment variables in half. For the &lt;code&gt;AWS_ACCESS_KEY_ID&lt;/code&gt; value, you smash these two together. This will match the 
environment variable value, and will not be shown because the pattern still matches the value:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;|{}{}|
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For &lt;code&gt;AWS_SECRET_ACCESS_KEY&lt;/code&gt;, we split the two halves with a space and print it out. This will be shown, because the extra space no longer matches the exact value of the 
environment variable.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;|{} {}|
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Commit and push the change to GitHub. In Travis CI, we see the following in the build log:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Accessing the values" src="http://andrewwegner.com/images/9-variables-filtered-by-match.png"/&gt;&lt;/p&gt;
&lt;p&gt;As expected, the first pattern is hidden because it matches the environment variable. The second pattern is shown, because the space in the middle means the pattern no longer 
matches.&lt;/p&gt;
&lt;h3 id="transfer-the-repository"&gt;Transfer the repository&lt;a class="headerlink" href="#transfer-the-repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've shown the variables are accessible, it's time to transfer the repository to a new owner. In GitHub, this can be accomplished by going to the repository settings
and going down to the red "danger area". Once you've entered the name of the current repository and the name of the new owner, we wait for the new owner to accept the transfer.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Transfer the repository" src="http://andrewwegner.com/images/10-transfer-repository.png"/&gt;&lt;/p&gt;
&lt;h3 id="build-with-the-new-owner"&gt;Build with the new owner&lt;a class="headerlink" href="#build-with-the-new-owner" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Make a change and commit it to the new repository. I simply modified the "Hello World" line:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Hello World from new owner!")
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A new build will kick off. You can see that the repository has transfered to the new owner in the build log. You can also see the environment variables were transfered to the 
new owner. Other than the new owner being listed, the build log shows the same output as before&lt;/p&gt;
&lt;p&gt;&lt;img alt="Everything has transfered" src="http://andrewwegner.com/images/11-build-after-transfer.png"/&gt;&lt;/p&gt;
&lt;h3 id="variables-in-the-ui"&gt;Variables in the UI&lt;a class="headerlink" href="#variables-in-the-ui" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You can also see these variables have transfered by going back to "More Options", then "Settings" in Travis CI. The values are still hidden behind the input password field. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Variables in UI" src="http://andrewwegner.com/images/12-variables-transfered.png"/&gt;&lt;/p&gt;
&lt;h2 id="impact-of-bug"&gt;Impact of bug&lt;a class="headerlink" href="#impact-of-bug" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The example above shows two problems. The bigger problem, in my opinion, is that environment variables are transfered to a new owner. The secondary problem is that "secure"
variables are really just obfuscated. Accessing them is trivial. With this demonstration, we added in a step to show that the variables can be seen by the original
owner. However, it is just as likely that the new owner could introduce such a change after the repository is transfered.&lt;/p&gt;
&lt;p&gt;This bug requires the owner of the repository to perform the "dangerous" GitHub action of transferring a repository. That means it's impact is limited. However, it's just as
likely that the original owner has forgotten that environment variables were set up in Travis CI, an entirely separate system. &lt;/p&gt;
&lt;p&gt;When a GitHub repository is transfered to a new owner, the environment variables in Travis CI should not travel with. This is especially true for the "secure" variables. I'd 
rather that a build breaks after the transfer due to the lack of appropriate variables being set up than having my cloud credentials be sent to a third party. &lt;/p&gt;
&lt;h2 id="mitigation"&gt;Mitigation&lt;a class="headerlink" href="#mitigation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Mitigation of this bug, until Travis CI stops transferring environment variables to new repository owners, requires the original owner to remove the variables prior to 
transferring the repository. One of the steps that the owner should take is to log into Travis CI and ensure all secure variables have been removed from the Travis CI 
environment. This will break the builds, but it will also ensure that private variables aren't leaked unintentionally to a third party.&lt;/p&gt;
&lt;h2 id="repository"&gt;Repository&lt;a class="headerlink" href="#repository" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The repository for testing is available on &lt;a href="https://github.com/AWegnerGitHub/TravisIssue"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Installing NextCloud</title><link href="http://andrewwegner.com/Installing%20NextCloud.html" rel="alternate"></link><published>2018-03-27T23:30:00-05:00</published><updated>2018-03-27T23:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-03-27:/Installing NextCloud.html</id><summary type="html">&lt;p&gt;The ZFS pool is set up. It's time to use all that storage space and install NextCloud.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In the last post, I described how I &lt;a href="http://andrewwegner.com/zfs-pool-on-ubuntu.html"&gt;set up ZFS on the new server&lt;/a&gt;. With a newly configured operating system and tons of space, it's time to start using it. One of the goals
I &lt;a href="http://andrewwegner.com/new-house-server.html"&gt;mentioned&lt;/a&gt; when I set up this server was the ability to: &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Back up data from all devices in the house automatically. As camera phones have gotten better, we've found that we carry our bulky digital camera less and less. The problem
 with the phone camera is that we need to get the pictures to the computer. I don't want to hunt down a data cable or email the pictures to myself. I'm also not a fan of 
 posting everything to social media. I want my phone to send the pictures to a backup location automatically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm going to accomplish that by hosting an instance of &lt;a href="https://nextcloud.com/"&gt;NextCloud&lt;/a&gt; on this new server. Fortunately, the install process is pretty simple for this one. NextCloud provides 
&lt;a href="https://nextcloud.com/install/"&gt;installation instructions&lt;/a&gt;. When I installed it in mid-February 2018, it was on version 12.x. As of this post, in late March 2018, it's on version 13.x. I'll cover install
and upgrade processes in this post.&lt;/p&gt;
&lt;h2 id="installation"&gt;Installation&lt;a class="headerlink" href="#installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="prerequisites"&gt;Prerequisites&lt;a class="headerlink" href="#prerequisites" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;For NextCloud you'll need either MySQL or MariaDB. I host it via Apache2, so we'll have that installed too. NextCloud is written in PHP, meaning we need that too.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install apache2 mariadb-server php7.0 libapache2-mod-php7.0 php7.0-mbstring php7.0-curl php7.0-zip php7.0-gd php7.0-mysql php7.0-mcrypt php7.0-bcmath php7.0-xml php7.0-json php7.0-tidy
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Enable the Apache2 rewrite module and restart the web server.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo a2enmod rewrite
sudo service apache2 restart
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="set-up-the-database"&gt;Set up the database&lt;a class="headerlink" href="#set-up-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;You'll need to create a database for NextCloud. Log into your database using credentials that can create new users and databases. &lt;code&gt;root&lt;/code&gt; will work.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;mysql -uroot -p
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, execute a couple SQL statements to create a database and create a user that can access the database. Make sure you use a secure password.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CREATE DATABASE nextcloud;
GRANT ALL PRIVILEGES ON nextcloud.* TO 'nextclouduser'@'localhost' IDENTIFIED BY 'YOURSECUREPASSWORDHERE';
FLUSH PRIVILEGES;
\q
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="download-nextcloud"&gt;Download NextCloud&lt;a class="headerlink" href="#download-nextcloud" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned above, I initially installed version 12 of NextCloud. The latest version can be found on the &lt;a href="https://nextcloud.com/install/"&gt;NextCloud install page&lt;/a&gt;. The URL from that page should be
used instead of the version 12 link in the following code block. The code block below will be putting NextCloud in the default location Ubuntu has Apache look. You can modify
that as needed. If you do so, the virtual host will need to be modified slightly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo cd /tmp &amp;amp;&amp;amp; wget wget https://download.nextcloud.com/server/releases/nextcloud-12.0.2.zip
sudo unzip nextcloud-12.0.2.zip
sudo mv nextcloud/ /var/www/html
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We need to adjust ownership of the files so that Apache can read them. The default user and group, in this case is &lt;code&gt;www-data&lt;/code&gt;. If you have configured your server to use a 
different user or group, adjust this command accordingly.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo chown www-data:www-data -R /var/www/html/nextcloud
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="create-the-virtual-host"&gt;Create the Virtual Host&lt;a class="headerlink" href="#create-the-virtual-host" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'll be exposing this to the internet and I'll be accessing it via the internet. That means I really don't want to send data unencrypted to or from NextCloud. I'll be setting
up the standard port 80 web server traffic to redirect to the secure port of 443. I'll cover generating SSL certificates in a future post. I use &lt;a href="https://letsencrypt.org/"&gt;Let's Encrypt&lt;/a&gt;. The keys 
referenced in the virtual host configuration file below created by that process.&lt;/p&gt;
&lt;p&gt;Create a new virtual host.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo touch /etc/apache2/sites-available/nextcloud.conf
sudo ln -s /etc/apache2/sites-available/nextcloud.conf /etc/apache2/sites-enabled/nextcloud.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you need to edit this newly created file &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo nano /etc/apache2/sites-available/nextcloud.conf
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Paste the following:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerAdmin YOUR@EMAILADDRESS
    DocumentRoot /var/www/html/nextcloud/
    ServerName nas.example.com
    Redirect permanent / https://nas.example.com/

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
&lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;

&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt; &lt;span class="err"&gt;*:443&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    ServerName nas.example.com
    DocumentRoot /var/www/html/nextcloud/
    RewriteCond %{THE_REQUEST} ^.*/index\.php
    RewriteRule ^(.*)index.php$ /$1 [R=301,L]
    SSLEngine on
    SSLCertificateFile /opt/repos/dehydrated/certs/nas.example.com/cert.pem
    SSLCertificateKeyFile /opt/repos/dehydrated/certs/nas.example.com/privkey.pem
    SSLCertificateChainFile /opt/repos/dehydrated/certs/nas.example.com/chain.pem
    &lt;span class="nt"&gt;&amp;lt;IfModule&lt;/span&gt; &lt;span class="err"&gt;mod_headers.c&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
        Header always set Strict-Transport-Security "max-age=15552000; includeSubDomains"
    &lt;span class="nt"&gt;&amp;lt;/IfModule&amp;gt;&lt;/span&gt;

    &lt;span class="nt"&gt;&amp;lt;Directory&lt;/span&gt; &lt;span class="err"&gt;/var/www/html/nextcloud&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
        Options FollowSymLinks
        AllowOverride All
        Order allow,deny
        allow from all
    &lt;span class="nt"&gt;&amp;lt;/Directory&amp;gt;&lt;/span&gt;

    ErrorLog /var/log/apache2/nas.example.com-error_log
    CustomLog /var/log/apache2/nas.example.com-access_log common
 &lt;span class="nt"&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are two separate virtual host configurations being created here. The first one, on port 80, is setting up the permanent redirect to the HTTPS site. &lt;/p&gt;
&lt;p&gt;In the secure virtual host configuration, we're setting a small rewrite rule to provide nicer URLs and configuring the SSL certificates to use. The &lt;code&gt;DocumentRoot&lt;/code&gt; variables
should match the path you installed NextCloud into in the previous step.&lt;/p&gt;
&lt;h3 id="application-configuration"&gt;Application Configuration&lt;a class="headerlink" href="#application-configuration" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;There are a few settings that you need to change in the NextCloud configuration. Do this by editing &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;. If this file doesn't exist, 
you need to copy &lt;code&gt;/var/www/html/nextcloud/config/config.sample.php&lt;/code&gt; to &lt;code&gt;/var/www/html/nextcloud/config/config.php&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The important settings to check are:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;- `datadirectory`: In my case, this was pointed at a dataset I created when I [set up my ZFS pool][1]
- `overwrite.cli.url`: Changed to point to the HTTPS version of the URL I want to use
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="complete-the-installation"&gt;Complete the installation&lt;a class="headerlink" href="#complete-the-installation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Restart Apache and the navigate to the domain you've set up for your NextCloud installation. I am assuming that you know how to set up a DNS record for the server name
you specified in your virtual host configuration.&lt;/p&gt;
&lt;p&gt;Once you've reached the domain in your web browser, follow the instructions on screen. You'll need the database username and password you created above. You'll also create an
administration user. &lt;/p&gt;
&lt;h3 id="upgrading"&gt;Upgrading&lt;a class="headerlink" href="#upgrading" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After some time, NextCloud will update. You should apply these updates, as they'll include new features and security patches. Log into NextCloud using your administration user.
Click on the Gear icon in the upper right and pick "Settings". On the left hand side, select "Basic settings". Half way down the page you'll see the version you are currently
running and whether or not there is an update available. If there is, you can begin the update from here.&lt;/p&gt;
&lt;p&gt;NextCloud does not support skipping versions when updating. This means if you are on version 12, you can upgrade to version 13. You can not, however, upgrade directly from 12 to 14. &lt;/p&gt;
&lt;h2 id="syncing-data"&gt;Syncing data&lt;a class="headerlink" href="#syncing-data" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;NextCloud provides client applications that allow you to automatically sync data to your install. There are clients for both computers and mobile devices. My use case only
requires the mobile clients right now, but that may change in the future. From the &lt;a href="https://nextcloud.com/install/"&gt;install page&lt;/a&gt;, you can find the clients for Android, iOS and Windows devices. Select
the appropriate installer on your device.&lt;/p&gt;
&lt;p&gt;Once the mobile client is installed, you need to provide the URL to your installation and a username and password that can access your information. I've enabled automatic
uploads of new pictures from my devices only when I'm on a wireless connection (no sense wasting mobile data). This, however, is why I wanted the SSL certificates. The client
doesn't let me whitelist uploading from specific networks. I'd prefer I don't send my pictures unencrypted.&lt;/p&gt;
&lt;h2 id="results"&gt;Results&lt;a class="headerlink" href="#results" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I've been using NextCloud for almost three months so far. I love it. Previously, I'd have to find a data cable and remember to manually backup my pictures once and a while. Now,
it "just happens". If I take a picture at home, it's backed up within seconds. If I take a bunch of pictures while I'm out of the house, my pictures are backed up within 
minutes of me getting home. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Setting up a ZFS pool on Ubuntu 16.04</title><link href="http://andrewwegner.com/zfs-pool-on-ubuntu.html" rel="alternate"></link><published>2018-02-15T22:30:00-06:00</published><updated>2018-02-15T22:30:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2018-02-15:/zfs-pool-on-ubuntu.html</id><summary type="html">&lt;p&gt;With the backup server assembled, it's time to start configuring it. This post covers setting up the ZFS pool for all the data&lt;/p&gt;</summary><content type="html">
&lt;h2 id="introduction"&gt;Introduction&lt;a class="headerlink" href="#introduction" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://andrewwegner.com/new-house-server.html"&gt;Previously&lt;/a&gt; in this series, the new NAS was assembled. Ubuntu 16.04 has been installed and updated. It's time to do something with all those hard drives! &lt;/p&gt;
&lt;p&gt;I'll be setting the seven 4TB drives in a single &lt;a href="https://en.wikipedia.org/wiki/ZFS"&gt;ZFS&lt;/a&gt; pool. I'm using ZFS for protection against data corruption. It offers several other &lt;a href="https://wiki.ubuntu.com/ZFS"&gt;features&lt;/a&gt; too. I'll
be using dual parity, which means I could lose two drives and be able to recover. The goal is never to test this, but I'd rather not go through a &lt;a href="http://andrewwegner.com/backup-your-data.html"&gt;data loss scare&lt;/a&gt; again.&lt;/p&gt;
&lt;p&gt;Before we begin, it's a good idea to ensure Ubuntu has been updated.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the update complete, let's get started. &lt;/p&gt;
&lt;h2 id="installing-zfs"&gt;Installing ZFS&lt;a class="headerlink" href="#installing-zfs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Installing the ZFS file system is simple on Ubuntu. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt-get install zfs parted
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ta-da! Your system is now capable of setting up ZFS pools. The &lt;code&gt;parted&lt;/code&gt; package will be used to set up a ZFS pool shortly.&lt;/p&gt;
&lt;h2 id="setting-up-our-pool"&gt;Setting up our pool&lt;a class="headerlink" href="#setting-up-our-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Pools are the basic building block of ZFS. A pool is made up of the underlying devices that will store the data. Setting up our ZFS pool requires a little bit of prep work
for our new drives. First, ensure that the &lt;code&gt;zfs&lt;/code&gt; package installed correctly by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool status
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point in the process, you should get the message &lt;code&gt;no pools available&lt;/code&gt;. &lt;/p&gt;
&lt;h3 id="adding-the-gpt-label"&gt;Adding the GPT label&lt;a class="headerlink" href="#adding-the-gpt-label" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'm setting up this pool with brand new drives. We need to add a &lt;code&gt;GPT&lt;/code&gt; label to each disk so that ZFS doesn't complain about disks having an &lt;code&gt;invalid vdev specification&lt;/code&gt; 
when we create the pool. To do this, we'll find the names of our drives first&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ls -l /dev/sd*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On my system, I get a result similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;brw-rw---- 1 root disk 8,   0 Feb 13 09:23 /dev/sda
brw-rw---- 1 root disk 8,   1 Feb 13 09:23 /dev/sda1
brw-rw---- 1 root disk 8,   2 Feb 13 09:23 /dev/sda2
brw-rw---- 1 root disk 8,   5 Feb 13 09:23 /dev/sda5
brw-rw---- 1 root disk 8,  16 Feb 13 09:23 /dev/sdb
brw-rw---- 1 root disk 8,  32 Feb 13 09:23 /dev/sdc
brw-rw---- 1 root disk 8,  48 Feb 13 09:23 /dev/sdd
brw-rw---- 1 root disk 8,  64 Feb 13 09:23 /dev/sde
brw-rw---- 1 root disk 8,  80 Feb 13 09:23 /dev/sdf
brw-rw---- 1 root disk 8,  96 Feb 13 09:23 /dev/sdg
brw-rw---- 1 root disk 8, 112 Feb 13 09:23 /dev/sdh
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We'll be adding the &lt;code&gt;GPT&lt;/code&gt; labels to each of the unformatted drives. The unformatted ones are the listed drives that don't have a numeral as well. For me, that means we'll
be working with &lt;code&gt;sdb&lt;/code&gt;, &lt;code&gt;sdc&lt;/code&gt;, &lt;code&gt;sdd&lt;/code&gt;, &lt;code&gt;sde&lt;/code&gt;, &lt;code&gt;sdf&lt;/code&gt;, &lt;code&gt;sdg&lt;/code&gt; and &lt;code&gt;sdh&lt;/code&gt;. The &lt;code&gt;sda&lt;/code&gt; drive has been formatted and contains partitions already. Those are &lt;code&gt;sda1&lt;/code&gt;, &lt;code&gt;sda2&lt;/code&gt; and &lt;code&gt;sda5&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;For each drive, except &lt;code&gt;sda&lt;/code&gt; in my case, we need to run the &lt;code&gt;parted&lt;/code&gt; command.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo parted /dev/sdb
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will give you a short dialog. All you will need to do is issue the &lt;code&gt;mklabel GPT&lt;/code&gt; command and then quit (using &lt;code&gt;q&lt;/code&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;GNU Parted 3.2
Using /dev/sdb
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) mklabel GPT
(parted) q
Information: You may need to update /etc/fstab.
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="getting-device-ids"&gt;Getting device IDs&lt;a class="headerlink" href="#getting-device-ids" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once the &lt;code&gt;GPT&lt;/code&gt; labels are added, we can create our pool. However, we're not going to use the device paths returned above. Theoretically, those can change (especially if you 
replace a drive). That would be bad and mess with the entire ZFS pool. Instead we're going to create the pool by using the device id. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ls -l /dev/disk/by-id/*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This returns output similar to this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;...
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee20f1d3114 -&amp;gt; ../../sdc
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee20f3ba2b9 -&amp;gt; ../../sdg
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2647227b7 -&amp;gt; ../../sdb
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee26490a21e -&amp;gt; ../../sdd
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9c81501 -&amp;gt; ../../sdh
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9e6ab61 -&amp;gt; ../../sdf
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x50014ee2b9e6b857 -&amp;gt; ../../sde
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87 -&amp;gt; ../../sda
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part1 -&amp;gt; ../../sda1
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part2 -&amp;gt; ../../sda2
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/wwn-0x5001b444a9525c87-part5 -&amp;gt; ../../sda5

...
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT -&amp;gt; ../../sdb
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0 -&amp;gt; ../../sdc
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U -&amp;gt; ../../sdg
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4 -&amp;gt; ../../sdf
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA -&amp;gt; ../../sde
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY -&amp;gt; ../../sdd
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS -&amp;gt; ../../sdh
lrwxrwxrwx 1 root root  9 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671 -&amp;gt; ../../sda
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part1 -&amp;gt; ../../sda1
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part2 -&amp;gt; ../../sda2
lrwxrwxrwx 1 root root 10 Feb 13 09:23 /dev/disk/by-id/ata-WDC_WDS100T1B0A-00H9H0_174256421671-part5 -&amp;gt; ../../sda5
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that both formats symlink to the same location. This means you can pick which ever format you like better. However, I recommend the second one that contains the 
device serial number. It'll make it easier to determine problem disks in the future. &lt;/p&gt;
&lt;h3 id="create-the-pool"&gt;Create the pool&lt;a class="headerlink" href="#create-the-pool" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Now that we've determined the device ides for each of our hard drives, it's time to actually create the pool. As I mentioned above, we'll be creating using dual parity
(&lt;code&gt;raidz2&lt;/code&gt;). We'll be naming our pool &lt;code&gt;data&lt;/code&gt;. Once this command is complete, &lt;code&gt;/data&lt;/code&gt; will be where this pool resides.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool create data raidz2 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4 /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U /dev/disk/by-id/ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a little while, but a surprisingly smaller amount of time than I initially expected. &lt;/p&gt;
&lt;p&gt;Once the creation is complete, take a look at the status of your new pool:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zpool status

  pool: data
 state: ONLINE
  scan: none requested
config:

        NAME                                          STATE     READ WRITE CKSUM
        data                                          ONLINE       0     0     0
          raidz2-0                                    ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKUXT  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K0HLKXS0  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNNTXY  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K6VNN6TA  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K5LCEYN4  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K4YJ6T0U  ONLINE       0     0     0
            ata-WDC_WD40EFRX-68N32N0_WD-WCC7K7TSA4VS  ONLINE       0     0     0

errors: No known data errors
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That last line is important. No known data errors is good. &lt;/p&gt;
&lt;h2 id="create-datasets"&gt;Create datasets&lt;a class="headerlink" href="#create-datasets" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Where pools are the basic building blocks of ZFS, datasets is a term for a ZFS file system, volume, snapshot or clone. Each dataset can be managed and configured differently.
This means that you can compress one dataset, but leave the others alone. You can put a quota on one, but leave the others without a quota. Creating a dataset is pretty easy:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd /
sudo zfs create data/storage
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create a dataset that exists at &lt;code&gt;/data&lt;/code&gt; named &lt;code&gt;storage&lt;/code&gt;. You can have child datasets that inherit attributes from parents (or even grandparents) by doing something
like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo zfs create data/storage/music
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will create the new dataset at &lt;code&gt;/data/storage&lt;/code&gt; named &lt;code&gt;music&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once you've set up your datasets, you can see they were all created and how much space they have available by issuing &lt;code&gt;sudo zfs list&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="set-up-complete"&gt;Set up complete&lt;a class="headerlink" href="#set-up-complete" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With that, we've finished setting up ZFS on Ubuntu 16.04. I set up a few datasets for my purposes. I'm one step closer to getting this running and handling all of the 
digital data in the house. &lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Choosing an ORM library for a new project</title><link href="http://andrewwegner.com/choosing-orm-library.html" rel="alternate"></link><published>2017-04-26T14:30:00-05:00</published><updated>2017-04-26T14:30:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2017-04-26:/choosing-orm-library.html</id><summary type="html">&lt;p&gt;A discussion about how a team picked an ORM library for a new project.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="project-history"&gt;Project History&lt;a class="headerlink" href="#project-history" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;a href="http://andrewwegner.com/can-a-machine-be-taught-to-flag-spam-automatically.html"&gt;SmokeDetector&lt;/a&gt; project is over three years old at this point. It's grown from a small python script to a 
decently sized application that integrates with another project. In that time, it's expanded what types of spam and
patterns it looks for, what chat rooms it posts to, what external services it integrates with and how permissions to
use the system are determined. &lt;/p&gt;
&lt;p&gt;A lot has changed under the hood. I was hoping to put a cool chart here showing code change over time, but some early
decisions with the project really throw off the chart. Using a &lt;a href="https://erikbern.com/2016/12/05/the-half-life-of-code.html"&gt;Ship of Theseus&lt;/a&gt; analogy for code, you can see how 
much has changed. The basic idea is, if a ship leaves port and replaces every plank along it's journey, is it still the 
same ship when it returns? With code, the idea is to apply this to lines of code in an application.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://andrewwegner.com/images/smokey-git-theseus-all.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus" src="http://andrewwegner.com/images/smokey-git-theseus-all.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="what-happened-in-2014"&gt;What happened in 2014?!&lt;a class="headerlink" href="#what-happened-in-2014" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In late 2014, the project attempted their first machine learning method of detecting spam. In this time period, a 
&lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/102aa9c64edafb7f5fef5ba16414f4cefad03d64"&gt;commit&lt;/a&gt; was added that added about 200,000 lines of code to the project. This was almost all training data for a 
Bayesian algorithm. It wasn't needed and probably shouldn't have been added to the main repository. Unfortunately, it 
stayed in the repository for over a year and was finally &lt;a href="https://github.com/Charcoal-SE/SmokeDetector/commit/68d49ccc0b4981a4ebe91d993f42643542e44d80"&gt;removed&lt;/a&gt; in late 2015. This is the cause of the weird graph 
above, and why almost everything added in 2014 looks like it's missing in later years.&lt;/p&gt;
&lt;h3 id="what-has-really-changed"&gt;What has really changed?&lt;a class="headerlink" href="#what-has-really-changed" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;After eliminating that bayesian directory from git history, you can get a much better idea of how much has changed. &lt;/p&gt;
&lt;p&gt;&lt;a href="http://andrewwegner.com/images/smokey-git-theseus-filtered.png"&gt;&lt;img alt="SmokeDetector - Git of Theseus - Filtered" src="http://andrewwegner.com/images/smokey-git-theseus-filtered.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Very little of the original code, written in 2014, remains untouched. The explosion in code after that is due to
new detection patterns, chat commands (and a rewrite), integration with MetaSmoke and the introduction of blacklists.&lt;/p&gt;
&lt;p&gt;Even more dramatically, you can see how long a line of code is expected to survive in the code base.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://andrewwegner.com/images/smokey-git-theseus-survival.png"&gt;&lt;img alt="SmokeDetector - Line Survival Rate" src="http://andrewwegner.com/images/smokey-git-theseus-survival.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Within one year, the team is removing over 40% what's been committed to the repository. Looking at these commits, 
it was determined that a vast majority aren't even &lt;em&gt;code&lt;/em&gt;. They are new items to blacklist or new patterns to detect. &lt;/p&gt;
&lt;h2 id="enter-the-database"&gt;Enter the database&lt;a class="headerlink" href="#enter-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of this type of data can be stored in a database and managed outside of code. In early 2017, those discussions 
started taking place. Several team members come from a Ruby background and were familiar with it's &lt;a href="https://en.wikipedia.org/wiki/Object-relational_mapping"&gt;ORM&lt;/a&gt; method of
accessing databases. They wanted something similar when a database was brought into SmokeDetector.&lt;/p&gt;
&lt;p&gt;A bit of research was done and it was narrowed down to &lt;a href="http://docs.peewee-orm.com/en/latest/"&gt;peewee&lt;/a&gt; and &lt;a href="https://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. &lt;/p&gt;
&lt;h3 id="how-to-choose"&gt;How to choose?&lt;a class="headerlink" href="#how-to-choose" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Fortunately for the SmokeDetector team, there weren't any strong opinions either way. The biggest reason for choosing
one over the other came down to a &lt;a href="https://www.reddit.com/r/Python/comments/4tnqai/choosing_a_python_ormpeewee_vs_sqlalchemy/d5jyuug/"&gt;comment made by the peewee author&lt;/a&gt; on reddit. They state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[...] SQLAlchemy is the gold standard for ORM in the Python world. It has a very active community and a maintainer 
who is committed to excellence. If you're a glass-half-empty guy, to put it another way, you can't go wrong if you 
choose SQLAlchemy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The weaknesses they list for using their own package is the smaller ecosystem, support and number of developers.&lt;/p&gt;
&lt;h3 id="technical-differences"&gt;Technical differences&lt;a class="headerlink" href="#technical-differences" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;That's a boring story though. Not to be deterred from such a glowing review from a competitor, I wanted to see what the
technical differences were between the two solutions.&lt;/p&gt;
&lt;p&gt;To that end, I put together a small Python notebook showing the &lt;a href="https://gist.github.com/AWegnerGitHub/201dbaf09740f9ecd797c32ebfc15872"&gt;differences between peewee and SQLAlchemy&lt;/a&gt; in a 
handful of tests. These tests included inserting two settings in an SQLite database, retrieving one, inserting a large
list of users and then retrieving a subset of those users.&lt;/p&gt;
&lt;p&gt;The results were...unremarkable. &lt;/p&gt;
&lt;p&gt;[![peewee vs SQLAlchemy results][13]][13]&lt;/p&gt;
&lt;p&gt;The two libraries each took two tests (out of four) for being faster than the other. In both cases where SQLAlchemy was
faster, it was between two and six times faster. Where peewee was faster it was between a fraction faster and twice as
fast. &lt;/p&gt;
&lt;p&gt;The time scales are so small though, and SmokeDetector doesn't need to have thousands, hundreds or even tens of hits to
the database a second. A hundred extra milliseconds isn't going to cripple anything it handles.&lt;/p&gt;
&lt;p&gt;Thus, the choice was made based on the recommendation of the author of the peewee library. SQLAlchemy has a larger
community and better support. &lt;/p&gt;</content><category term="technical"></category><category term="programming"></category></entry><entry><title>My experiences releasing a package to PyPI</title><link href="http://andrewwegner.com/my-experiences-releasing-a-package-to-pypi.html" rel="alternate"></link><published>2016-03-15T12:26:00-05:00</published><updated>2016-03-15T12:26:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2016-03-15:/my-experiences-releasing-a-package-to-pypi.html</id><summary type="html">&lt;p&gt;I released StackAPI to PyPI. This post talks about my experiences.&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;In some of my &lt;a href="http://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;other projects&lt;/a&gt;, I've needed to make extensive use of the Stack Exchange API. I built a small library - StackAPI - to assist in this task and released it on Python's &lt;a href="https://pypi.python.org/pypi/StackAPI"&gt;PyPI repository&lt;/a&gt;. This post is going to cover some of the technical decisions and issues I ran into while going through this process. This was my first project being released to PyPI.&lt;/p&gt;
&lt;p&gt;My goals when releasing this were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clean up my own code so that it is usable by others&lt;/li&gt;
&lt;li&gt;Improve the documentation and host the documentation on &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automatically release it to PyPI, if it passes basic tests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those goals sound simple. In the future, they probably will be, but for this first release it wasn't as simple as I was hoping.&lt;/p&gt;
&lt;h2 id="project-layout"&gt;Project Layout&lt;a class="headerlink" href="#project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before this project, I'd written modules and libraries that were used by myself (for personal projects) or as part of a larger application (for work). In both cases, though, I had a directory structure that looked something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/project_root
    /mymodule
        __init__.py
        mymodule.py
    __init__.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This was close to the end goal, but lacked some files in the &lt;code&gt;project_root&lt;/code&gt; that were needed for a proper install via &lt;code&gt;pip&lt;/code&gt;. The important file that was missing was &lt;code&gt;setup.py&lt;/code&gt;. I needed this file to ensure that everything would install with a simple &lt;code&gt;pip install stackapi&lt;/code&gt; &lt;/p&gt;
&lt;h3 id="setuppy"&gt;setup.py&lt;a class="headerlink" href="#setuppy" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;My &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.py"&gt;&lt;code&gt;setup.py&lt;/code&gt;&lt;/a&gt; is pretty basic and available on GitHub. There are a couple important things though.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt;: This is needed, but I didn't want to have to constantly remember to update this when pushing a version to PyPI. This was one of my first criteria when starting the project. I wanted to automate as much as I could, and versioning was at the top of that list. It's small, but easy to forget and keep syncronized across all the files in the project. I decided to utilize &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; and &lt;a href="http://www.fabfile.org/"&gt;Fabric&lt;/a&gt; to manage this specific field (both here and elsewhere in the project).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;install_requires&lt;/code&gt;: StackAPI is built in the fantasitc &lt;a href="http://docs.python-requests.org/en/master/"&gt;Requests&lt;/a&gt; library. To ensure this was installed when StackAPI was install, it was needed in this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tests_require&lt;/code&gt;: The testsuite I build utilizes the &lt;code&gt;mock&lt;/code&gt; library. I don't want that to be installed if the developer isn't running the tests, so it is added to this field.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_suite&lt;/code&gt;: I wanted developers to be able to run &lt;code&gt;python setup.py test&lt;/code&gt; to execute the test suite. To do so, I had to point to the where the tests were being executed from.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The rest of &lt;code&gt;setup.py&lt;/code&gt; seemed to be fairly standard when compared to other Python libraries.&lt;/p&gt;
&lt;h3 id="bumpversion-and-fabric"&gt;Bumpversion and Fabric&lt;a class="headerlink" href="#bumpversion-and-fabric" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As I mentioned, I wanted to automate any versioning that was required. To do so, I used the &lt;a href="https://pypi.python.org/pypi/bumpversion"&gt;bumpversion&lt;/a&gt; library and wrote a small &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/fabfile.py"&gt;Fabric&lt;/a&gt; script to handle it automatically. &lt;code&gt;bumpversion&lt;/code&gt; uses a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/setup.cfg"&gt;config file&lt;/a&gt;, to determine what it is going to do. I configured it to automatically create a commit and a new git tag for each version. I then pointed to a couple files where the current version is listed. When &lt;code&gt;bumpversion&lt;/code&gt; is executed, it will change the version in each of those files to the new version. It will then create a single commit to the git repository with a commit message similar to &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Bump version: 0.1.6 → 0.1.7&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That is nice and clean. It tags the commit for me, which is useful later, when I want to push the change to PyPI.&lt;/p&gt;
&lt;p&gt;To make running &lt;code&gt;bumpversion&lt;/code&gt; a bit easier, I utilized a Fabric routine I found &lt;a href="https://gist.github.com/jbarratt/85c91d7b904462702892"&gt;online&lt;/a&gt; and adjusted it for my purposes. When I run &lt;code&gt;fab release&lt;/code&gt;, all of the &lt;code&gt;bumpversion&lt;/code&gt; 'stuff' occurs. Then I just have to push the commit (and new tag) to GitHub. &lt;/p&gt;
&lt;h3 id="final-project-layout"&gt;Final Project Layout&lt;a class="headerlink" href="#final-project-layout" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The final project layout I settled on was this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/stackapi
    /docs
        ...
    /stackapi
        __init__.py
        stackapi.py
    /tests
    .gitignore
    .travis.yml
    fabfile.py
    setup.cfg
    setup.py
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="read-the-docs"&gt;Read the Docs&lt;a class="headerlink" href="#read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id="configure-the-project"&gt;Configure the project&lt;a class="headerlink" href="#configure-the-project" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In the final project layout, you can see there is a &lt;code&gt;docs&lt;/code&gt; directory. One of my goals was to make this library usable and understandable by other developers. A good part of that means having decent documentation. I spent way more time than I expected cleaning the documentation in the code and creating documentation with examples. Most of that time was spent learning the sphinx documentation style and ReStructuredText, which Read the Docs utilizes.&lt;/p&gt;
&lt;p&gt;The first step in this process was installing and setting up the initial configuration for the documentation:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install sphinx sphinx-autobuild
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, I created the &lt;code&gt;docs&lt;/code&gt; directory and switched to it and ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sphinx-quickstart
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This starts a short, interactive, wizard. Fill out the questions. At the end of this, it creates a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/docs/conf.py"&gt;&lt;code&gt;conf.py&lt;/code&gt;&lt;/a&gt; file in the &lt;code&gt;docs&lt;/code&gt; directory. The rest of the &lt;a href="https://github.com/AWegnerGitHub/stackapi/tree/master/docs"&gt;documentation&lt;/a&gt; is ReStructuredText files.&lt;/p&gt;
&lt;p&gt;To see how the documentation looks, from the &lt;code&gt;docs&lt;/code&gt; directory, run:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;make html
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates a &lt;code&gt;_build&lt;/code&gt; directory. If you open &lt;code&gt;_build/html/index.html&lt;/code&gt;, the documentation can be browsed locally. I do not commit this directory to git, though. It is ignored in &lt;code&gt;.gitignore&lt;/code&gt;, as a user can regenerate it at will.&lt;/p&gt;
&lt;h3 id="configure-read-the-docs"&gt;Configure Read the Docs&lt;a class="headerlink" href="#configure-read-the-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Once I was satisfied with how the documentation looked, I had to configure Read the Docs to read my GitHub repository. To repeat those steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sign up (or log in) at &lt;a href="https://readthedocs.org/"&gt;Read the Docs&lt;/a&gt; (part of this will be associating the account to a GitHub account)&lt;/li&gt;
&lt;li&gt;Visit your &lt;a href="https://readthedocs.org/dashboard/"&gt;dashboard&lt;/a&gt; and click "Import a project"&lt;/li&gt;
&lt;li&gt;Fill out the form, but in my case the defaults were all appropriate. Do note that URLs are case sensitive.&lt;/li&gt;
&lt;li&gt;Click "Create". This is the first version of your documentation.&lt;/li&gt;
&lt;li&gt;To keep the code updating as you update GitHub, log into GitHub and go to the repository's "Settings" page.&lt;/li&gt;
&lt;li&gt;Click "Webhooks &amp;amp; Services"&lt;/li&gt;
&lt;li&gt;Click "Add Service"&lt;/li&gt;
&lt;li&gt;Select "ReadTheDocs" and add the service&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, each time you push a change to the repository, a new set of documents will be built. I then added the Read the Docs badge to my &lt;code&gt;README.rst&lt;/code&gt; for a simple link to the detailed documentation.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;..&lt;/span&gt; &lt;span class="ow"&gt;image&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt; https://readthedocs.org/projects/stackapi/badge/?version=latest
&lt;span class="nc"&gt;:target:&lt;/span&gt; &lt;span class="nf"&gt;http://stackapi.readthedocs.org/en/latest/?badge=latest&lt;/span&gt;
&lt;span class="nc"&gt;:alt:&lt;/span&gt; &lt;span class="nf"&gt;Documentation Status&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="force-rebuild-of-docs"&gt;Force rebuild of docs&lt;a class="headerlink" href="#force-rebuild-of-docs" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Toward the very end of this project, Read the Docs had a minor hiccup and failed on building my documentation. I didn't want to force a build by making a fake commit. Instead, Read the Docs provides the information needed to force a rebuild. It requires a very simple &lt;code&gt;POST&lt;/code&gt; to the Post Commit Hook they provide. In my case, this was as simple as running this command (provided from the Dashboard):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -X POST https://readthedocs.org/build/stackapi
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="pypi"&gt;PyPI&lt;a class="headerlink" href="#pypi" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Nearing the end of the journey, it was time to see what exactly PyPI required. The first step was setting up an account on both the Test and Production instances of PyPI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PiPY Test: http://testpypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;li&gt;PyPI Live: https://pypi.python.org/pypi?%3Aaction=register_form&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having one on both was important while testing. It meant that I didn't have to send broken versions to the live PyPI server, and I could adjust ReStructuredText formatting issues without requiring another release to PyPI. Each time a version is pushed to PyPI it &lt;strong&gt;must&lt;/strong&gt; have a new version number. By using the test instance, I could use as many of these fake versions as needed to fix things. Hooray for test environments!&lt;/p&gt;
&lt;p&gt;Before we perform this step automatically, we need to test that the PyPI accounts work. By following portions of a &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;"First Time with PyPI"&lt;/a&gt; tutorial, I focused by steps down to these:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a &lt;code&gt;.pypirc&lt;/code&gt; file in your home directory - not your project directory. This won't be required once Travis CI is set up and configured, so having the passwords in this, temporarily, wasn't an issue because I eventually deleted the file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The file looks like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[distutils]&lt;/span&gt;
&lt;span class="na"&gt;index-servers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&lt;/span&gt;
&lt;span class="s"&gt;  pypi&lt;/span&gt;
&lt;span class="s"&gt;  pypitest&lt;/span&gt;

&lt;span class="k"&gt;[pypi]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://pypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;

&lt;span class="k"&gt;[pypitest]&lt;/span&gt;
&lt;span class="na"&gt;repository&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;https://testpypi.python.org/pypi&lt;/span&gt;
&lt;span class="na"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_username&lt;/span&gt;
&lt;span class="na"&gt;password&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;your_password&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Register the package on PyPI Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Register the package on PyPI Live: &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Test: &lt;code&gt;python setup.py register -r pypitest&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Upload the project to Live, &lt;em&gt;if&lt;/em&gt; you're ready for your first release. Remember, once a version is released to PyPI, it can't be used again (or overwritten): &lt;code&gt;python setup.py register -r pypi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If all of the above passed to your satisfaction, you can remove the &lt;code&gt;.pypirc&lt;/code&gt; file and move on to configuring Travis CI.    &lt;/p&gt;
&lt;h2 id="travis"&gt;Travis&lt;a class="headerlink" href="#travis" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The last step in this process will be using Travis CI to perform some basic tests and, if this was a new release, push the changes to PyPI. The Travis config file is available on &lt;a href="https://github.com/AWegnerGitHub/stackapi/blob/master/.travis.yml"&gt;GitHub&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;My goal is to support 'modern' Python with this library. I've configured Travis to test against multiple versions of Python, ranging from 2.7 to 3.5. StackAPI is installed using &lt;code&gt;python setup.py -q install&lt;/code&gt;. Then the test suite is run. &lt;/p&gt;
&lt;p&gt;The important bits are in the &lt;code&gt;deploy&lt;/code&gt; section. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;tags&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
  &lt;span class="n"&gt;branch&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;master&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If there is a new git tag pushed to GitHub, and the tests pass, Travis CI will push the code to PyPI. Since &lt;code&gt;bumpversion&lt;/code&gt; makes a new git tag with each new version, this works perfectly. &lt;/p&gt;
&lt;p&gt;This does require that my password be included in the yml file. To keep this secure, I utilized the &lt;a href="https://blog.travis-ci.com/2013-01-14-new-client/"&gt;Travis Command Line Client&lt;/a&gt; (&lt;code&gt;gem install travis&lt;/code&gt;). In my local directory, I then ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;travis encrypt --add deploy.password
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This added the password to the YML file. &lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This was the first time I've released something to PyPI. It took a lot more set up than I expected it would take. However, now that I've gone through the process, gotten used to the ReStructuredText format that Sphinx and Read the Docs require, and set up PyPI for one project, I think it'll be fairly simple to do in the future. Most of the work is getting the other services to talk with GitHub and practicing good developer habits (documentation...).&lt;/p&gt;
&lt;h2 id="all-stackapi-links"&gt;All StackAPI Links&lt;a class="headerlink" href="#all-stackapi-links" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;All of these links are to the various places that StackAPI lives on the internet&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: https://github.com/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read the Docs&lt;/strong&gt;: http://stackapi.readthedocs.org/en/latest/&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TravisCI&lt;/strong&gt;: https://travis-ci.org/AWegnerGitHub/stackapi&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPI&lt;/strong&gt;: https://pypi.python.org/pypi/StackAPI&lt;/li&gt;
&lt;/ul&gt;</content><category term="technical"></category></entry><entry><title>How I built a Flask application that integrates with Travis CI and OpenShift</title><link href="http://andrewwegner.com/how-i-set-up-openshift-travisci-and-flask.html" rel="alternate"></link><published>2015-12-11T09:15:00-06:00</published><updated>2015-12-12T00:00:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2015-12-11:/how-i-set-up-openshift-travisci-and-flask.html</id><summary type="html">&lt;p&gt;A walkthrough on how I set up a Flask application on OpenShift and used TravisCI to deploy it&lt;/p&gt;</summary><content type="html">
&lt;h2 id="motivation"&gt;Motivation&lt;a class="headerlink" href="#motivation" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Since I &lt;a href="http://andrewwegner.com/thanks-for-all-the-fish.html"&gt;shut down&lt;/a&gt; Vipers early this year, I've been itching to do &lt;em&gt;something&lt;/em&gt; web related. Web technologies aren't my best technical skill, but I like trying out new things and learning something in the process. I use Python at work. I like Python a lot. With Christmas and New Years coming up, I want to have a project during my down time. My goal is to get a &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; application built and then deployed to &lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt;. Part of this deployment is to utilize &lt;a href="https://travis-ci.org/"&gt;TravisCI&lt;/a&gt;. I'm planning on using &lt;a href="http://pytest.org/latest/"&gt;pytest&lt;/a&gt; and &lt;a href="https://hypothesis.readthedocs.org/en/latest/"&gt;hypothesis&lt;/a&gt; for my test suite. Finally, I want to use my own (sub)domain, instead of the provided &lt;code&gt;rhcloud&lt;/code&gt; one.&lt;/p&gt;
&lt;p&gt;Of these three technologies, I've used only Flask before. The &lt;a href="http://andrewwegner.com/can-a-machine-be-taught-to-flag-comments-automatically.html"&gt;comment flagging bot&lt;/a&gt; I built has a dashboard built in Flask. I've never used OpenShift or TravisCI. I selected OpenShift because it has a couple &lt;a href="http://www.paasify.it/compare/heroku-vs-openshift%20online"&gt;features&lt;/a&gt; I want that Heroku doesn't. The biggest one, according to the previous link, was that OpenShift has support for MySQL and Heroku doesn't (surprisingly). I want to use TravisCI and automated testing, because one of my goals for next year at work is to introduce automated tested to our development. (I work with Engineers, not coders...that's my excuse and it's a bad excuse, so I'm going to try and fix it.) To get ready for that goal, I want to test out a system that does continuous integration/automated testing. Both OpenShift and Travis CI provide me with free services. Hypothesis and py.test provide me with a way to generate comprehensive test conditions. &lt;/p&gt;
&lt;h2 id="openshift-set-up"&gt;OpenShift set up&lt;a class="headerlink" href="#openshift-set-up" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Signing up for OpenShift was easy. Fill out the form, provide an email address - though they don't like email addresses with &lt;code&gt;+&lt;/code&gt; signs, which is disappointing - and then click the link they email back to you. &lt;/p&gt;
&lt;p&gt;Next, the &lt;code&gt;rhc&lt;/code&gt; OpenShift client tools are needed. This is a Ruby package. I have no experience with Ruby, so I needed to install Ruby as well. I ran into a problem almost immediately. The &lt;a href="https://developers.openshift.com/en/managing-client-tools.html"&gt;page&lt;/a&gt; for installing these tools says:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenShift rhc can be run on any operating system with Ruby 1.8.7 or higher assuming you have the requisite user permissions to install programs. Instructions for specific operating systems are provided below. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Based on that, I figured I'd install the latest version of &lt;a href="http://rubyinstaller.org/downloads/"&gt;Ruby&lt;/a&gt;. At the time I tested this, that was 2.2.3. Unfortunately, when I ran the command to install the &lt;code&gt;rhc&lt;/code&gt; tools, I received an error. After a bit of Googling, I found that it doesn't like 2.2x. So, I installed 2.1.7 instead. Next, I ran:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gem install rhc
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This installs several gems and took a few minutes to complete. Next,&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc setup
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This started the OpenShift setup wizard. It consisted of filling out the few prompts and letting it generate an SSH key and then connecting to my account. Remember the Namespace you select. Again, this took a few minutes.&lt;/p&gt;
&lt;h2 id="flask-setup"&gt;Flask setup&lt;a class="headerlink" href="#flask-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The next step was to set up my first "Gear". This would be the Flask application. I'll work on the database next. First, I just want Python and Flask to function properly. Fortunately, this is very easy, as OpenShift has a Flask template.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc app create testapp python-2.7 --from-code=https://github.com/openshift-quickstart/flask-base.git
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I am utilizing Python 2.7, because that is the recommendation from the Flask team.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;testapp&lt;/code&gt; can be any alphanumeric string. This is the name that will appear in the Web Console. A specific note, &lt;code&gt;_&lt;/code&gt; is not alphanumeric. I'm getting the feeling that OpenShift doesn't like "special" characters.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--from-code&lt;/code&gt; parameter will download that repository and use it as the base of your application. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point, Flask can be run locally using:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python app.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The application can be pushed back to OpenShift at this point and there should be a functional page on your OpenShift domain. In your command line, from the directory of your project:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git add --all
git commit -m "Adding Flask application"
git push
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will take a moment. At the end, you should see these lines in your command prompt:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Git&lt;/span&gt; &lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Receive&lt;/span&gt; &lt;span class="n"&gt;Result&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Activation&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;span class="n"&gt;remote&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Deployment&lt;/span&gt; &lt;span class="n"&gt;completed&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;success&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If all three are a success, then you should be able to visit your URL. Your URL is a combination of your selected Namespace and the application name you created.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;http://&amp;lt;namespace&amp;gt;-&amp;lt;testapp&amp;gt;.rhcloud.com/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should show a "Welcome to Flask on OpenShift" page. If you append &lt;code&gt;/test&lt;/code&gt; to your URL, you'll get a message that says "It's Alive!"&lt;/p&gt;
&lt;p&gt;If it doesn't, you can check your error logs by running:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rhc tail -a &amp;lt;testapp&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="mysql-setup"&gt;MySQL setup&lt;a class="headerlink" href="#mysql-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Next, I set up my application to utilize MySQL. It's the database I have the most experience with, so I decided to keep that aspect of this project simple for myself. The first step was to add a MySQL 5.5 cartridge to my test gear (OpenShift terminology). I did this in the OpenShift web console. The UI provided me with the option to install various databases and one of those was MySQL. Clicking the link caused a few second delay as it was set up, and then I was presented with login credentials to my database. Step one...done.&lt;/p&gt;
&lt;p&gt;The next step is installing the correct Python modules to utilize MySQL. I selected &lt;a href="http://www.pymysql.org/"&gt;PyMySQL&lt;/a&gt; (again, experience) and &lt;a href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. I added these to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;. The idea behind doing it in both places is to make life easy for myself in the future. Additionally, the quick tutorials I've looked at for TravisCI encourage the usage of &lt;code&gt;requirements.txt&lt;/code&gt;, while it seems OpenShift uses the &lt;code&gt;setup.py&lt;/code&gt;. I'll fix that eventually, but getting it set up initially, this will be fastest.&lt;/p&gt;
&lt;p&gt;Add these to &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sqlalchemy==1.0.9
pymysql==0.6.7
Flask-SQLAlchemy==2.1
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add this to the &lt;code&gt;install_requires&lt;/code&gt; list in &lt;code&gt;setup.py&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'sqlalchemy==1.0.9','pymysql==0.6.7','Flask-SQLAlchemy==2.1'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The nice thing about OpenShift is that the credentials to the database are placed in &lt;a href="https://developers.openshift.com/en/managing-environment-variables.html#database-variables"&gt;environment variables&lt;/a&gt;, so I don't need to embed the passwords, connections strings, or anything potentially sensitive in my code. For MySQL these are available as:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Variable Name               |   Purpose
------------------------------------------------
OPENSHIFT_MYSQL_DB_HOST     |   The host name or IP address used to connect to the database.
OPENSHIFT_MYSQL_DB_PORT     |   The port the database server is listening on.
OPENSHIFT_MYSQL_DB_USERNAME |   The database administrative user name.
OPENSHIFT_MYSQL_DB_PASSWORD |   The database administrative user’s password.
OPENSHIFT_MYSQL_DB_SOCKET   |   An AF socket for connecting to the database (for non-scaled apps only).
OPENSHIFT_MYSQL_DB_URL      |   Database connection URL.
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="utilizing-the-database"&gt;Utilizing the database&lt;a class="headerlink" href="#utilizing-the-database" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Setting up SQLAlchemy and MySQL is fairly easy. I tested this with a simple table and ensured that it appeared in the database as expected.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kr"&gt;class&lt;/span&gt; &lt;span class="nx"&gt;User&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="nx"&gt;__tablename__&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'users'&lt;/span&gt;
    &lt;span class="nx"&gt;id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'user_id'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Integer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nx"&gt;primary_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nx"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nx"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;Column&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;db&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nb"&gt;String&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;60&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A few adjustments were made to the import statements of the Flask application:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;flask_sqlalchemy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SQLAlchemy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A couple variables were created and loaded:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;app.config.from_pyfile('flaskapp.cfg')
db = SQLAlchemy(app)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the &lt;code&gt;flaskapp.cfg&lt;/code&gt; file was modified to include these two lines:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SQLALCHEMY_DATABASE_URI = os.environ['OPENSHIFT_MYSQL_DB_URL'] + os.environ['OPENSHIFT_APP_NAME]
SQLALCHEMY_ECHO = False
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="remote-mysql-access"&gt;Remote MySQL Access&lt;a class="headerlink" href="#remote-mysql-access" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I like to use &lt;a href="https://www.mysql.com/products/workbench/"&gt;MySQL Workbench&lt;/a&gt; while building and testing to watch what's happening in the database. To use that with OpenShift, I had to jump through a few small hoops. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open MySQL Workbench and create a new connection&lt;/li&gt;
&lt;li&gt;Give the connection a name&lt;/li&gt;
&lt;li&gt;In "Connection Method", select "Standard TCP/IP over SSH"&lt;/li&gt;
&lt;li&gt;The SSH Hostname is the full name of your OpenShift gear where MySQL is installed. It should look like &lt;code&gt;namespace-appname.rhcloud.com&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The SSH Username is the gear's Unique Identifier. This can be found by looking at the &lt;code&gt;OPENSHIFT_GEAR_UUID&lt;/code&gt; environment variable. It can also be found in the web console, but looking at the "remote access" section. It shows a connection string. You need the username portion. This is the part that appears before the &lt;code&gt;@&lt;/code&gt; in the &lt;code&gt;ssh longuniquestring@namespace-appname.rhcloud.com&lt;/code&gt; command. &lt;/li&gt;
&lt;li&gt;Set the SSH key file. On Windows this is in &lt;code&gt;\Users\&amp;lt;username&amp;gt;\.ssh\id_rsa&lt;/code&gt; by default&lt;/li&gt;
&lt;li&gt;Set MySQL Hostname equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_HOST&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set Username equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_USERNAME&lt;/code&gt; (this was also provided to you when you installed MySQL)&lt;/li&gt;
&lt;li&gt;See Password equal to the value in &lt;code&gt;OPENSHIFT_MYSQL_DB_PASSWORD&lt;/code&gt; (again, this was provided to you when MySQL was installed)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="travisci-setup"&gt;TravisCI setup&lt;a class="headerlink" href="#travisci-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I want to play with automated testing. The idea behind this is to get a jump start on a goal for next year at work and to learn something new. I'd like to utilize Travis CI to perform the tests and if they pass, deploy to OpenShift. If the tests fail, I don't want to push a broken build to OpenShift. That's the goal...we'll see how it turns out. But, the first step is getting Travis CI and OpenShift talking to one another.&lt;/p&gt;
&lt;p&gt;Travis CI integrates with GitHub, so what I'm going to do in reality is push to GitHub and let Travis CI pick up the changes. From there, it will perform it's tests. If the tests pass, it will push the commit to OpenShift.&lt;/p&gt;
&lt;p&gt;On GitHub, create a new repository for your source. This is where you will be pushing your code for Travis CI to pick up.&lt;/p&gt;
&lt;p&gt;From your OpenShift directory (which is already a git repository):&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git remote rename origin openshift
git remote add origin https://github.com/&amp;lt;USER&amp;gt;/&amp;lt;repositoryname&amp;gt;.git
git push -u origin master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This resets the origin to point to your new GitHub repository and sets up a new remote. Then it pushes the changes to GitHub.&lt;/p&gt;
&lt;p&gt;Log into your &lt;a href="https://travis-ci.org/profile"&gt;Travis CI profile page&lt;/a&gt;. Make sure you are logged into GitHub first, as this will create the profile automatically. Press the "Sync now" button at the top of the page to pull a list of all of your repositories. Once that is done, find the repository you just set up, and enable integration with that repository.&lt;/p&gt;
&lt;p&gt;Next you need to set up Travis CI and the &lt;code&gt;.travis.yml&lt;/code&gt; file. &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gem install travis
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will install a Ruby script that assists in this process. If you get an error when running this, you need to create an empty &lt;code&gt;.travis.yml&lt;/code&gt; file first and then run the command again.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;travis setup openshift
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fill out the prompts. Defaults should be fine in most cases, but do pay attention to "OpenShift application name". If your GitHub repository is named differently than your OpenShift application name, the default for this prompt will be incorrect.&lt;/p&gt;
&lt;p&gt;One last note, for a quick test you can change the &lt;code&gt;script&lt;/code&gt; section to &lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;script&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This forces the tests to pass. Once you've written tests, you can do something like:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script:
    - py.test
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will run your test scripts, utilizing &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Deploy these changes to GitHub:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git add .travis.yml
git commit -m "Deploying Travis"
git push origin master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will commit and push the changes to GitHub. A few seconds later, if you are watching Travis CI, you'll see it notices the new commit and starts running tests. If you tests complete with a status code of &lt;code&gt;0&lt;/code&gt; (successful), it will deploy the changes to OpenShift. If the tests fail (any other status code), it will not deploy to OpenShift.&lt;/p&gt;
&lt;h2 id="pytest-setup"&gt;py.test setup&lt;a class="headerlink" href="#pytest-setup" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Setting up the testing frame work involves a few Python modules. These need to be added to both &lt;code&gt;requirements.txt&lt;/code&gt; and &lt;code&gt;setup.py&lt;/code&gt;.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pytest&amp;gt;=2.8.0
hypothesis==1.16.0
pytest-runner==2.6.2
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The next step is setting up some quick integration with &lt;code&gt;setup.py&lt;/code&gt;, so that users can run &lt;code&gt;python setup.py test&lt;/code&gt; and execute your tests.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;setup.py&lt;/code&gt;, add (or edit) the &lt;code&gt;setup_requires&lt;/code&gt; list to include &lt;code&gt;pytest-runner&lt;/code&gt;. Add (or edit) the &lt;code&gt;tests_require&lt;/code&gt; list to include &lt;code&gt;pytest&lt;/code&gt;. I also added the following to my &lt;code&gt;setup.cfg&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[aliases]&lt;/span&gt;
&lt;span class="na"&gt;test&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;pytest&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I modified my &lt;code&gt;setup_requires&lt;/code&gt; list a bit, so that it's conditional. Since this would install the &lt;code&gt;pytest-runner&lt;/code&gt; on every call to &lt;code&gt;setup.py&lt;/code&gt;, even when the module wouldn't be called, I wanted the runner to only be required when &lt;code&gt;pytest&lt;/code&gt; is utilized.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'pytest'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ptr'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;intersection&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pytest_runner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pytest-runner'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;needs_pytest&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="n"&gt;setup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;setup_requires&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="c1"&gt;#... Other requirements here&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;pytest_runner&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I wanted to test that my tests were working correctly. I created a &lt;code&gt;tests&lt;/code&gt; directory, which is where I plan on storing all of my test cases. &lt;code&gt;pytest&lt;/code&gt; will find any files that start or end with &lt;code&gt;test&lt;/code&gt; and execute them. I created a very simple &lt;code&gt;test_tests.py&lt;/code&gt; file with the following simple test (taken from the &lt;a href="https://hypothesis.readthedocs.org/en/latest/quickstart.html#writing-tests"&gt;Hypothesis Quickstart&lt;/a&gt;)&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@given(st.integers(), st.integers())
def test_ints_are_commutative(x, y):
    assert x + y == y + x
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, Travis CI needs to be told what to do. Modify the &lt;code&gt;script&lt;/code&gt; key to include &lt;code&gt;py.test&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;script:
   - py.test
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After a successful run through Travis, you'll see something like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tests/test_tests.py .
=========================== 1 passed in 0.26 seconds ===========================
The command "py.test" exited with 0.
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="custom-domain"&gt;Custom Domain&lt;a class="headerlink" href="#custom-domain" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have my own domain name. I want to utilize OpenShift with one of those domains, instead of the default one provided. Since I've using the free tier, that will rule out using the SSL certificate that is wildcarded to the whole &lt;code&gt;rhcloud.com&lt;/code&gt; domain. I can live with this. If I need SSL on my domain, I'll upgrade.&lt;/p&gt;
&lt;p&gt;To set up OpenShift to use your domain, log into the web console. Go to the gear you are configuring. At the top, where the full domain is displayed, is the option to "Change". Select that option. Input the full domain (and subdomain) you want to utilize and click "Save". After a few seconds, you'll get a notification that the alias was created.&lt;/p&gt;
&lt;p&gt;The next step is to configure the DNS records. I &lt;a href="http://andrewwegner.com/how-i-set-up-this-site-with-github-pages-and-cloudflare.html"&gt;utilize&lt;/a&gt; CloudFlare for my domains, so the instructs will be specific to that, but should apply to any DNS system. Login to your management system and go to the area where you can specify DNS records.&lt;/p&gt;
&lt;p&gt;For my test, I set up a subdomain of one of my domains as the alias I wanted to use. In your DNS system, set up a CNAME that points to the original hostname on OpenShift. The CNAME should be the subdomain you told OpenShift about. Save the record. &lt;/p&gt;
&lt;p&gt;CloudFlare recognized this immediately and redirected me to my Flask application. Hooray!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;a class="headerlink" href="#conclusion" title="Permanent link"&gt;¶&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;With this, the set up is complete. You have a Flask application, connected to MySQL, that is integrated with a CI system which automatically deploys to OpenShift when all tests pass and uses CloudFlare (because I already was doing so), to provide a CDN. &lt;/p&gt;
&lt;p&gt;On to building something!&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Connect Python to OSI Soft PI</title><link href="http://andrewwegner.com/connect-python-to-osi-soft-pi.html" rel="alternate"></link><published>2012-02-07T12:45:00-06:00</published><updated>2012-04-16T00:00:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2012-02-07:/connect-python-to-osi-soft-pi.html</id><summary type="html">&lt;p&gt;How I connected Python to OSI Soft PI&lt;/p&gt;</summary><content type="html">&lt;p&gt;OSI PI is a historian database. I had a task to connect a python application to this database. I asked a question on 
&lt;a href="http://stackoverflow.com/questions/8898114/how-can-i-connect-python-2-6-to-osi-pi"&gt;Stack Overflow&lt;/a&gt; about whether this was a simple problem to solve. After two weeks I still hadn't gotten a viable response,
so I had to build by own solution.&lt;/p&gt;
&lt;p&gt;I did reach out to the vendor first for help. Their response back was not helpful. &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Looks like pyodbc is written against ODBC 3.x.  The OSI PI ODBC driver is using ODBC 2.0.  The python ODBC driver manager 
will convert most ODBC 3 calls on the fly to ODBC 2 ones. Anything added to 3, however, will obviously fail. You would 
need to find some way to make sure that your only using 2.0 compliant ODBC calls.  Currently their is not a PI ODBC 
driver that is compliant with ODBC 3.0.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, it looks like the vendor doesn't support Python (odd, they are named "PI", but I digress). Additionally, the drivers provided 
by the company initially didn't work. &lt;/p&gt;
&lt;p&gt;The code below shows how I was able to finally connect python to OSI PI. It may not be the most elegant, but it 
functions for the purposes of my application. Initially I was attempting to connect using the &lt;a href="https://github.com/mkleehammer/pyodbc"&gt;pyodbc&lt;/a&gt; module. Unfortunately, 
OSI PI would return a message like this:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pyodbc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nl"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;IM002&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[IM002] [OSI][PI ODBC][PI]PI-API Error &amp;lt;pilg_getdefserverinfo&amp;gt; 0 (0) (SQLDriverConnectW); [01000] [Microsoft][ODBC Driver Manager] The driver doesn&amp;#39;t support the version of ODBC behavior that the application requested (see SQLSetEnvAttr). (0)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;They vendor mentioned that using OLEDB instead may prove more fruitful. Thus, the code below is how I got connected using 
the vendor provided OLDEB driver. The downside is that I also had to do this all through COM objects using &lt;a href="http://python.net/crew/skippy/win32/Downloads.html"&gt;win32com&lt;/a&gt;. 
I'm not knocking the module, because it is extremely useful and I've done some great things with it.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;win32com.client&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.Connection&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Dispatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ADODB.RecordSet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ConnectionString&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Provider=PIOLEDB;Data Source=&amp;lt;server&amp;gt;;User ID=&amp;lt;username&amp;gt;;database=&amp;lt;database&amp;gt;;Password=&amp;lt;password&amp;gt;&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;We&amp;#39;ve connected to the database.&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;db_cmd&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&amp;quot;SELECT tag FROM pipoint WHERE tag LIKE &amp;#39;TAG0001%&amp;#39;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ActiveConnection&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db_cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EOF&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;#print oRS.Fields.Item(&amp;quot;tag&amp;quot;).Value   # Ability to print by a field name&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Fields&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Value&lt;/span&gt;        &lt;span class="c1"&gt;# Ability to print by a field location&lt;/span&gt;
        &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;MoveNext&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;oRS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Not connected&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;State&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;oConn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;oConn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I followed up on my Stack Overflow post about 2 months after posting my solution with the following note:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Just following up on this after using it for a couple months. This is still the only way I've found to do this with 
python, but it seems to be very slow when I need to run a large number of queries. I suspect it is because I have to 
open/close the database connection for each query, but OSI PI/ADODB complains if I do not. Performance has not reached a 
point where I am forced to rewrite this yet. If/when I do I will follow up again. In the meantime others using this 
solution should be aware that it is slow when running many queries.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="technical"></category></entry><entry><title>Multiple IP addresses on the same physical network card</title><link href="http://andrewwegner.com/multiple-ip-addresses-on-the-same-physical-network-card.html" rel="alternate"></link><published>2010-11-17T12:54:00-06:00</published><updated>2010-11-17T12:54:00-06:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-11-17:/multiple-ip-addresses-on-the-same-physical-network-card.html</id><summary type="html">&lt;p&gt;A quick walkthrough on how to configure a single network card to pull multiple IP addresses (RedHat based distribution)&lt;/p&gt;</summary><content type="html">&lt;p&gt;There are times when a server can be allocated more than one IP Address even though it contains only one physical 
network card. To associate these IP addresses with the server some manipulation of networking settings will need to be 
performed. The steps outlined in this walk-through are for RedHat based systems. This tutorial is for statically assigned 
IP Addresses (as a server generally will have).
For this walk through we are going to add one additional IP address to &lt;code&gt;eth0&lt;/code&gt;. Navigate to&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd /etc/sysconfig/network-scripts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Copy &lt;code&gt;ifcfg-eth0&lt;/code&gt; to &lt;code&gt;ifcfg-eth0:0&lt;/code&gt;&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cp ifcfg-eth0 ifcfg-eth0:0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now we need to modify the new file slightly so that it gets it's own IP address. Open &lt;code&gt;ifcfg-eth0:0&lt;/code&gt; in your favorite editor&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;DEVICE=eth0:0           &amp;lt;-- Change this to match the new eth0:0 file we just created
BOOTPROTO=none
BROADCAST=x.x.x.x       &amp;lt;-- This is the broad cast address for the subnet the new IP is on
DNS1=x.x.x.x            &amp;lt;-- This is the main DNS server you are using (example: 64.120.14.26)
GATEWAY=x.x.x.x         &amp;lt;-- This is the gateway address for the subnet the new IP is on
HWADDR=&amp;lt;DO NOT CHANGE&amp;gt;  &amp;lt;-- Don&amp;#39;t change this from what is existing. The Hardware address is the same as the physical one
IPADDR=x.x.x.x          &amp;lt;-- This is your new IP address
NETMASK=x.x.x.x         &amp;lt;-- This is the netmask for the subnet the new IP is on
ONBOOT=yes              &amp;lt;-- Leave to yes
OPTIONS=layer2=1
TYPE=Ethernet
PREFIX=29
DEFROUTE=yes
NAME=&amp;quot;System eth0:0&amp;quot;    &amp;lt;-- Change to reflect new name of device
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Save your file with the new settings. Now we need to restart the networking service:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service network restart
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When the network components come back up you should see your new device in the &lt;code&gt;ifconfig&lt;/code&gt; command. To add more IPs, 
copy and replace values as specified above.&lt;/p&gt;</content><category term="technical"></category></entry><entry><title>Fixing MYISAM Crashed Tables</title><link href="http://andrewwegner.com/fixing-myisam-crashed-tables.html" rel="alternate"></link><published>2010-05-14T10:08:00-05:00</published><updated>2010-05-14T10:08:00-05:00</updated><author><name>Andy Wegner</name></author><id>tag:andrewwegner.com,2010-05-14:/fixing-myisam-crashed-tables.html</id><summary type="html">&lt;p&gt;How to fix MyISAM tables that are marked as crashed&lt;/p&gt;</summary><content type="html">&lt;p&gt;For various reasons, MyISAM tables are known to crash. When this happens, the following message will be displayed:&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;INVALID SQL: 145 : Table &amp;#39;{something}&amp;#39; is marked as crashed and should be repaired
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I've found this error occurs when MySQL is unexpectedly shut down - whether from a power failure to the entire server or 
if MySQL itself has issues and you use the &lt;code&gt;kill&lt;/code&gt; command to stop it. Unexpected shut downs, especially while these tables 
are being used, do not make MyISAM tables happy.&lt;/p&gt;
&lt;p&gt;To fix this, you need the ability to stop MySQL in a controlled manner, and you need to know where the database files 
are stored.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;locate *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will return where all the MYI files are stored. In this example, I am using&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/var/lib/mysql/mysql/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Go to the directory of the crashed table using the &lt;code&gt;cd&lt;/code&gt; command. Next, stop MySQL. This is to ensure the tables are not 
accessed while we perform our repair functions. If you don't perform this step, the repair may not succeed.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service mysqld stop
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Next we are going to perform two repair functions. The first one may take a while depending on the size of your tables.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;myisamchk -r --force --safe-recover *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The second repair step is used to ensure all table states are updated correctly and repair any minor indexing issues. It 
is likely that this step is not needed after performing the previous step, but it should only take a few seconds now.&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;myisamchk --force --fast --update-state *.MYI
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Finally, restart MySQL&lt;/p&gt;
&lt;div class="codehilight code"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;service mysqld start
&lt;/pre&gt;&lt;/div&gt;</content><category term="technical"></category></entry></feed>